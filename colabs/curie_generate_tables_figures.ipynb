{"cells":[{"cell_type":"code","source":["!pip install json5"],"metadata":{"id":"jZB-sM04kGdl"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"p1aMxI6bBKfF"},"outputs":[],"source":["import collections\n","\n","import json5\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import pandas as pd\n","import seaborn as sns\n","\n","from google.colab import drive\n","# from google.colab import userdata\n","\n","\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3qSVW0_BNM02"},"outputs":[],"source":["BASEDIR = '/content/drive/Shareddrives/Curie/benchmarks/public_release'\n","meta_results_path = f\"{BASEDIR}/eval_results/up_to_date/meta_results.json\""]},{"cell_type":"markdown","metadata":{"id":"tR70YC0gaHIE"},"source":["# Tables"]},{"cell_type":"markdown","metadata":{"id":"Mhu6mMSUMp1s"},"source":["## Table 1"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ArZez8JbMhs7"},"outputs":[],"source":["TASKS_2_METRICS = {\n","    (\"dft\", \"extract_structure_data_1_shot\"): [\n","        \"rougeLsum\",\n","        \"bert_f1\",\n","    ],\n","    (\"dft\", \"extract_dft_metadata_1_shot\"): [\n","        \"rougeLsum\",\n","        \"bert_f1\",\n","    ],\n","    (\"dft\", \"write_code_for_paper_0_shot\"): [\n","        \"rougeLsum\",\n","        \"bert_f1\",\n","    ],\n","    (\"mpv\", \"mat_paper_to_property_1_shot\"): [\n","        \"rougeLsum\",\n","        \"bert_f1\",\n","    ],\n","    (\"hfd\", \"derivation_prompt\"): [\n","        \"rougeLsum\",\n","        \"bert_f1\",\n","    ],\n","    (\"hfe\", \"extract_hamiltonian_0_shot\"): [\n","        \"rougeLsum\",\n","        \"bert_f1\",\n","    ],\n","    (\"qecc_65\", \"describe_code_in_paper\"): [\n","        \"rougeLsum\",\n","        \"bert_f1\",\n","    ],\n","    (\"geo\", \"extract_dataset_from_geo_papers_0_shot\"): [\n","        \"rougeLsum\",\n","        \"bert_f1\",\n","    ],\n","    (\"biogr\", \"georeference_image_0_shot\"): [\n","        \"iou\",\n","    ],\n","    (\"pdb\", \"reconstruct_protein_amino_acid_sequence_0_shot\"): [\n","        \"identity_ratio\",\n","    ],\n","}\n","\n","all_results = json5.load(open(meta_results_path, \"r\"))\n","df = pd.json_normalize(all_results, sep=\"$$\").transpose()\n","\n","# Add separe columns for task, model, example, metric, and value\n","df[\"task\"] = df.apply(lambda x: x.name.split(\"$$\")[0], axis=1)\n","df[\"prompt\"] = df.apply(lambda x: x.name.split(\"$$\")[1], axis=1)\n","df[\"model\"] = df.apply(lambda x: x.name.split(\"$$\")[2], axis=1)\n","df[\"example\"] = df.apply(lambda x: x.name.split(\"$$\")[3], axis=1)\n","def extract_metric(x):\n","  \"\"\"Extracts the metric from the name string.\"\"\"\n","  parts = x.name.split(\"$$\")\n","  if len(parts) > 4:\n","    return parts[4]\n","  else:\n","    return \"xxxxx\"\n","df[\"metric\"] = df.apply(extract_metric, axis=1)\n","df[\"value\"] = df[0]\n","\n","# Update the names\n","df[\"task\"] = df[\"task\"].str.replace(\"mpve\", \"mpv\")\n","\n","\n","df[\"task_prompt\"] = df.apply(lambda x: \"_\".join([x.task, x.prompt]), axis=1)\n","df[\"task_prompt_metric\"] = df.apply(\n","    lambda x: \"_\".join([x.task, x.prompt, x.metric]), axis=1\n",")\n","\n","df_len = len(df)\n","\n","# Delete extra tasks, prompts, and metrics\n","task_prompt_metric_keep = []\n","for (task, prompt), metrics in TASKS_2_METRICS.items():\n","  for metric in metrics:\n","    task_prompt_metric_keep.append(\"_\".join([task, prompt, metric]))\n","\n","df = df.drop(df[~df[\"task_prompt_metric\"].isin(task_prompt_metric_keep)].index)\n","print(f\"{df_len-len(df)} rows contain extra tasks and are dropped.\")\n","df_len = len(df)\n","\n","# Delete non numerical entries\n","df = df[pd.to_numeric(df['value'], errors='coerce').notnull()]\n","print(f'{df_len-len(df)} rows contain non numerical entries and are dropped.')\n","df_len = len(df)\n","\n","print(f\"The final dataframe has {len(df)} rows.\")\n","\n","grouped = (\n","    df.groupby([\"model\", \"task\", \"metric\"])[\"value\"]\n","    .agg([\"mean\", \"std\"])\n","    .fillna(0)\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wNKKu-5yMhp0"},"outputs":[],"source":["def print_row(model):\n","  metrics_strings = []\n","  for task in [\n","      \"dft\",\n","      \"mpv\",\n","      \"hfd\",\n","      \"hfe\",\n","      \"qecc_65\",\n","      \"geo\",\n","  ]:\n","    for metric in [\"rougeLsum\", \"bert_f1\"]:\n","      try:\n","        val = grouped.loc[(model, task, metric), \"mean\"]\n","        metrics_strings.append(str(round(val, 2)))\n","      except:\n","        print(f'Missing metric: {metric}, task: {task}, model: {model}')\n","\n","  try:\n","    val = grouped.loc[(model, 'biogr', \"iou\"), \"mean\"]\n","    metrics_strings.append(str(round(val, 2)))\n","  except:\n","    metrics_strings.append(\"-\")\n","  try:\n","    val = grouped.loc[(model, 'pdb', \"identity_ratio\"), \"mean\"]\n","    metrics_strings.append(str(round(val, 2)))\n","  except:\n","    metrics_strings.append(\"-\")\n","\n","  return \"& \" + \" & \".join(metrics_strings) + \" \\\\\\\\\\n\"\n","\n","\n","# Begin LaTeX table\n","latex = \"\"\"\n","\\\\begin{table*}[!t]\n","\n","\\centering\n","\n","\\small\n","\\setlength{\\\\tabcolsep}{4pt}\n","\\\\resizebox{\\\\textwidth}{!}{\\\\begin{tabular}{l | c c | c c |c c | c c | c c | c c | c | c }\n","\n","\\\\toprule\n","\n","\\multirow{2}{*}{\\\\bf Method} & \\multicolumn{2}{c|}{\\\\bf \\data\\ DFT} & \\multicolumn{2}{c|}{\\\\bf \\data\\ MPV} &\n","\\multicolumn{2}{c|}{\\\\bf \\data\\ HFD} &\n","\\multicolumn{2}{c|}{\\\\bf \\data\\ HFE} &\n","\\multicolumn{2}{c|}{\\\\bf \\data\\ QECC} &\n","\\multicolumn{2}{c|}{\\\\bf \\data\\ GEO} &\n","{\\\\bf \\data\\ BIOGR} &\n","{\\\\bf \\data\\ PDB}\n","\\\\\\\\\n","\n","& R-L & B-F1 & R-L & B-F1 & R-L & B-F1 & R-L & B-F1 & R-L & B-F1 & R-L & B-F1 & IoU & ID_{r} \\\\\\\\\n","\n","\\midrule\n","\\multicolumn{15}{c}{\\\\textit{Zero-shot Open Weight LLMs}} \\\\\\\\\n","\\midrule\n","\n","Mixtral % \\cite{Mixtral}\n","\"\"\"\n","latex += print_row('mixtral-gcp')\n","\n","latex += \"Command-R$+$ %\\cite{CommandR+} \\n\"\n","latex += print_row('command-r-plus')\n","\n","latex += \"LongLLaMa %\\cite{LongLLaMa} \\n\"\n","latex += print_row('longllama')\n","\n","latex += \"\"\"\\n\n","\\\\midrule\n","\\multicolumn{15}{c}{\\\\textit{Zero-shot Closed Weight LLMs}} \\\\\\\\\n","\\midrule\n","\n","\n","%Gemini 1.0 Pro \\cite{team2023gemini1.0} \\\\\n","Gemini 1.0 Pro %\\cite{team2023gemini}\n","\"\"\"\n","latex += print_row('gemini-1.0-pro')\n","latex += \"GPT-4o %\\cite{gpt4orelease} \\n\"\n","latex += print_row('gpt-4o')\n","latex += \"Gemini 1.5 Pro %\\cite{reid2024gemini1.5} \\n\"\n","latex += print_row('gemini-1.5-pro-latest')\n","latex += \"Gemini 1.5 Flash %\\cite{reid2024gemini1.5} \\n\"\n","latex += print_row('gemini-1.5-flash-latest')\n","latex += \"Claude 3 (Opus) %\\cite{claude3} \\n\"\n","latex += print_row('claude-3-opus-20240229')\n","latex += \"\"\"\n","\\\\bottomrule\n","\\end{tabular}}\n","\\\\vspace{-2mm}\n","\\caption{\\\\textbf{Results comparing performance of all models on all tasks based on automated metrics} R-L: Rouge-L, and B-F1:BertScore-F1. The avg. performance of all 3 DFT tasks are reported under DFT. All models support a context length of 32k or more. BIOGR has multimodal inputs which is unsupported by the chosen open models. Blue highlights the highest values.}\n","\\label{tab:main_results}\n","\\\\vspace{-3mm}\n","\\end{table*}\"\"\"\n","\n","print(latex)"]},{"cell_type":"markdown","metadata":{"id":"XBkxMcS9M2--"},"source":["## Table 2"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Hs5FHTC2M4nt"},"outputs":[],"source":["TASKS_2_METRICS = {\n","    (\"dft\", \"extract_structure_data_1_shot\"): [\n","        \"LMSim-F1\",\n","        \"LMSim-Pr\",\n","        \"LMSim-Re\",\n","    ],\n","    (\"dft\", \"extract_dft_metadata_1_shot\"): [\n","        \"LMSim-F1\",\n","        \"LMSim-Pr\",\n","        \"LMSim-Re\",\n","    ],\n","    (\"mpv\", \"mat_paper_to_property_1_shot\"): [\n","        \"LMSim-F1\",\n","        \"LMSim-Pr\",\n","        \"LMSim-Re\",\n","    ],\n","    (\"mpv\", \"mat_paper_to_property_1_shot_exclude_trivia\"): [\n","        \"LMSim-F1\",\n","        \"LMSim-Pr\",\n","        \"LMSim-Re\",\n","    ],\n","    (\"mpv\", \"mat_paper_to_property_1_shot_bandgap_refractive\"): [\n","        \"LMSim-F1\",\n","        \"LMSim-Pr\",\n","        \"LMSim-Re\",\n","    ],\n","}\n","\n","all_results = json5.load(open(meta_results_path, \"r\"))\n","df = pd.json_normalize(all_results, sep=\"$$\").transpose()\n","\n","\n","# Add separe columns for task, model, example, metric, and value\n","df[\"task\"] = df.apply(lambda x: x.name.split(\"$$\")[0], axis=1)\n","df[\"prompt\"] = df.apply(lambda x: x.name.split(\"$$\")[1], axis=1)\n","df[\"model\"] = df.apply(lambda x: x.name.split(\"$$\")[2], axis=1)\n","df[\"example\"] = df.apply(lambda x: x.name.split(\"$$\")[3], axis=1)\n","df[\"metric\"] = df.apply(extract_metric, axis=1)\n","df[\"value\"] = df[0]\n","\n","# # Update the namings\n","df[\"task\"] = df[\"task\"].str.replace(\"mpve\", \"mpv\")\n","\n","\n","df[\"task_prompt\"] = df.apply(lambda x: \"_\".join([x.task, x.prompt]), axis=1)\n","df[\"task_prompt_metric\"] = df.apply(\n","    lambda x: \"_\".join([x.task, x.prompt, x.metric]), axis=1\n",")\n","\n","df_len = len(df)\n","\n","# Delete extra tasks, prompts, and metrics\n","task_prompt_metric_keep = []\n","for (task, prompt), metrics in TASKS_2_METRICS.items():\n","  for metric in metrics:\n","    task_prompt_metric_keep.append(\"_\".join([task, prompt, metric]))\n","\n","df = df.drop(df[~df[\"task_prompt_metric\"].isin(task_prompt_metric_keep)].index)\n","print(f\"{df_len-len(df)} rows contain extra tasks and are dropped.\")\n","df_len = len(df)\n","\n","\n","print(f\"The final dataframe has {len(df)} rows.\")\n","\n","grouped = (\n","    df.groupby([\"model\", \"task_prompt\", \"metric\"])[\"value\"]\n","    .agg([\"mean\", \"std\"])\n","    .fillna(0)\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Oq3xtjgDM90E"},"outputs":[],"source":["# Generate a LaTeX table for precision, recall, and F1 score.\n","\n","def print_row(model):\n","  metrics_strings = []\n","  for task_prompt in [\n","      \"dft_extract_structure_data_1_shot\",\n","      \"dft_extract_dft_metadata_1_shot\",\n","      \"mpv_mat_paper_to_property_1_shot\",\n","      \"mpv_mat_paper_to_property_1_shot_exclude_trivia\",\n","      \"mpv_mat_paper_to_property_1_shot_bandgap_refractive\",\n","  ]:\n","    for metric in [\"LMSim-Pr\", \"LMSim-Re\", \"LMSim-F1\"]:\n","      try:\n","        val = grouped.loc[(model, task_prompt, metric), \"mean\"]\n","        metrics_strings.append(str(round(100*val, 2)))\n","      except:\n","        print(f'Missing metric: {metric}, task_prompt: {task_prompt}, model: {model}')\n","\n","  return \"& \" + \" & \".join(metrics_strings) + \" \\\\\\\\\\n\"\n","\n","\n","# Begin LaTeX table\n","latex = \"\"\"\n","\\\\begin{table*}[!th]\n","\\centering\n","\\small\n","\\setlength{\\\\tabcolsep}{4pt}\n","\\\\resizebox{\\\\textwidth}{!}{\\\\begin{tabular}{l | c c c | c c c |c c c | c c c | c c c }\n","\\\\toprule\n","\n","\\multirow{2}{*}{\\\\bf Model} &\n","\\multicolumn{3}{c|}{\\\\bf \\data\\ DFT-S} &\n","\\multicolumn{3}{c|}{\\\\bf \\data\\ DFT-P} &\n","\\multicolumn{3}{c|}{\\\\bf \\data\\ MPV} &\n","\\multicolumn{3}{c|}{\\\\bf \\data\\ MPV-non-trivial} &\n","\\multicolumn{3}{c}{\\\\bf \\data\\ MPV-specific}\n","\\\\\\\\\n","\n","& Pr. & Rec. & F1 & Pr. & Rec. & F1 & Pr. & Rec. & F1 & Pr. & Rec. & F1 & Pr. & Rec. & F1  \\\\\\\\\n","\n","\\midrule\n","\\multicolumn{15}{c}{\\\\textit{Zero-shot Open Weight LLMs}} \\\\\\\\\n","\\midrule\n","Mixtral %\\cite{Mixtral}\n","\"\"\"\n","latex += print_row('mixtral-gcp')\n","\n","latex += \"Command-R$+$ %\\cite{CommandR+} \\n\"\n","latex += print_row('command-r-plus')\n","\n","latex += \"LongLLaMa %\\cite{LongLLaMa} \\n\"\n","latex += print_row('longllama')\n","\n","latex += \"\"\"\\n\n","\\\\midrule\n","\\multicolumn{15}{c}{\\\\textit{Zero-shot Closed Weight LLMs}} \\\\\\\\\n","\\midrule\n","\n","\n","%Gemini 1.0 Pro \\cite{team2023gemini1.0} \\\\\n","Gemini 1.0 Pro %\\cite{team2023gemini}\n","\"\"\"\n","latex += print_row('gemini-1.0-pro')\n","latex += \"GPT-4o %\\cite{gpt4orelease} \\n\"\n","latex += print_row('gpt-4o')\n","latex += \"Gemini 1.5 Pro %\\cite{reid2024gemini1.5} \\n\"\n","latex += print_row('gemini-1.5-pro-latest')\n","latex += \"Gemini 1.5 Flash %\\cite{reid2024gemini1.5} \\n\"\n","latex += print_row('gemini-1.5-flash-latest')\n","latex += \"Claude 3 (Opus) %\\cite{claude3} \\n\"\n","latex += print_row('claude-3-opus-20240229')\n","latex += \"\"\"\n","\\\\bottomrule\n","\\end{tabular}}\n","\\\\vspace{-1.5mm}\n","\\caption{\\\\textbf{Comparing performance using \\lmsim.} On sub-tasks requiring exhaustive retrieval of information we use \\lmsim \\ based similarity to compute compute F1 scores for finer grained assessment on materials science. We also include 2 ablations for the MPV task where we ask the LLM to retrieve non-trivial or specific property values (refractive index and optical bandgap) for materials. Command-R$+$ responses on MPV papers were incomplete leading to invalid json dictionaries. We find the precision and recall values to match human evaluations on the MPV tasks for Gemini 1.5 pro and GPT-4o.}\n","\\label{tab:matsci_results}\n","\\\\vspace{-2mm}\n","\\end{table*}\"\"\"\n","\n","print(latex)"]},{"cell_type":"markdown","metadata":{"id":"DqSIhPMCNG_R"},"source":["# Figures"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jnyJxaZigDPC"},"outputs":[],"source":["# Assuming that the first metric in the list of metric in TASKS_2_METRICS is\n","# the main score value\n","\n","TASKS_2_METRICS = {\n","    (\"dft\", \"extract_structure_data_1_shot\"): [\"LMSim-F1\", \"LMSim-Pr\", \"LMSim-Re\", \"rougeLsum\", \"bert_f1\"],\n","    (\"dft\", \"extract_dft_metadata_1_shot\"): [\"LMSim-F1\", \"LMSim-Pr\", \"LMSim-Re\", \"rougeLsum\", \"bert_f1\"],\n","    (\"dft\", \"write_code_for_paper_0_shot\"): [\"rougeLsum\", \"bert_f1\"],\n","    (\"mpv\", \"mat_paper_to_property_1_shot\"): [\"LMSim-F1\", \"LMSim-Pr\", \"LMSim-Re\", \"rougeLsum\", \"bert_f1\"],\n","    (\"hfd\", \"derivation_prompt\"): [\"rougeLsum\", \"bert_f1\"],\n","    (\"hfe\", \"extract_hamiltonian_0_shot\"): [\"rougeLsum\", \"bert_f1\"],\n","    (\"qecc_65\", \"describe_code_in_paper\"): [\"rougeLsum\", \"bert_f1\"],\n","    (\"geo\", \"extract_dataset_from_geo_papers_0_shot\"): [\"rougeLsum\", \"bert_f1\"],\n","    (\"biogr\", \"georeference_image_0_shot\"): [\"iou\"],\n","    (\"pdb\", \"reconstruct_protein_amino_acid_sequence_0_shot\"): [\n","        \"identity_ratio\"\n","    ],\n","}\n","TASKS_2_TITLES = {\n","    \"dft\": \"DFT\",\n","    \"mpv\": \"MPVE\",\n","    \"hfd\": \"HFD\",\n","    \"hfe\": \"HFE\",\n","    \"qecc_65\": \"QECC\",\n","    \"geo\": \"GEO\",\n","    \"biogr\": \"BIOGR\",\n","    \"pdb\": \"PDB\",\n","}\n","\n","GEO_BAD_LICENSE = [\n","    \"4d5c098bd142b2356e5485f7e3786255aa636073\",\n","    \"40cb6b737064b0881c536512d61817dbe79a3da4\",\n","    \"bb871818b3e903ba70b5e90929a575cd018e0b2b\",\n","    \"cea27d393e1b9dcfab5f8f9f2fbd33e5bdd96e76\",\n","    \"e10fd24fe75f5c10d54698a0d141dc9151cb2535\",\n","    \"32ecb10ab170fa193ea879e1f63ce8ae5d7b9f34\",\n","    \"bfde3d73c1df8980a0c3915e627236ce818d42c7\",\n","    \"00f8c2660ea4795d25e8e801fc831bb9dcf64022\",\n","    \"5a7a518d77aee623be48bbee6538fdbd77c26238\",\n","    \"375bbe6ac4c3f3c16ddddaea2464f9f2e112e00a\",\n","    \"8349632fbb06bbce22012097f1030d1c53a8e57b\",\n","    \"467f0fdc420f5cd8996c0b2b1eb33a3dcda93c5e\",\n","    \"5c0e2e83c0d8d4e5d86ab77bea49c62ac77ab9e9\",\n","]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ud8Te3GAQoMp"},"outputs":[],"source":["# Load the meta_results.json and convert it to dataframe\n","\n","all_results = json5.load(open(meta_results_path, 'r'))\n","df = pd.json_normalize(all_results, sep='$$').transpose()\n","\n","# Add separe columns for task, model, example, metric, and value\n","df['task'] = df.apply(lambda x: x.name.split('$$')[0], axis=1)\n","df['prompt'] = df.apply(lambda x: x.name.split('$$')[1], axis=1)\n","df['model'] = df.apply(lambda x: x.name.split('$$')[2], axis=1)\n","df['example'] = df.apply(lambda x: x.name.split('$$')[3], axis=1)\n","df[\"metric\"] = df.apply(extract_metric, axis=1)\n","df['value'] = df[0]\n","\n","# Update the namings\n","df['task'] = df['task'].str.replace('mpve', 'mpv')\n","df['model'] = df['model'].str.replace('gpt-4o', 'GPT-4o')\n","df['model'] = df['model'].str.replace('claude-3-opus-20240229', 'Claude 3 (Opus)')\n","df['model'] = df['model'].str.replace('gemini-1.5-pro-latest', 'Gemini 1.5 Pro')\n","df['model'] = df['model'].str.replace('gemini-1.0-pro', 'Gemini 1.0 Pro')\n","df['model'] = df['model'].str.replace('gemini-1.5-flash-latest', 'Gemini 1.5 Flash')\n","df['model'] = df['model'].str.replace('longllama', 'LongLLaMA')\n","df['model'] = df['model'].str.replace('mixtral-gcp', 'Mixtral-8x7b')\n","df['model'] = df['model'].str.replace('command-r-plus', 'Command R+')\n","\n","df['task_prompt'] = df.apply(lambda x: '_'.join([x.task, x.prompt]), axis=1)\n","df['task_prompt_metric'] = df.apply(lambda x: '_'.join([x.task, x.prompt, x.metric]), axis=1)\n","\n","df_len = len(df)\n","print(f'The dataframe has \\033[1m{df_len}\\033[0m rows.')\n","\n","# Delete extra tasks, prompts, and metrics\n","task_prompt_metric_keep = []\n","for (task, prompt), metrics in TASKS_2_METRICS.items():\n","  for metric in metrics:\n","    task_prompt_metric_keep.append('_'.join([task, prompt, metric]))\n","\n","df = df.drop(df[~df['task_prompt_metric'].isin(task_prompt_metric_keep)].index)\n","print(f'\\033[1m{df_len-len(df)}\\033[0m rows contain extra tasks/prompts/metrics and are dropped.')\n","df_len = len(df)\n","\n","# Delete non numerical entries\n","df = df[pd.to_numeric(df['value'], errors='coerce').notnull()]\n","print(f'\\033[1m{df_len-len(df)}\\033[0m rows contain non numerical entries and are dropped.')\n","df_len = len(df)\n","\n","# Delete geo examples with license issues\n","df = df.drop(df[df['example'].isin(GEO_BAD_LICENSE)].index)\n","print(f'\\033[1m{df_len-len(df)}\\033[0m rows contain license issues and are dropped.')\n","df_len = len(df)\n","\n","# Divide the RougeLsum by 100\n","df.loc[df['metric'] == 'rougeLsum', 'value'] /= 100\n","\n","print(f'The final dataframe has \\033[1m{len(df)}\\033[0m rows.')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vRSJhxi2m8Iv"},"outputs":[],"source":["# Sanity check: Count the number of examples for each task\n","counts =df.groupby('task').count()\n","\n","# Assert all the tasks in TASKS_2_METRICS exist in the df\n","assert set(counts.index.tolist()) == set([i[0] for i in TASKS_2_METRICS.keys()])\n","\n","counts"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XMmGzF73nAQ5"},"outputs":[],"source":["# Sanity check: Check the values of unique metrics for each task\n","\n","df.groupby('task')['metric'].unique()"]},{"cell_type":"markdown","metadata":{"id":"2lKM8mtuaSMt"},"source":["## Figure 6: barplots for all tasks"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pk3LfaspSmwq"},"outputs":[],"source":["model_order = [\n","    'Claude 3 (Opus)',\n","    'Gemini 1.5 Pro',\n","    'GPT-4o',\n","    'Gemini 1.5 Flash',\n","    'Gemini 1.0 Pro',\n","    'Command R+',\n","    'Mixtral-8x7b',\n","    'LongLLaMA',\n","]\n","palette = [\n","    '#D9886C',\n","    '#E7B7A0',\n","    '#B3D1DF',\n","    '#89A8C0',\n","    '#6DA78B',\n","    '#346A67',\n","    '#E0C085',\n","    '#C49B3C',\n","]\n","\n","palette2 = [\n","    '#58508d',\n","    '#bc5090',\n","    '#ff6361',\n","    '#ffa600',\n","]\n","\n","palette3 = [\n","    '#BA68C8',\n","    '#7986CB',\n","    '#B2DFDB',\n","]\n","\n","TASKS_2_METRICS_FIGS = {\n","    \"dft\": \"rougeLsum\",\n","    \"mpv\": \"rougeLsum\",\n","    \"hfd\": \"rougeLsum\",\n","    \"hfe\": \"rougeLsum\",\n","    \"qecc_65\": \"rougeLsum\",\n","    \"geo\": \"rougeLsum\",\n","    \"biogr\": \"iou\",\n","    \"pdb\": \"identity_ratio\",\n","}\n","\n","palette4 = [\n","    '#ffa600',\n","    '#58508d',\n","    '#bc5090',\n","    '#ff6361',\n","    '#7986CB',\n","    '#B2DFDB',\n","]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"D964bMCMFNl7"},"outputs":[],"source":["label_font_size = 16\n","tick_label_size = 14\n","legend_font_size = 14\n","\n","def plot_metric(metric, df, ylim=None):\n","  sns.set_theme(style='whitegrid')\n","  df_metric = df[df['metric'] == metric]\n","  df_metric[metric] = df_metric['value']\n","\n","  plt.figure(figsize=(20, 6))\n","\n","  ax = sns.barplot(\n","      x='task',\n","      y=metric,\n","      estimator=pd.Series.mean,\n","      errorbar=('pi', 50),\n","      data=df_metric,\n","      hue='model',\n","      palette=palette,\n","      capsize=0.05,\n","      errwidth=0.75,\n","      hue_order=model_order,\n","      order=TASKS_2_TITLES.keys()\n","  )\n","\n","  ax.set_xlabel('Task', fontsize=label_font_size)\n","  ax.set_ylabel('Score', fontsize=label_font_size)\n","  ax.tick_params(labelsize=tick_label_size)\n","  ax.set_xticklabels(TASKS_2_TITLES.values(), rotation=0)\n","\n","  # Add hatch patterns to specific bars\n","  bars = ax.patches\n","  num_hatches = len(df['task'].unique())\n","  hatches = (\n","      ['o'] * num_hatches\n","      + [''] * num_hatches\n","      + [''] * num_hatches\n","      + [''] * num_hatches\n","      + ['//'] * num_hatches\n","      + [''] * num_hatches\n","      + ['\\\\'] * num_hatches\n","  )\n","\n","  for bar, hatch in zip(bars, hatches):\n","    bar.set_hatch(hatch)\n","\n","  plt.legend(loc='upper left', bbox_to_anchor=(1, 1))\n","  if ylim is not None:\n","    plt.ylim([0, ylim])\n","\n","  plt.show()\n","\n","def plot_score(df, ylim=None):\n","  sns.set_theme(style='whitegrid')\n","\n","  df_list = []\n","  for task, metric in TASKS_2_METRICS_FIGS.items():\n","    df_list.append(df[(df['task'] == task) & (df['metric'] == metric)])\n","  df_score = pd.concat(df_list)\n","  df_score['Score'] = df_score['value']\n","\n","\n","  plt.figure(figsize=(20, 6))\n","\n","  ax = sns.barplot(\n","      x='task',\n","      y='Score',\n","      estimator=pd.Series.mean,\n","      errorbar=('pi', 50),\n","      data=df_score,\n","      hue='model',\n","      palette=palette,\n","      capsize=0.05,\n","      errwidth=0.75,\n","      hue_order=model_order,\n","      order=TASKS_2_TITLES.keys()\n","  )\n","\n","  ax.set_xlabel('Task', fontsize=label_font_size)\n","  ax.set_ylabel('Score', fontsize=label_font_size)\n","  ax.tick_params(labelsize=tick_label_size)\n","  ax.set_xticklabels(TASKS_2_TITLES.values(), rotation=0)\n","\n","  # Add hatch patterns to specific bars\n","  bars = ax.patches\n","  num_hatches = len(df['task'].unique())\n","  hatches = (\n","      ['o'] * num_hatches\n","      + [''] * num_hatches\n","      + [''] * num_hatches\n","      + [''] * num_hatches\n","      + ['//'] * num_hatches\n","      + [''] * num_hatches\n","      + ['\\\\'] * num_hatches\n","  )\n","\n","  for bar, hatch in zip(bars, hatches):\n","    bar.set_hatch(hatch)\n","\n","  plt.legend(loc='upper left', ncol=8)\n","  if ylim is not None:\n","    plt.ylim([0, ylim])\n","\n","  plt.savefig('Figure_6.png', format='png', dpi=300)\n","  plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7ypnP0_za5bf"},"outputs":[],"source":["plot_score(df, 0.9)"]},{"cell_type":"markdown","metadata":{"id":"fhQwh6vrkwgY"},"source":["## Figure 2: average over tasks"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6HxEeyeRcice"},"outputs":[],"source":["df_list = []\n","for task, metric in TASKS_2_METRICS_FIGS.items():\n","  df_list.append(df[(df['task'] == task) & (df['metric'] == metric)])\n","df_score = pd.concat(df_list)\n","df_score['Score'] = df_score['value']\n","\n","df_mean = df_score.groupby(['model', 'task'])['Score'].agg([\"mean\"]).unstack()\n","df_mean['Average Score'] = df_mean.mean(axis=1)\n","df_mean['model'] = df_mean.index\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ANx0KgXIebyH"},"outputs":[],"source":["# If a cell is NaN, we don't have any prediction for that domain with the model.\n","df_mean"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"m3NCnQcqmmUw"},"outputs":[],"source":["ax = sns.barplot(\n","    x='Average Score',\n","    y='model',\n","    data=df_mean,\n","    palette=palette,\n","    order=model_order,\n",");\n","\n","ax.set_ylabel('', fontsize=label_font_size)\n","ax.set_xlabel('Average Score', fontsize=label_font_size)\n","ax.tick_params(labelsize=tick_label_size)\n","plt.xlim([0, 0.3])\n","plt.xticks(fontsize=12)\n","plt.tight_layout()\n","plt.savefig('Figure_2.png', format='png', dpi=300)\n","plt.show()\n"]},{"cell_type":"markdown","metadata":{"id":"ZTAWck-Hq_ja"},"source":["## Figure 1: Compare Gemini 1.0 vs Gemini 1.5 on other benchmarks"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LTsQvB1MnZbi"},"outputs":[],"source":["# https://storage.googleapis.com/deepmind-media/gemini/gemini_v1_5_report.pdf\n","\n","metrics = {\n","    1:{\n","        'Model': 'Gemini 1.0 Pro',\n","        'CURIE': float(df_mean[df_mean['model'] == 'Gemini 1.0 Pro'][\n","            'Average Score'\n","        ].values[0]) * 100,\n","        'DROP': 74.9,  # Variable shots,\n","        'GPQA': 27.9,  # 4-shot,\n","        'MMLU': 71.8,  # 5-shot,\n","    },\n","    2:{\n","        'Model': 'Gemini 1.5 Pro',\n","        'CURIE': float(df_mean[df_mean['model'] == 'Gemini 1.5 Pro'][\n","            'Average Score'\n","        ].values[0]) * 100,\n","        'DROP': 74.1,  # Variable shots,\n","        'GPQA': 46.2,  # 0-shot,\n","        'MMLU': 85.9,  # 5-shot,\n","    },\n","}\n","\n","other_benchmarks = pd.DataFrame(metrics).transpose()"]},{"cell_type":"code","source":["# https://storage.googleapis.com/deepmind-media/gemini/gemini_v1_5_report.pdf\n","\n","metrics = {\n","    1:{\n","        'Model': 'Claude 3 (Opus)',\n","        'CURIE': float(df_mean[df_mean['model'] == 'Claude 3 (Opus)'][\n","            'Average Score'\n","        ].values[0]) * 100,\n","        'ZeroScrolls': 39.07,  # Variable shots,\n","        'GPQA': 50.4,  # 4-shot,\n","        'MMLU-pro': 76.12,  # 5-shot,\n","        'MathVista': 50.5,\n","        'RULER': 89,\n","    },\n","    2:{\n","        'Model': 'Gemini 1.5 Pro',\n","        'CURIE': float(df_mean[df_mean['model'] == 'Gemini 1.5 Pro'][\n","            'Average Score'\n","        ].values[0]) * 100,\n","        'ZeroScrolls': np.nan,\n","        'GPQA': 46.2,  # 4-shot,\n","        'MMLU-pro': 69.03,  # 5-shot,\n","        'MathVista': 63.9,\n","        'RULER': 95.5,\n","    },\n","    3:{\n","        'Model': 'GPT-4o',\n","        'CURIE': float(df_mean[df_mean['model'] == 'GPT-4o'][\n","            'Average Score'\n","        ].values[0]) * 100,\n","        'ZeroScrolls': 41.67,  # Variable shots,\n","        'GPQA': 50.4,  # 4-shot,\n","        'MMLU-pro': 76.12,  # 5-shot,\n","        'MathVista': 50.5,\n","        'RULER': np.nan\n","    },\n","}\n","\n","other_benchmarks = pd.DataFrame(metrics).transpose()"],"metadata":{"id":"YMowdBZ94J_5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_mean['model']"],"metadata":{"id":"cmsPMG3A_zmB"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bKCvdjJKwjhI"},"outputs":[],"source":["other_benchmarks"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LadlBQxpyK0s"},"outputs":[],"source":["other_benchmarks = other_benchmarks.melt(\n","    id_vars=['Model'], var_name='Benchmark', value_name='Score'\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hEC6rAc5nuCh"},"outputs":[],"source":["ax = sns.barplot(\n","    y='Score',\n","    hue='Benchmark',\n","    x='Model',\n","    data=other_benchmarks,\n","    palette=palette4,\n","    hue_order=['CURIE', 'ZeroScrolls', 'GPQA', 'MathVista', 'MMLU-pro', 'RULER'  ],\n",")\n","\n","# Get the legend handles and labels\n","handles, labels = plt.gca().get_legend_handles_labels()\n","\n","# Modify the legend labels\n","labels_info = {'RULER': 'Long Context', 'MMLU-pro': 'Understanding', 'MathVista': 'Reasoning in Visual Context', 'GPQA': 'Science Expertise', 'ZeroScrolls': \"Long Context\", 'CURIE':'Science + Long Context (ours)'}\n","labels = [f'{l}: {labels_info[l]}' for l in labels]\n","\n","# Set the legend labels\n","plt.legend(handles, labels, loc='upper center', ncol=2, bbox_to_anchor=(0.5, 1.35),  borderaxespad=0.)\n","plt.xlabel('')\n","\n","plt.tight_layout()\n","\n","plt.savefig('Figure_1.png', format='png', dpi=300)\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"kqbyxXnzLMMg"},"source":["## Figure 8: separate results by difficulty levels"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EfEePOlyLMAg"},"outputs":[],"source":["import json5\n","import pandas as pd"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yEOH5Ps-MFLS"},"outputs":[],"source":["# Load the difficulty level json file\n","\n","difficulty_json = json5.load(\n","    open(\n","        f\"{BASEDIR}/data/difficulty_levels.json\"\n","    )\n",")\n","\n","df_lists = []\n","for task, difficulties in difficulty_json.items():\n","  df_diff = pd.DataFrame(difficulties, index=['difficulty']).transpose()\n","  df_diff['task'] = len(df_diff) * [task]\n","  df_diff['example'] = df_diff.index\n","  df_diff = df_diff.reset_index()\n","  df_diff = df_diff.drop(columns=['index'])\n","  df_lists.append(df_diff)\n","\n","df_diff = pd.concat(df_lists)\n","df_diff = df_diff.replace('qecc_85', 'qecc_65')\n","df_diff = df_diff.replace('mpve', 'mpv')\n","df_diff['task_example'] = df_diff.apply(\n","    lambda x: x['task'] + '_' + x['example'], axis=1\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ov3TIaBHQzKF"},"outputs":[],"source":["# Add difficulty levels to the df_score\n","\n","df_score['task_example'] = df_score.apply(\n","    lambda x: x['task'] + '_' + x['example'], axis=1\n",")\n","df_score = df_score.merge(df_diff, on=['task_example'], how='left')\n","\n","# Quick check that they merged properly\n","collections.Counter(list(df_score['difficulty']))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tsXebTV3LUNc"},"outputs":[],"source":["# Average scores over all tasks, separated by example difficulties\n","df_score['difficulty'] = df_score['difficulty'].apply(lambda x: x.lower())\n","df_mean_hard = df_score[df_score['difficulty']=='hard'].groupby(['model', 'task_x'])['Score'].agg([\"mean\"]).unstack()\n","df_mean_hard['Average Score'] = df_mean_hard.mean(axis=1)\n","df_mean_hard['model'] = df_mean_hard.index\n","\n","\n","df_mean_medium = df_score[df_score['difficulty']=='medium'].groupby(['model', 'task_x'])['Score'].agg([\"mean\"]).unstack()\n","df_mean_medium['Average Score'] = df_mean_medium.mean(axis=1)\n","df_mean_medium['model'] = df_mean_medium.index\n","\n","df_mean_easy = df_score[df_score['difficulty']=='easy'].groupby(['model', 'task_x'])['Score'].agg([\"mean\"]).unstack()\n","df_mean_easy['Average Score'] = df_mean_easy.mean(axis=1)\n","df_mean_easy['model'] = df_mean_easy.index"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"czeXOsZ4-P6D"},"outputs":[],"source":["df_mean = (\n","    df_score.groupby(['model', 'difficulty'])['Score']\n","    .agg(['mean'])\n","    .unstack()\n",")\n","\n","df_mean = df_mean.reset_index()\n","df_mean.columns = ['_'.join(x) for x in df_mean.columns]\n","df_mean.rename(columns={'model_': 'model', 'mean_easy': 'Easy', 'mean_medium': 'Medium', 'mean_hard': 'Hard'}, inplace=True)\n","\n","df_mean = df_mean.melt(\n","    id_vars=['model'],\n","    value_vars=['Easy', 'Medium', 'Hard'],\n","    var_name='difficulty',\n","    value_name='mean score',\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6k2HBIOXBqf0"},"outputs":[],"source":["plt.figure(figsize=(12, 5))\n","ax = sns.barplot(\n","    y='mean score',\n","    x='model',\n","    data=df_mean,\n","    palette=palette3,\n","    hue='difficulty',\n","    order=model_order,\n",")\n","plt.tight_layout()\n","plt.savefig('Figure_8.png', format='png', dpi=300)\n","plt.show()"]},{"cell_type":"markdown","source":["## Figure 35: identity ratio versus protein sequence length"],"metadata":{"id":"HqIAOnVGXYYj"}},{"cell_type":"code","source":["import os\n","import glob\n","df_pdb = df[df['task'] == 'pdb']"],"metadata":{"id":"f_BXQF4uXs11"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["gt_pattern = f\"{BASEDIR}/data/pdb/ground_truth/*.json\"\n","\n","gt_pdb = {}\n","for path in glob.glob(gt_pattern):\n","  example = os.path.basename(path).split('.json')[0]\n","  gt_pdb[example] = {'json': json5.load(open(path, 'r'))}\n","\n","for k, v in gt_pdb.items():\n","  v['sequence_length'] = len(v['json']['sequence'])\n","\n","df_pdb['sequence_length'] = df_pdb.apply(lambda x: gt_pdb[x['example']]['sequence_length'], axis=1)\n","df_pdb['sequence_length_bins'] = pd.qcut(df_pdb['sequence_length'], q=20)\n","plt.figure(figsize=(21, 7))\n","\n","sns.set_style('white')\n","plt.figure(figsize=(21, 7))\n","sns.set_style(\"darkgrid\")\n","sns.set(font_scale=1.5)\n","\n","sns.boxplot(\n","    df_pdb[df_pdb['metric'] == 'identity_ratio'],\n","    y='value',\n","    x='sequence_length_bins',\n",")\n","plt.ylim([0, 1])\n","plt.xticks(rotation=90)\n","plt.savefig('pdb_supp.png', format='png', bbox_inches='tight', dpi=300)\n","\n","plt.show()"],"metadata":{"id":"qlFge3AjGSAo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"g5Cigh8dYN-B"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"last_runtime":{"build_target":"","kind":"shared"},"private_outputs":true,"provenance":[{"file_id":"/piper/depot/google3/research/biology/collaborations/sci_asst/colabs/benchamark_paper_writing_helper.ipynb","timestamp":1725396000912},{"file_id":"1kVpGcgKbPgXsQTxmigipjN-ljPM5PT13","timestamp":1719886313973},{"file_id":"1rlruCg6PAYZnSEa96gGr2nonrSbokPur","timestamp":1719801054734},{"file_id":"1iKAX1S8xqdOYQ-xb5jsZ71Rawj-kFKWq","timestamp":1718492553434},{"file_id":"/piper/depot/google3/research/biology/collaborations/sci_asst/colabs/benchamark_paper_writing_helper.ipynb","timestamp":1717653306344},{"file_id":"/piper/depot/google3/research/biology/collaborations/sci_asst/colabs/benchamark_paper_writing_helper.ipynb?workspaceId=shamsiz:ag3::citc","timestamp":1717611597311},{"file_id":"/piper/depot/google3/research/biology/collaborations/sci_asst/colabs/benchamark_paper_writing_helper.ipynb","timestamp":1717544306678},{"file_id":"/piper/depot/google3/research/biology/collaborations/sci_asst/colabs/benchamark_paper_writing_helpers.ipynb?workspaceId=vsubhashini:textable::citc","timestamp":1717542909019},{"file_id":"1nSpN7dCWzccH7HOXdUnR8rusYJVIzbFE","timestamp":1717542719440},{"file_id":"/piper/depot/google3/research/biology/collaborations/sci_asst/colabs/benchamark_paper_writing_helper.ipynb","timestamp":1717471223674},{"file_id":"/piper/depot/google3/research/biology/collaborations/sci_asst/colabs/benchamark_paper_writing_helper.ipynb","timestamp":1717467236222},{"file_id":"12iBI1WxeWyladNhZrI7_jpDb6y6wzMyd","timestamp":1717110410072}],"toc_visible":true},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}