{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1mbYaiiytf-c7e8tNpzcppHwxks0_SuLb","timestamp":1717484837203},{"file_id":"1yVNLy6YKtkJwk4kdwcUW30Hrzt1tBJuk","timestamp":1717356613138},{"file_id":"1_mWSaqR67znLRx3euZmMcom3_3nChoNm","timestamp":1717352161145},{"file_id":"1upwIkRZsBsSQ9I7mc11bk6ClawYvG7dV","timestamp":1717298974033},{"file_id":"175zL8DNlwGQIko4nArl_YkMXc7nqsvZ_","timestamp":1717211525893},{"file_id":"1FU5niwb_mlb5nlu0wDV3L3P49tHBE5EP","timestamp":1717205296074},{"file_id":"1uOLJANGUtzmXHymtfJszovrHXeE4Pt0d","timestamp":1717190289746},{"file_id":"https://github.com/CStanKonrad/long_llama/blob/main/long_llama_instruct_colab.ipynb","timestamp":1716452980202}],"gpuType":"A100","machine_shape":"hm","private_outputs":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# Task: PDB\n","## Modifying LongLLaMA: Focused Transformer Training for Context Scaling\n","\n","**Original Notebook**: https://colab.research.google.com/github/CStanKonrad/long_llama/blob/main/long_llama_code_instruct_colab.ipynb\n","\n","\n","References:\n","* [LongLLaMA-Instruct-3Bv1.1](https://huggingface.co/syzymon/long_llama_3b_instruct)\n","* [FoT paper](https://arxiv.org/abs/2307.03170) and [GitHub repository](https://github.com/CStanKonrad/long_llama)"],"metadata":{"id":"blR8hhA_e-4S"}},{"cell_type":"markdown","source":["# Setup"],"metadata":{"id":"ZTROtgpafB_8"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"La3cPHfCe7hU"},"outputs":[],"source":["!pip install --upgrade pip\n","!pip install transformers==4.30.0  sentencepiece accelerate -q"]},{"cell_type":"code","source":["import numpy as np\n","import torch\n","from transformers import LlamaTokenizer, AutoModelForCausalLM, TextStreamer, PreTrainedModel, PreTrainedTokenizer\n","from typing import List, Optional\n","import os"],"metadata":{"id":"0x_utNYxfECA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["os.listdir(os.getcwd())"],"metadata":{"id":"2A0YH8yf4K_f"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["MODEL_PATH = (\n","    \"syzymon/long_llama_3b_instruct\"\n",")\n","TOKENIZER_PATH = MODEL_PATH\n","# to fit into colab GPU we will use reduced precision\n","TORCH_DTYPE = torch.bfloat16\n","\n","if torch.cuda.is_available():\n","    device = torch.device(\"cuda\")\n","else:\n","    device = torch.device(\"cpu\")"],"metadata":{"id":"LrrFlXKMfHMs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["device"],"metadata":{"id":"zVkJN0N96cPj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tokenizer = LlamaTokenizer.from_pretrained(TOKENIZER_PATH)\n","\n","model = AutoModelForCausalLM.from_pretrained(\n","    MODEL_PATH,\n","    torch_dtype=TORCH_DTYPE,\n","    device_map=device,\n","    trust_remote_code=True,\n","    # mem_attention_grouping is used\n","    # to trade speed for memory usage\n","    # for details, see the section Additional configuration\n","    mem_attention_grouping=(1, 2048),\n",")\n","model.eval()"],"metadata":{"id":"5fE5Z1ABfJUp"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Load Input Documents (usually Papers)"],"metadata":{"id":"ElblcG7MfOM4"}},{"cell_type":"code","source":["import os"],"metadata":{"id":"kP6dd87I78Yq"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Specify directory here"],"metadata":{"id":"SuZ0JisLWGs6"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"NyPVAae8USwJ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Specify paths containing the input JSONS and where the results should be saved."],"metadata":{"id":"v8XfPgoaXCSX"}},{"cell_type":"code","source":["# @title Input and Result Output Dirs\n","INPUT_RTDIR = '/content/drive/My Drive/local_benchmark/' # @param {type:\"string\"}\n","DIRPATH = '/content/drive/My Drive/local_benchmark/results/' # @param {type:\"string\"}"],"metadata":{"cellView":"form","id":"Yt4-kncbWlDU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["os.listdir(INPUT_RTDIR)"],"metadata":{"id":"63IT20cqWvUG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#DIRPATH = 'inference/t_1/'"],"metadata":{"id":"VBeWnZwG5ZsB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# @title Task Specific Config\n","TASK_NAME = \"pdb\" # @param {type:\"string\"}\n","PROMPT_NAME = \"reconstruct_protein_amino_acid_sequence_0_shot\" # @param {type:\"string\"}\n","PROMPT_PATH = PROMPT_NAME + \".txt\""],"metadata":{"id":"SNezBvLsPHh1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["INPUT_DIR= f'{INPUT_RTDIR}/{TASK_NAME}/inputs/'"],"metadata":{"id":"8zwTeM3Ajm3V"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Modifications for Paper, Prompt order:\n","* below are the tertiary structure -> The PROTEIN TERTIARY STRUCTURE is provided above.\n","* Append \"PROTEIN TERTIARY STRUCTURE\" to input['text']\n","* AMINO ACID SEQUENCE:"],"metadata":{"id":"PE6Bqaetd2vj"}},{"cell_type":"code","source":["PMODIFIED = \"\"\"You are a computational biologist and I want you to reconstruct a protein's amino acid sequence from its tertiary structure.\n","* The input is a PDB that is a textual format describing the three-dimensional structures of a protein.\n","* Return the amino acid sequence in the standard FASTA format, which starts with a definition line with the greater than (>) line,\n","  followed by the single-letter codes for all amino acids in the second line.\n","* Make sure the amino acid sequence is in the second line.\n","* If there is an unknown amino acid in the structure, put \"X\" in the sequence.\n","* Make sure you go through the whole structure and get all the amino acids.\n","* No extra explanation is needed.\n","\n","The PROTEIN TERTIARY STRUCTURE is provided above.\n","\n","AMINO ACID SEQUENCE:\n","\"\"\""],"metadata":{"id":"k0K5cMNCd2vj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["PREFIX = \"PROTEIN TERTIARY STRUCTURE: \""],"metadata":{"id":"oY5CI6E0Es-p"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import json\n","import os"],"metadata":{"id":"1nb9zULE8lE2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["os.listdir(INPUT_DIR), len(os.listdir(INPUT_DIR))"],"metadata":{"id":"_pqlrcjo2JFn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def get_paper_list(inputdir):\n","  files = os.listdir(inputdir)\n","  papers = []\n","  for f in files:\n","    if f.endswith('.json'):\n","      papers.append(f[:f.rindex(\".json\")])\n","  return papers"],"metadata":{"id":"HssNqrtXcohP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# modified output dict metadata prep\n","def prepare_task_for_paper(paper: str, prompt_path: str, lm_id: str)-> dict[str, str]:\n","  paper_input = f'{INPUT_DIR}/{paper}.json'\n","  inputs = json.load(open(paper_input, 'r'))\n","\n","  return {'record_id': inputs['record_id'], 'model_id': lm_id, 'prompt_path': prompt_path,\n","          'prompt_text': PREFIX + inputs['text'] + PMODIFIED , 'response_text': ''}"],"metadata":{"id":"FiRm3uas3cp1"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Run on all sequences"],"metadata":{"id":"chPK2r8CfRcC"}},{"cell_type":"code","source":["from io import StringIO\n","import sys"],"metadata":{"id":"I1fDgI7d8Ai3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","#for the paper\n","@torch.no_grad()\n","def load_to_memory(model: PreTrainedModel, tokenizer: PreTrainedTokenizer, text: str):\n","    tokenized_data = tokenizer(text, return_tensors=\"pt\")\n","    input_ids = tokenized_data.input_ids\n","    input_ids = input_ids.to(model.device)\n","    # torch.manual_seed(0)\n","    output = model(input_ids=input_ids)\n","    memory = output.past_key_values\n","    return memory"],"metadata":{"id":"rt0PMfKDfLjy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["@torch.no_grad()\n","def generate_with_memory_new(\n","    model: PreTrainedModel, tokenizer: PreTrainedTokenizer, memory, prompt: str, temperature=1.0\n","):\n","    tokenized_data = tokenizer(prompt, return_tensors=\"pt\")\n","    input_ids = tokenized_data.input_ids\n","    input_ids = input_ids.to(model.device)\n","\n","    streamer = TextStreamer(tokenizer, skip_prompt=False)\n","\n","    new_memory = memory\n","\n","    catch_stout = StringIO()\n","    sys.stdout = catch_stout\n","\n","    stop = False\n","    while not stop:\n","        output = model(input_ids, past_key_values=new_memory)\n","        new_memory = output.past_key_values\n","        assert len(output.logits.shape) == 3\n","        assert output.logits.shape[0] == 1\n","        last_logit = output.logits[[0], [-1], :]\n","        dist = torch.distributions.Categorical(logits=last_logit / temperature)\n","        next_token = dist.sample()\n","        if next_token[0] == tokenizer.eos_token_id:\n","            streamer.put(next_token[None, :])\n","            streamer.end()\n","            stop = True\n","            # Restore stdout to its original state\n","            sys.stdout = sys.__stdout__\n","        else:\n","            input_ids = next_token[None, :]\n","            streamer.put(input_ids)\n","    return catch_stout.getvalue()"],"metadata":{"id":"5XUhGHsRz3gr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import inspect"],"metadata":{"id":"GzQ6C80W1120"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["PROMPT_PATH"],"metadata":{"id":"e1s0cYDQ6Dd1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def run_eval_loop(paper_list: List[str], results_dir: str, temperature: float):\n","  for PAPER in paper_list:\n","    print(PAPER)\n","    outpath = f'{results_dir}/{PAPER}.json'\n","    if os.path.exists(outpath):\n","      print(f'Skipping since result for {PAPER} already exists.')\n","    else:\n","      inputs = json.load(open(f'{INPUT_DIR}/{PAPER}.json', 'r'))\n","      out_dict = prepare_task_for_paper(paper=PAPER, prompt_path=PROMPT_PATH, lm_id=MODEL_PATH)\n","\n","      fot_memory = load_to_memory(model, tokenizer, PREFIX + inputs['text']) # loads the paper to memory\n","      answer = generate_with_memory_new(model, tokenizer, fot_memory, PMODIFIED, temperature) #asks the prompt after\n","      out_dict['response_text'] = answer\n","      json.dump(out_dict, open(outpath, 'w'))\n","  return"],"metadata":{"id":"ZMzjo3EycvHG"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["d: Which run (trial) this is. If you're running multiple trials of the same experiment."],"metadata":{"id":"8N1A5dRMOIq-"}},{"cell_type":"code","source":["# @title Specify Run_d here\n","trial = \"run_0\" # @param {type:\"string\"}\n","EXP_DIR = f\"{DIRPATH}/{TASK_NAME}/{PROMPT_NAME}/longllama/{trial}/success/\""],"metadata":{"id":"naUs15IAe1I1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(EXP_DIR)"],"metadata":{"id":"rq5XoUUjGl9C"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["os.makedirs(EXP_DIR, exist_ok=True)"],"metadata":{"id":"477c0EetJo7V"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["PAPERS = get_paper_list(INPUT_DIR)\n","print(len(PAPERS))"],"metadata":{"id":"v2Z4kTuMAuJA"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Now run on all papers"],"metadata":{"id":"87KhE0wcD8mD"}},{"cell_type":"code","source":["print(EXP_DIR)"],"metadata":{"id":"WZqxTT4RHeuj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["run_eval_loop(PAPERS, EXP_DIR, 1.0)"],"metadata":{"id":"ag2_yMVFHmlp"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Aside: Handling failures if any"],"metadata":{"id":"XSIB_1PYSIUv"}},{"cell_type":"code","source":["PAPERS_FAILED = ['18', '19', '20', '7', '14', '5', '21']"],"metadata":{"id":"dVCv4KCA2_m6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["PAPERS_SUCCESS = PAPERS.copy()\n","for p in PAPERS_FAILED:\n","  PAPERS_SUCCESS.remove(p)"],"metadata":{"id":"7BJPL0Xj3P_9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["len(PAPERS_SUCCESS)"],"metadata":{"id":"PRnpiRcQ3WNI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["torch.cuda.empty_cache()"],"metadata":{"id":"BNOg3JBnOwTw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["run_eval_loop(PAPERS_SUCCESS, EXP_DIR, 1.0)"],"metadata":{"id":"VJ4lSS3wLBtR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["PAPERS_SUCCESS"],"metadata":{"id":"GGOaUkMRM0_F"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["os.listdir(EXP_DIR)"],"metadata":{"id":"krFzGVOItsSv"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Render Outputs"],"metadata":{"id":"Z3laZTRma8Y2"}},{"cell_type":"code","source":["test_paper = PAPERS[2]"],"metadata":{"id":"yRZjD7VSC7or"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sd0 = json.load(open(f'{EXP_DIR}/{test_paper}.json', 'r'))"],"metadata":{"id":"wY69Uow0DnfH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sd0['response_text']"],"metadata":{"id":"DmEj1MD7D1vj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"UnEzLqukVUm2"},"execution_count":null,"outputs":[]}]}