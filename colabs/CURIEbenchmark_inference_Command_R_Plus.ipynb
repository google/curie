{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["## Notebook for processesing CURIE-benchmark tasks using the **Cohere Command-R Plus model**.\n"],"metadata":{"id":"fGW0Oeb2IxMX"}},{"cell_type":"code","source":["# @title Import Required Libraries\n","import os\n","import json\n","import pandas as pd\n","import numpy as np\n","import altair as alt\n","import logging\n","import textwrap as tr\n","import torch\n","from google.colab import drive\n","from tenacity import retry, stop_after_attempt, wait_exponential\n","import time\n","from dataclasses import dataclass\n","from typing import Optional, Dict, List\n","from enum import Enum"],"metadata":{"id":"8rsiVfsTG-A-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# @title Install and import Cohere\n","! pip install -U cohere\n","import cohere"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aYK7SbWtG-vu","outputId":"bbef8713-ef2b-49c0-8590-c24cc8ca5216"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting cohere\n","  Downloading cohere-5.13.4-py3-none-any.whl.metadata (3.4 kB)\n","Collecting fastavro<2.0.0,>=1.9.4 (from cohere)\n","  Downloading fastavro-1.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.5 kB)\n","Requirement already satisfied: httpx>=0.21.2 in /usr/local/lib/python3.10/dist-packages (from cohere) (0.28.1)\n","Collecting httpx-sse==0.4.0 (from cohere)\n","  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n","Collecting parameterized<0.10.0,>=0.9.0 (from cohere)\n","  Downloading parameterized-0.9.0-py2.py3-none-any.whl.metadata (18 kB)\n","Requirement already satisfied: pydantic>=1.9.2 in /usr/local/lib/python3.10/dist-packages (from cohere) (2.10.3)\n","Requirement already satisfied: pydantic-core<3.0.0,>=2.18.2 in /usr/local/lib/python3.10/dist-packages (from cohere) (2.27.1)\n","Requirement already satisfied: requests<3.0.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from cohere) (2.32.3)\n","Requirement already satisfied: tokenizers<1,>=0.15 in /usr/local/lib/python3.10/dist-packages (from cohere) (0.21.0)\n","Collecting types-requests<3.0.0,>=2.0.0 (from cohere)\n","  Downloading types_requests-2.32.0.20241016-py3-none-any.whl.metadata (1.9 kB)\n","Requirement already satisfied: typing_extensions>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from cohere) (4.12.2)\n","Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.21.2->cohere) (3.7.1)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.21.2->cohere) (2024.12.14)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.21.2->cohere) (1.0.7)\n","Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx>=0.21.2->cohere) (3.10)\n","Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.21.2->cohere) (0.14.0)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.9.2->cohere) (0.7.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->cohere) (3.4.0)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->cohere) (2.2.3)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from tokenizers<1,>=0.15->cohere) (0.27.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (3.16.1)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (2024.10.0)\n","Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (24.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (6.0.2)\n","Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (4.67.1)\n","Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.21.2->cohere) (1.3.1)\n","Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.21.2->cohere) (1.2.2)\n","Downloading cohere-5.13.4-py3-none-any.whl (250 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m250.0/250.0 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n","Downloading fastavro-1.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m75.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading parameterized-0.9.0-py2.py3-none-any.whl (20 kB)\n","Downloading types_requests-2.32.0.20241016-py3-none-any.whl (15 kB)\n","Installing collected packages: types-requests, parameterized, httpx-sse, fastavro, cohere\n","Successfully installed cohere-5.13.4 fastavro-1.10.0 httpx-sse-0.4.0 parameterized-0.9.0 types-requests-2.32.0.20241016\n"]}]},{"cell_type":"code","source":["# @title API Configuration\n","API_KEY = \"YOUR_API_KEY\"\n","MODEL_PATH = 'command-r-plus'\n","co_v2 = cohere.ClientV2(api_key=API_KEY)"],"metadata":{"id":"lw-KLn5zHFmx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# @title Mount Google Drive\n","drive.mount('/content/drive', force_remount=True)\n","os.chdir(\"/content/drive/My Drive\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ev-eMAHRHJl3","outputId":"4d0f2a09-c59f-4868-e642-b01d5819a386"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["# @title Configuration Classes\n","@dataclass\n","class ExperimentConfig:\n","    \"\"\"Configuration class for experiment settings\"\"\"\n","    name: str\n","    base_dir: str\n","    inference_dir: str\n","    prompt_path: str\n","\n","class ExperimentType(Enum):\n","    \"\"\"Enum for different types of experiments\"\"\"\n","    PDB = \"pdb\"\n","    MPVE = \"mpve\"\n","    HFE = \"hfe\"\n","    GEO = \"geo\"\n","    DFT = \"dft\"\n","    HFD = \"hfd\"\n","    QECC_PDF = \"qecc_pdf\"\n","    QECC_TEX = \"qecc_tex\""],"metadata":{"id":"jN6DcI1BIP-u"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0K6ocK19G5GM"},"outputs":[],"source":["# @title Experiment Manager Class\n","class ExperimentManager:\n","    \"\"\"Manages different experiment configurations\"\"\"\n","    def __init__(self, base_path: str = \"/content/drive/My Drive\"):\n","        self.base_path = base_path\n","        self.experiments = self._initialize_experiments()\n","\n","    def _initialize_experiments(self) -> Dict[ExperimentType, ExperimentConfig]:\n","        \"\"\"Initialize all experiment configurations\"\"\"\n","        benchmark_path = f\"{self.base_path}/benchmarks\"\n","        return {\n","            ExperimentType.PDB: ExperimentConfig(\n","                name=\"PDB\",\n","                base_dir=f\"{self.base_path}/pdb\",\n","                inference_dir=f\"{self.base_path}/inference/multi_runs/current/pdb_new/reconstruct_protein_amino_acid_sequence_0_shot/\",\n","                prompt_path=f\"{benchmark_path}/prompts/reconstruct_protein_amino_acid_sequence_0_shot.txt\"\n","            ),\n","            ExperimentType.MPVE: ExperimentConfig(\n","                name=\"MPVE\",\n","                base_dir=f\"{benchmark_path}/data/mpve\",\n","                inference_dir=f\"{benchmark_path}/inference/multi_runs/current/mpve/mat_paper_to_property_1_shot_exclude_trivia/\",\n","                prompt_path=f\"{benchmark_path}/prompts/mat_paper_to_property_1_shot_exclude_trivia.txt\"\n","            ),\n","            ExperimentType.HFE: ExperimentConfig(\n","                name=\"HFE\",\n","                base_dir=f\"{benchmark_path}/data/hfe\",\n","                inference_dir=f\"{benchmark_path}/inference/multi_runs/current/hfe/extract_hamiltonian_0_shot/\",\n","                prompt_path=f\"{benchmark_path}/prompts/extract_hamiltonian_0_shot.txt\"\n","            ),\n","            ExperimentType.GEO: ExperimentConfig(\n","                name=\"GEO\",\n","                base_dir=f\"{benchmark_path}/data/geo\",\n","                inference_dir=f\"{benchmark_path}/inference/multi_runs/current/geo/extract_dataset_from_geo_papers_0_shot\",\n","                prompt_path=f\"{benchmark_path}/prompts/extract_dataset_from_geo_papers_0_shot.txt\"\n","            ),\n","            ExperimentType.DFT: ExperimentConfig(\n","                name=\"DFT\",\n","                base_dir=f\"{benchmark_path}/data/dft\",\n","                inference_dir=f\"{benchmark_path}/inference/multi_runs/current/dft/extract_dft_metadata_1_shot/\",\n","                prompt_path=f\"{benchmark_path}/prompts/extract_dft_metadata_1_shot.txt\"\n","            ),\n","            ExperimentType.HFD: ExperimentConfig(\n","                name=\"HFD\",\n","                base_dir=f\"{benchmark_path}/data/hfd\",\n","                inference_dir=f\"{benchmark_path}/inference/multi_runs/current/hfd/derivation_prompt/\",\n","                prompt_path=f\"{benchmark_path}/prompts/derivation_prompt.txt\"\n","            ),\n","            ExperimentType.QECC_PDF: ExperimentConfig(\n","                name=\"QECC_PDF\",\n","                base_dir=f\"{benchmark_path}/data/qecc_pdf\",\n","                inference_dir=f\"{benchmark_path}/inference/multi_runs/current/qecc_pdf/describe_code_in_paper/\",\n","                prompt_path=f\"{benchmark_path}/prompts/describe_code_in_paper.txt\"\n","            ),\n","            ExperimentType.QECC_TEX: ExperimentConfig(\n","                name=\"QECC_TEX\",\n","                base_dir=f\"{benchmark_path}/data/qecc_tex\",\n","                inference_dir=f\"{benchmark_path}/inference/multi_runs/current/qecc_tex/describe_code_in_paper/\",\n","                prompt_path=f\"{benchmark_path}/prompts/describe_code_in_paper.txt\"\n","            )\n","        }\n","\n","    def get_config(self, experiment_type: ExperimentType) -> ExperimentConfig:\n","        \"\"\"Get configuration for specific experiment type\"\"\"\n","        return self.experiments[experiment_type]"]},{"cell_type":"code","source":["# @title Paper Processing Utilities\n","def specialize_prompt(template: str, tag: str, infil: str) -> str:\n","    \"\"\"Replace a tag in a template with provided text.\"\"\"\n","    if tag in template:\n","        return template.replace(tag, infil)\n","    raise ValueError(f'{tag} absent in template.')\n","\n","def prepare_task_for_paper(paper: str, config: ExperimentConfig, model_id: str) -> dict:\n","    \"\"\"Prepare the task information for a given paper.\"\"\"\n","    paper_input = os.path.join(config.base_dir, 'inputs', f'{paper}.json')\n","    paper_gt = os.path.join(config.base_dir, 'ground_truth', f'{paper}.json')\n","\n","    with open(paper_input, 'r') as f:\n","        inputs = json.load(f)\n","    with open(paper_gt, 'r') as f:\n","        targets = json.load(f)\n","\n","    with open(config.prompt_path, 'r') as f:\n","        ptemp = f.read()\n","\n","    spec_prompt = specialize_prompt(ptemp, '{{text}}', infil=inputs['text'])\n","\n","    return {\n","        'record_id': paper,\n","        'model_id': model_id,\n","        'prompt_path': config.prompt_path,\n","        'prompt_text': spec_prompt,\n","        'response_text': ''\n","    }"],"metadata":{"id":"02DSqrzbHYUi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# @title Paper Processor Class\n","class PaperProcessor:\n","    \"\"\"Handles the processing of scientific papers\"\"\"\n","\n","    def __init__(self, api_key: str, model_path: str):\n","        self.co_v2 = cohere.ClientV2(api_key=api_key)\n","        self.model_path = model_path\n","        self._setup_logging()\n","\n","    def _setup_logging(self):\n","        \"\"\"Configure logging settings\"\"\"\n","        logging.basicConfig(\n","            filename='experiment_log.log',\n","            level=logging.INFO,\n","            format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n","        )\n","        self.logger = logging.getLogger(__name__)\n","\n","    @retry(\n","        stop=stop_after_attempt(3),\n","        wait=wait_exponential(multiplier=1, min=4, max=10),\n","        reraise=True\n","    )\n","    def _make_api_call(self, messages: List[Dict]) -> str:\n","        \"\"\"Make API call with retry logic\"\"\"\n","        response = self.co_v2.chat(\n","            model=self.model_path,\n","            messages=messages,\n","            temperature=0.9,\n","            k=50,\n","            p=0.95,\n","            max_tokens=4000\n","        )\n","        return self._extract_response_text(response)\n","\n","    def _extract_response_text(self, response) -> str:\n","        \"\"\"Extract text from API response\"\"\"\n","        if hasattr(response, 'message'):\n","            if hasattr(response.message, 'content'):\n","                if isinstance(response.message.content, list):\n","                    return ' '.join(item.text for item in response.message.content if hasattr(item, 'text'))\n","                elif isinstance(response.message.content, str):\n","                    return response.message.content\n","        return str(response)\n","\n","    def _save_result(self, task_info: dict, inference_dir: str, run_id: int, success: bool = True):\n","        \"\"\"Save processing results\"\"\"\n","        status = 'success' if success else 'failure'\n","        output_dir = os.path.join(inference_dir, self.model_path, f'run_{run_id}', status)\n","        os.makedirs(output_dir, exist_ok=True)\n","\n","        serializable_task_info = {\n","            'record_id': task_info['record_id'],\n","            'model_id': task_info['model_id'],\n","            'prompt_path': task_info['prompt_path'],\n","            'prompt_text': task_info['prompt_text'],\n","            'response_text': str(task_info['response_text'])\n","        }\n","\n","        output_file = os.path.join(output_dir, f'{task_info[\"record_id\"]}.json')\n","        with open(output_file, 'w') as f:\n","            json.dump(serializable_task_info, f, indent=4)\n","\n","    def process_papers(self, config: ExperimentConfig, run_range: range = range(1, 3)):\n","        \"\"\"Process papers for given experiment configuration\"\"\"\n","        input_dir = os.path.join(config.base_dir, 'inputs')\n","        papers = [f.replace('.json', '') for f in os.listdir(input_dir) if f.endswith('.json')]\n","\n","        self.logger.info(f\"Starting processing {len(papers)} papers for {config.name}\")\n","\n","        for run_id in run_range:\n","            self.logger.info(f\"Starting run {run_id + 1}\")\n","            for i, paper in enumerate(papers, 1):\n","                self.logger.info(f\"Processing paper {i}/{len(papers)} in run {run_id + 1}\")\n","                self._process_single_paper(paper, config, run_id)\n","\n","    def _process_single_paper(self, paper: str, config: ExperimentConfig, run_id: int):\n","        \"\"\"Process a single paper\"\"\"\n","        try:\n","            task_info = prepare_task_for_paper(paper, config, self.model_path)\n","\n","            if len(task_info['prompt_text'].split()) > 128000:\n","                raise ValueError(\"Input text exceeds token limit\")\n","\n","            response = self._make_api_call([{\n","                \"role\": \"user\",\n","                \"content\": task_info['prompt_text']\n","            }])\n","\n","            task_info['response_text'] = response\n","            self._save_result(task_info, config.inference_dir, run_id, success=True)\n","            time.sleep(2)  # Rate limiting\n","\n","        except Exception as e:\n","            self.logger.error(f\"Error processing paper {paper}: {str(e)}\")\n","            task_info['response_text'] = str(e)\n","            self._save_result(task_info, config.inference_dir, run_id, success=False)\n","            time.sleep(2)"],"metadata":{"id":"vslgWfVSHQR0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# @title Main Execution\n","def main():\n","    \"\"\"Main execution function\"\"\"\n","    experiment_manager = ExperimentManager()\n","\n","    processor = PaperProcessor(\n","        api_key=API_KEY,\n","        model_path=MODEL_PATH\n","    )\n","\n","    # Select experiment type\n","    experiment_type = ExperimentType.DFT  # CHANGE THIS to process different experiments\n","    config = experiment_manager.get_config(experiment_type)\n","\n","    processor.process_papers(config)\n","\n","if __name__ == \"__main__\":\n","    main()"],"metadata":{"collapsed":true,"id":"GVSZxHWAHSRm"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["For example, for running the DFT task, you need to run the following cell:"],"metadata":{"id":"p9cYh-ffKGR5"}},{"cell_type":"code","source":["experiment_manager = ExperimentManager()\n","\n","processor = PaperProcessor(\n","    api_key=\"YOUR_API_KEY\",\n","    model_path=MODEL_PATH\n",")\n","\n","experiment_type = ExperimentType.DFT\n","config = experiment_manager.get_config(experiment_type)\n","\n","print(\"Selected Configuration:\")\n","print(f\"Base Directory: {config.base_dir}\")\n","print(f\"Inference Directory: {config.inference_dir}\")\n","print(f\"Prompt Path: {config.prompt_path}\")\n","\n","processor.process_papers(config)"],"metadata":{"id":"1V5ipuLUKQ6n"},"execution_count":null,"outputs":[]}]}