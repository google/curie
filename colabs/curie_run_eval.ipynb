{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"16ISYcglcz8JaeQdD0C-NtLs8SaS7nOVC","timestamp":1736887154642}],"collapsed_sections":["prmi14SE-8Hf","LpCKZtdqZAgj","k1NbBXyWZD7C","rXI7uAyl7cH1","iRmqK0PU7Pv9","sH5WLIFdGNDD","v5-94GHgHW4C","Z3q-IXimHghk","pukWSU7WHwQo","NwlQaQlVmRcy","gHb00g_6mTRS","7zqg5F8Ll9BO","SBaTJhefmM8l","brIrWo-gPzB8","lsiSmrqpPslm"]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"cbf536fcf00447e3b784304dd29b32fa":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_bc034f1a7fb44e51a58064275e1e684b","IPY_MODEL_2b58344741ee45ad81cc61650e70c9b1","IPY_MODEL_3018ee985b0d49c6b9f83178a8bff765"],"layout":"IPY_MODEL_8bfcfa9ea642448593d0ff7fac92a995"}},"bc034f1a7fb44e51a58064275e1e684b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d5de0e7a099f44e39427782916c3fffc","placeholder":"​","style":"IPY_MODEL_cccd7a57fc5841649c50e0f875a2607a","value":"tokenizer_config.json: 100%"}},"2b58344741ee45ad81cc61650e70c9b1":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_5a093e9b94654fdd95dcfc4b71861403","max":25,"min":0,"orientation":"horizontal","style":"IPY_MODEL_cddf8f1032624f69b66df46b8812c5e9","value":25}},"3018ee985b0d49c6b9f83178a8bff765":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cbe1d68152d04536b29071d9d8dcbf05","placeholder":"​","style":"IPY_MODEL_2057d6248e7b45c88267301e3ea0df8f","value":" 25.0/25.0 [00:00&lt;00:00, 596B/s]"}},"8bfcfa9ea642448593d0ff7fac92a995":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d5de0e7a099f44e39427782916c3fffc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cccd7a57fc5841649c50e0f875a2607a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5a093e9b94654fdd95dcfc4b71861403":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cddf8f1032624f69b66df46b8812c5e9":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"cbe1d68152d04536b29071d9d8dcbf05":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2057d6248e7b45c88267301e3ea0df8f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"38a5f31d35ec4d4f919fb8c38dcc9d2d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b1210c7b67144f128e7a5950c89fc76a","IPY_MODEL_6503abd2b4e245bda7e7d88e55673335","IPY_MODEL_50fbac13ff2c49c484259e052e9c0e9b"],"layout":"IPY_MODEL_ce6357ae048f4bb397a5e2cf6f5a0bb9"}},"b1210c7b67144f128e7a5950c89fc76a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a90aa476f24e4ced9ec3a57df8534603","placeholder":"​","style":"IPY_MODEL_75e04c5bccd745fd93a565d10dad2939","value":"config.json: 100%"}},"6503abd2b4e245bda7e7d88e55673335":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_8a850f0c410d4ec2995f716008567e81","max":482,"min":0,"orientation":"horizontal","style":"IPY_MODEL_14bbf20fa7a842739fca7a7bd9f370b3","value":482}},"50fbac13ff2c49c484259e052e9c0e9b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a081d464af6d470ca1533c2e5564dea6","placeholder":"​","style":"IPY_MODEL_fec6aa6ccf9b44dd9a6d5758aaa1fda7","value":" 482/482 [00:00&lt;00:00, 7.08kB/s]"}},"ce6357ae048f4bb397a5e2cf6f5a0bb9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a90aa476f24e4ced9ec3a57df8534603":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"75e04c5bccd745fd93a565d10dad2939":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8a850f0c410d4ec2995f716008567e81":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"14bbf20fa7a842739fca7a7bd9f370b3":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a081d464af6d470ca1533c2e5564dea6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fec6aa6ccf9b44dd9a6d5758aaa1fda7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"496bfd47e50b4c38bfbc213a0cd58d7f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_47e9da216afc4280b74d7a312d8d9fe7","IPY_MODEL_16f5d222298b4dce8ccae92a710887da","IPY_MODEL_f1b1c4217ef1424daffb3ca4fd03e75c"],"layout":"IPY_MODEL_a53470e82a3745978b678e02159eaccd"}},"47e9da216afc4280b74d7a312d8d9fe7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5212e01ecda6495ab7147a97ae79a7c2","placeholder":"​","style":"IPY_MODEL_3a7b3bd231084bcd8a7cb092d77049aa","value":"vocab.json: 100%"}},"16f5d222298b4dce8ccae92a710887da":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_521904df4caf4d5b92c414beb2ec5a66","max":898823,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e9af6d04145e4b4ead090f42ff1c0722","value":898823}},"f1b1c4217ef1424daffb3ca4fd03e75c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9c289b8598cd4336afee7654d5281a3b","placeholder":"​","style":"IPY_MODEL_82ffad66c60c4c9781a35920dc29227d","value":" 899k/899k [00:00&lt;00:00, 5.07MB/s]"}},"a53470e82a3745978b678e02159eaccd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5212e01ecda6495ab7147a97ae79a7c2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3a7b3bd231084bcd8a7cb092d77049aa":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"521904df4caf4d5b92c414beb2ec5a66":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e9af6d04145e4b4ead090f42ff1c0722":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"9c289b8598cd4336afee7654d5281a3b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"82ffad66c60c4c9781a35920dc29227d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"afc564454e1a4b75824f916ea8ec8d8b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_3c41b40636c44e72a96c82a938442ff2","IPY_MODEL_680334fe747c4bc2bc1e935c8b0b2c63","IPY_MODEL_4ee91bf0763f4a13bba5f8c12021d897"],"layout":"IPY_MODEL_96a86dd3a7b54310bb115030550b1056"}},"3c41b40636c44e72a96c82a938442ff2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_79c477295ce047e49bcb7d497c33292b","placeholder":"​","style":"IPY_MODEL_afd1a7c3f5534608a3a51f48ca2eb6e0","value":"merges.txt: 100%"}},"680334fe747c4bc2bc1e935c8b0b2c63":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_660cb110ccfd44018352e1e7a9c6da02","max":456318,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d33ce93035f14bad9fe5145a43714850","value":456318}},"4ee91bf0763f4a13bba5f8c12021d897":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6eebb8beaa14441ba2e819998166cbd0","placeholder":"​","style":"IPY_MODEL_fcbc36a563894dad980152388e3354df","value":" 456k/456k [00:00&lt;00:00, 6.40MB/s]"}},"96a86dd3a7b54310bb115030550b1056":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"79c477295ce047e49bcb7d497c33292b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"afd1a7c3f5534608a3a51f48ca2eb6e0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"660cb110ccfd44018352e1e7a9c6da02":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d33ce93035f14bad9fe5145a43714850":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6eebb8beaa14441ba2e819998166cbd0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fcbc36a563894dad980152388e3354df":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"147941c1ccd84f8fa0f99c6320f6d2a3":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_573b724d327f4497bea1b071e9638081","IPY_MODEL_15715bc76f2343468b24f7a1415344d1","IPY_MODEL_0ddde77a7b18447f99a16746af30dc9a"],"layout":"IPY_MODEL_c034520d064f4142a09b54b96b246b26"}},"573b724d327f4497bea1b071e9638081":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_50bea7706d2f44f1834a2f71fa5b581e","placeholder":"​","style":"IPY_MODEL_5e3dcebc234e4a4cbb93e15364072047","value":"tokenizer.json: 100%"}},"15715bc76f2343468b24f7a1415344d1":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_664bed347d6d41158116c427637d7788","max":1355863,"min":0,"orientation":"horizontal","style":"IPY_MODEL_aef062741a204d4ba0a98f46d801c929","value":1355863}},"0ddde77a7b18447f99a16746af30dc9a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0e6d40604e7d432697c95a0c8e1fb374","placeholder":"​","style":"IPY_MODEL_8ae7b0f28a944c72875cb8cc4f26cc1f","value":" 1.36M/1.36M [00:00&lt;00:00, 16.0MB/s]"}},"c034520d064f4142a09b54b96b246b26":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"50bea7706d2f44f1834a2f71fa5b581e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5e3dcebc234e4a4cbb93e15364072047":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"664bed347d6d41158116c427637d7788":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"aef062741a204d4ba0a98f46d801c929":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"0e6d40604e7d432697c95a0c8e1fb374":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8ae7b0f28a944c72875cb8cc4f26cc1f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3aef8b52cdd14f5f8095455b61efb63a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_746833f30a7f482ea229bb9cc5605a74","IPY_MODEL_1c675640c6e64fae9b2442fdd23c1abb","IPY_MODEL_a6f506709cab41e79543a42ab8deb4d0"],"layout":"IPY_MODEL_60398a3b6bdf4f858531737a20b7293e"}},"746833f30a7f482ea229bb9cc5605a74":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6bfa536f4f2b44559a55747c58073f9f","placeholder":"​","style":"IPY_MODEL_6b53c11771cf4a298329718e5a25515f","value":"model.safetensors: 100%"}},"1c675640c6e64fae9b2442fdd23c1abb":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_4e478d6e27b04b99b79bd1fb992ea9d0","max":1421700479,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d906b7fd8b104f9ba5decdad9ad59928","value":1421700479}},"a6f506709cab41e79543a42ab8deb4d0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fa54d587c88343dd8bdbb5aa19d3622c","placeholder":"​","style":"IPY_MODEL_e422f2af61ca4c989100597d3aa1f515","value":" 1.42G/1.42G [00:18&lt;00:00, 132MB/s]"}},"60398a3b6bdf4f858531737a20b7293e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6bfa536f4f2b44559a55747c58073f9f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6b53c11771cf4a298329718e5a25515f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4e478d6e27b04b99b79bd1fb992ea9d0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d906b7fd8b104f9ba5decdad9ad59928":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"fa54d587c88343dd8bdbb5aa19d3622c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e422f2af61ca4c989100597d3aa1f515":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"markdown","source":["# params"],"metadata":{"id":"prmi14SE-8Hf"}},{"cell_type":"code","source":["file_root_path = \"/content/drive/Shareddrives/Curie/benchmarks/public_release\" #@param\n","task = \"geo\" #@param\n","prompt = \"extract_dataset_from_geo_papers_0_shot\" #@param\n","llm_name = \"command-r-plus\" #@param\n","record_id = \"850ca33e8c1853c1735da63073ec3910bce91ddc\" #@param"],"metadata":{"id":"1klrqpcq_Auz"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# read files in drive"],"metadata":{"id":"LpCKZtdqZAgj"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"P9-OqbH2Yktq","executionInfo":{"status":"ok","timestamp":1737484894045,"user_tz":480,"elapsed":22884,"user":{"displayName":"Jackson Cui","userId":"10266610839923849092"}},"outputId":"70829f97-db54-4885-ed40-7c9d4f8d8995"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","source":["# install"],"metadata":{"id":"k1NbBXyWZD7C"}},{"cell_type":"code","source":["!pip install json5"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hah1T1Yx5tY0","executionInfo":{"status":"ok","timestamp":1737484897994,"user_tz":480,"elapsed":3951,"user":{"displayName":"Jackson Cui","userId":"10266610839923849092"}},"outputId":"e5e0539e-a194-4fae-99f3-d7cd91cfd327"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting json5\n","  Downloading json5-0.10.0-py3-none-any.whl.metadata (34 kB)\n","Downloading json5-0.10.0-py3-none-any.whl (34 kB)\n","Installing collected packages: json5\n","Successfully installed json5-0.10.0\n"]}]},{"cell_type":"code","source":["!pip install bert-score"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_26XVvwZRREs","executionInfo":{"status":"ok","timestamp":1737484909689,"user_tz":480,"elapsed":11693,"user":{"displayName":"Jackson Cui","userId":"10266610839923849092"}},"outputId":"43c44a1f-9904-470a-d357-9ef092db0da7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting bert-score\n","  Downloading bert_score-0.3.13-py3-none-any.whl.metadata (15 kB)\n","Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from bert-score) (2.5.1+cu121)\n","Requirement already satisfied: pandas>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from bert-score) (2.2.2)\n","Requirement already satisfied: transformers>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from bert-score) (4.47.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from bert-score) (1.26.4)\n","Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from bert-score) (2.32.3)\n","Requirement already satisfied: tqdm>=4.31.1 in /usr/local/lib/python3.11/dist-packages (from bert-score) (4.67.1)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from bert-score) (3.10.0)\n","Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from bert-score) (24.2)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.1->bert-score) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.1->bert-score) (2024.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.1->bert-score) (2024.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (3.16.1)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (4.12.2)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (3.1.5)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (2024.10.0)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (12.1.105)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (9.1.0.70)\n","Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (12.1.3.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (11.0.2.54)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (10.3.2.106)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (11.4.5.107)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (12.1.0.106)\n","Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (2.21.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (12.1.105)\n","Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (3.1.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (1.13.1)\n","Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.0.0->bert-score) (12.6.85)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.0.0->bert-score) (1.3.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from transformers>=3.0.0->bert-score) (0.27.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers>=3.0.0->bert-score) (6.0.2)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers>=3.0.0->bert-score) (2024.11.6)\n","Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers>=3.0.0->bert-score) (0.21.0)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers>=3.0.0->bert-score) (0.5.2)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert-score) (1.3.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert-score) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert-score) (4.55.3)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert-score) (1.4.8)\n","Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert-score) (11.1.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert-score) (3.2.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->bert-score) (3.4.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->bert-score) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->bert-score) (2.3.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->bert-score) (2024.12.14)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=1.0.1->bert-score) (1.17.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.0.0->bert-score) (3.0.2)\n","Downloading bert_score-0.3.13-py3-none-any.whl (61 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.1/61.1 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: bert-score\n","Successfully installed bert-score-0.3.13\n"]}]},{"cell_type":"code","source":["!pip install -r rouge/requirements.txt\n","!pip install rouge-score\n","!pip install Bio\n","!pip install Levenshtein"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CXhrgXJ7U7DB","executionInfo":{"status":"ok","timestamp":1737484959121,"user_tz":480,"elapsed":49433,"user":{"displayName":"Jackson Cui","userId":"10266610839923849092"}},"outputId":"9db93913-6bfa-479b-d168-25a4f36a5c4b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[31mERROR: Could not open requirements file: [Errno 2] No such file or directory: 'rouge/requirements.txt'\u001b[0m\u001b[31m\n","\u001b[0mCollecting rouge-score\n","  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from rouge-score) (1.4.0)\n","Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (from rouge-score) (3.9.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from rouge-score) (1.26.4)\n","Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from rouge-score) (1.17.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk->rouge-score) (8.1.8)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk->rouge-score) (1.4.2)\n","Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk->rouge-score) (2024.11.6)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk->rouge-score) (4.67.1)\n","Building wheels for collected packages: rouge-score\n","  Building wheel for rouge-score (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for rouge-score: filename=rouge_score-0.1.2-py3-none-any.whl size=24935 sha256=0a8e7b0eefa835096b8cdb06ae1680a69124c655394cd9841f2ae097849eb34e\n","  Stored in directory: /root/.cache/pip/wheels/1e/19/43/8a442dc83660ca25e163e1bd1f89919284ab0d0c1475475148\n","Successfully built rouge-score\n","Installing collected packages: rouge-score\n","Successfully installed rouge-score-0.1.2\n","Collecting Bio\n","  Downloading bio-1.7.1-py3-none-any.whl.metadata (5.7 kB)\n","Collecting biopython>=1.80 (from Bio)\n","  Downloading biopython-1.85-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n","Collecting gprofiler-official (from Bio)\n","  Downloading gprofiler_official-1.0.0-py3-none-any.whl.metadata (11 kB)\n","Collecting mygene (from Bio)\n","  Downloading mygene-3.2.2-py2.py3-none-any.whl.metadata (10 kB)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from Bio) (2.2.2)\n","Requirement already satisfied: pooch in /usr/local/lib/python3.11/dist-packages (from Bio) (1.8.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from Bio) (2.32.3)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from Bio) (4.67.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from biopython>=1.80->Bio) (1.26.4)\n","Collecting biothings-client>=0.2.6 (from mygene->Bio)\n","  Downloading biothings_client-0.4.1-py3-none-any.whl.metadata (10 kB)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->Bio) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->Bio) (2024.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->Bio) (2024.2)\n","Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from pooch->Bio) (4.3.6)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from pooch->Bio) (24.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->Bio) (3.4.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->Bio) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->Bio) (2.3.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->Bio) (2024.12.14)\n","Requirement already satisfied: httpx>=0.22.0 in /usr/local/lib/python3.11/dist-packages (from biothings-client>=0.2.6->mygene->Bio) (0.28.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->Bio) (1.17.0)\n","Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.22.0->biothings-client>=0.2.6->mygene->Bio) (3.7.1)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.22.0->biothings-client>=0.2.6->mygene->Bio) (1.0.7)\n","Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.22.0->biothings-client>=0.2.6->mygene->Bio) (0.14.0)\n","Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.22.0->biothings-client>=0.2.6->mygene->Bio) (1.3.1)\n","Downloading bio-1.7.1-py3-none-any.whl (280 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m281.0/281.0 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading biopython-1.85-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m26.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading gprofiler_official-1.0.0-py3-none-any.whl (9.3 kB)\n","Downloading mygene-3.2.2-py2.py3-none-any.whl (5.4 kB)\n","Downloading biothings_client-0.4.1-py3-none-any.whl (46 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.7/46.7 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: biopython, gprofiler-official, biothings-client, mygene, Bio\n","Successfully installed Bio-1.7.1 biopython-1.85 biothings-client-0.4.1 gprofiler-official-1.0.0 mygene-3.2.2\n","Collecting Levenshtein\n","  Downloading levenshtein-0.26.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.2 kB)\n","Collecting rapidfuzz<4.0.0,>=3.9.0 (from Levenshtein)\n","  Downloading rapidfuzz-3.11.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n","Downloading levenshtein-0.26.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (162 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m162.7/162.7 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading rapidfuzz-3.11.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m42.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: rapidfuzz, Levenshtein\n","Successfully installed Levenshtein-0.26.1 rapidfuzz-3.11.0\n"]}]},{"cell_type":"markdown","source":["# imports"],"metadata":{"id":"rXI7uAyl7cH1"}},{"cell_type":"code","source":["import json5\n","import json\n","import re\n","import functools\n","from typing import Any, Tuple, Union, Dict\n","from Bio import Align\n","import glob\n","from bert_score import score\n","from rouge_score import rouge_scorer\n","import numpy as np\n","import ast\n","import os\n","import google.generativeai as genai\n","import Levenshtein"],"metadata":{"id":"VchTG3815jUG"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# eval functions"],"metadata":{"id":"iRmqK0PU7Pv9"}},{"cell_type":"markdown","source":["## LMSim eval"],"metadata":{"id":"sH5WLIFdGNDD"}},{"cell_type":"code","source":["# import google.generativeai as genai\n","# MY_API_KEY = \"\" #@param\n","# genai.configure(api_key=MY_API_KEY)\n","\n","\n","# def query_model(query_prompt: str,\n","#                 model_name: str = 'gemini-1.5-pro-latest'\n","#                 ) -> str:\n","#     model = genai.GenerativeModel(model_name=model_name)\n","#     response = model.generate_content(query_prompt)\n","#     return response.text\n","\n","# query_model(\"How many days are there in a year?\")\n"],"metadata":{"id":"94xUwOLFNmQW"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### LMSim util"],"metadata":{"id":"v5-94GHgHW4C"}},{"cell_type":"code","source":["\n","\n","@functools.lru_cache(maxsize=1)\n","def get_model(model_name: str = 'gemini-1.5-pro-latest'):\n","  return genai.GenerativeModel(model_name=model_name)\n","\n","\n","def llm_output(client: Any, prompt: str) -> str:\n","  # client=None for external api\n","  return get_model().generate_content(prompt).text\n","\n","def model_eval_json(\n","    record_id: str | None,\n","    json_ground_truth: list[dict[str, Any]],\n","    json_model_response: list[dict[str, Any]],\n","    eval_prompt: str,\n","    client: Any,\n",") -> dict[str, Any]:\n","  \"\"\"Evaluate with json ground truth and model response.\"\"\"\n","  eval_list = []\n","  for j, ground_truth_item in enumerate(json_ground_truth):\n","    for k, model_response_item in enumerate(json_model_response):\n","      # Add index to llm input to suppress hallucination on json_extracted_index\n","      # prediction\n","      model_response_item[\"json_extracted_index\"] = k\n","    prompt = (\n","        load_matsci_prompt(eval_prompt)\n","        .replace(\n","            \"{{json_ground_truth}}\", json.dumps(ground_truth_item, indent=2)\n","        )\n","        .replace(\n","            \"{{json_extracted_list}}\", json.dumps(json_model_response, indent=2)\n","        )\n","    )\n","    output = llm_output(client=client, prompt=prompt)\n","    try:\n","      output_json = json5.loads(output)\n","    except Exception as e:  # pylint: disable=broad-except\n","      print(\"Skipping incomplete last item in output: \", e)\n","      inds = [m.start() for m in re.finditer(r\",\\s*\\{\", output)]\n","      if inds:\n","        ind = inds[-1]\n","        output_json = json5.loads(output[:ind] + \"]\")\n","      else:\n","        output_json = []\n","    if isinstance(output_json, list):\n","      # Handle edge case that model hallucinated outputing list enclosing json.\n","      if not output_json:\n","        output_json = {}\n","      else:\n","        output_json = output_json[0]\n","    output_json[\"json_ground_truth_index\"] = j\n","    output_json[\"json_ground_truth\"] = ground_truth_item\n","    output_json[\"json_extracted\"] = {}\n","    # If not in it, it means llm didn't find a good match, so leave it empty.\n","    if \"json_extracted_index\" in output_json:\n","      if (\n","          str(output_json[\"json_extracted_index\"]).isdigit()\n","          and int(output_json[\"json_extracted_index\"]) > 0\n","          and int(output_json[\"json_extracted_index\"])\n","          < len(json_model_response)\n","      ):\n","        output_json[\"json_extracted\"] = json_model_response[\n","            int(output_json[\"json_extracted_index\"])\n","        ]\n","      else:\n","        del output_json[\"json_extracted_index\"]\n","    eval_list.append(output_json)\n","  return {\n","      \"record_id\": record_id,\n","      \"ground_truth_length\": len(json_ground_truth),\n","      \"model_response_length\": len(json_model_response),\n","      \"response_json\": eval_list,\n","  }"],"metadata":{"id":"N10Sp_IDHal6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"wDPIn2CUpsLt"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### LMSim dft"],"metadata":{"id":"Z3q-IXimHghk"}},{"cell_type":"code","source":["def get_lmsim_score_dft(prediction, reference):\n","  return dft_domain_expert_model_based_eval(reference, prediction, client=None) # Client=None for external api\n","\n","\n","_METADATA_EVAL_PROMPT_FILENAME = file_root_path + \"/prompts/dft_metadata_eval_output_1_shot.txt\"\n","_STRUCTURE_EVAL_PROMPT_FILENAME = file_root_path + \"/prompts/dft_structure_eval_output_1_shot.txt\"\n","\n","\n","def get_dft_model_response_field(\n","    model_output_value: dict[str, Any], field_name: str\n",") -> list[Any] | str:\n","  \"\"\"Returns the model response for a given field from the inference output.\n","\n","     This applies to json responses from the dft chained inference output.\n","\n","  Args:\n","    model_output_value: The model output response (from one two) as a dict.\n","    field_name: The name of the field to extract. This should be one of\n","      \"structure_metadata\", \"dft_metadata\", or \"code\".\n","  \"\"\"\n","  if field_name in [\"structure_metadata\"]:\n","    if field_name in model_output_value:\n","      print(model_output_value)\n","      return model_output_value[\"structure_metadata\"]\n","    else:\n","      return \"\"\n","\n","  elif field_name in [\"dft_metadata\"]:\n","    if field_name in model_output_value:\n","      return model_output_value[\"dft_metadata\"]\n","    else:\n","      return \"\"\n","\n","  elif field_name == \"code\":\n","    if field_name in model_output_value:\n","      code = \"\\n\".join(\n","          [x[\"code_element\"] for x in model_output_value[\"code_elements\"]]\n","      )\n","      code += \"\\n\" + model_output_value[\"execution_code\"]\n","      return code\n","    else:\n","      return \"\"\n","\n","  raise ValueError(f\"Unknown field name: {field_name}\")\n","\n","\n","def get_annotated_structure_metadata_and_dft_params(\n","    gt_paper_code: str, verbose: int = 0\n",") -> dict[str, list[str]]:\n","  \"\"\"Returns structure metadata and dft params from the ground truth code.\n","\n","  Args:\n","    gt_paper_code: The ground truth code from .py file as a string.\n","    verbose: The verbosity level.\n","  \"\"\"\n","  structures = []\n","  dft_params = []\n","\n","  paper = gt_paper_code\n","  if \"structure_metadata_\" in paper:\n","    parts = paper.split(\"structure_metadata_\")[1:]\n","    whole_parts = [\"structure_metadata_\" + part for part in parts]\n","\n","    for part in whole_parts:\n","      if verbose > 1:\n","        print(\"PART:\\n\", part)\n","      if \"parse_raw(\" not in part:\n","        continue\n","      left, right, *_ = part.split(\"parse_raw(\")\n","      if \"StructureMetadata\" in left:\n","        end_struc = \")\"\n","        if \"')\" in right:\n","          end_struc = \"')\"\n","        elif \"'\\n)\" in right:\n","          end_struc = \"'\\n)\"\n","        struc_json = right.split(end_struc)[0].strip()\n","        if verbose > 0:\n","          print(\"Extracted structure:\\n\", struc_json)\n","        # clean_json = struc_json.replace('NaN', '\"NaN\"')\n","        # struc_json = ast.literal_eval(clean_json)\n","        structures.append(struc_json)\n","\n","  if \"dft_params_\" in paper:\n","    parts = paper.split(\"dft_params_\")[1:]\n","    # print(parts)\n","    whole_parts = [\"dft_params_\" + part for part in parts]\n","\n","    for part in whole_parts:\n","      if verbose > 1:\n","        print(\"PART:\\n\", part)\n","      if \"parse_raw(\" not in part:\n","        continue\n","      left, right, *_ = part.split(\"parse_raw(\")\n","      if \"DFTParameters\" in left:\n","        end_struc = \")\"\n","        if \"')\" in right:\n","          end_struc = \"')\"\n","        elif \"'\\n)\" in right:\n","          end_struc = \"'\\n)\"\n","        dft_params_str = right.split(end_struc)[0].strip()\n","        if verbose > 0:\n","          print(\"Extracted dft_param:\\n\", dft_params_str)\n","        # clean_json = dft_params_str.replace('NaN', '\"NaN\"')\n","        # dft_params_str = ast.literal_eval(clean_json)\n","        dft_params.append(dft_params_str)\n","\n","  gt_struc_jsons = []\n","  for struct_metadata in structures:\n","    gt_json = struct_metadata.split(\"'\")[1]\n","    clean_json = gt_json.replace(\"NaN\", '\"NaN\"')\n","    try:\n","      gt_structure_json = ast.literal_eval(clean_json)\n","      gt_struc_jsons.append(gt_structure_json)\n","    except Exception:  # pylint: disable=broad-exception-caught\n","      gt_struc_jsons.append(clean_json)\n","\n","  gt_dft_params_jsons = []\n","  for dft_param in dft_params:\n","    gt_json = dft_param.split(\"'\")[1]\n","    clean_json = gt_json.replace(\"NaN\", '\"NaN\"')\n","    try:\n","      gt_dft_json = ast.literal_eval(clean_json)\n","      gt_dft_params_jsons.append(gt_dft_json)\n","    except Exception:  # pylint: disable=broad-exception-caught\n","      gt_dft_params_jsons.append(clean_json)\n","\n","  return {\n","      \"structures_metadata\": gt_struc_jsons,\n","      \"dft_params\": gt_dft_params_jsons,\n","  }\n","\n","\n","def get_material_composition_from_struc(\n","    structure: str | dict[str, str],\n",") -> str | None:\n","  \"\"\"Returns material composition from the structure metadata dict or string.\"\"\"\n","  if isinstance(structure, dict):\n","    if \"composition\" in structure:\n","      return structure[\"composition\"]\n","  elif isinstance(structure, str):\n","    if \"composition\" in structure:\n","      material = structure.split(r\"\\\"composition\\\":\")[1].split(\",\")[0]\n","      return material\n","  return None\n","\n","\n","def get_json_from_str(input_str: str) -> dict[str, Any] | None:\n","  \"\"\"Returns the json object from the ground truth input string.\"\"\"\n","  output_val = input_str.replace(\"NaN\", '\"NaN\"')\n","  output_val = output_val.replace(\"true\", '\"1.0\"')\n","  output_val = output_val.replace(\"false\", '\"NaN\"')\n","  try:\n","    output_val = ast.literal_eval(output_val)\n","  except ValueError:\n","    return None\n","  return output_val\n","\n","\n","def parse_ground_truth_dft(ground_truth: str, client: Any) -> list[dict[str, Any]]:\n","  \"\"\"Parses ground truth.\"\"\"\n","  try:\n","    json_ground_truth = json5.loads(\n","        ground_truth.replace(\"\\n\", \"\").replace(\"\\\\\", \"\")\n","    )\n","    if json_ground_truth and isinstance(json_ground_truth[0], str):\n","      json_ground_truth = [json5.loads(item) for item in json_ground_truth]\n","  except Exception:  # pylint: disable=broad-except\n","    print(\"***using llm to parse\")\n","    ground_truth = llm_output(\n","        client,\n","        prompt=\"Extract ground truth json list from the following text.\\n\"\n","        + ground_truth\n","        + \"\\nMake sure to remove all backslashes for escape characters. Output\"\n","        \" the json list ONLY, without any explanation, prefix or suffix:\\n\",\n","    )\n","    print(\"***llm_ground_truth:\\n\", ground_truth)\n","    json_ground_truth = json5.loads(\n","        ground_truth.replace(\"\\n\", \"\").replace('\\\\\"', \"\").replace(\"\\\\\", \"\")\n","    )\n","\n","  return json_ground_truth\n","\n","\n","def parse_model_response_dft(\n","    model_response: str, client: Any, use_llm=False\n",") -> list[dict[str, Any]]:\n","  \"\"\"Parses model response.\"\"\"\n","  def remove_prefix_suffix(text):\n","    return text.replace(\"\\n\", \"\").removeprefix(\"```json\").removesuffix(\"```json\").removeprefix(\"```\").removesuffix(\"```\").removeprefix(\"`\").removesuffix(\"`\")\n","  if use_llm:\n","    model_response = llm_output(\n","            client,\n","            prompt=\"Extract model_response json list from the following text.\\n\"\n","            + model_response\n","            + '\\nMake sure all None values are converted to \"NaN\". Output the json'\n","            \" list\"\n","            \" ONLY, without any explanation, prefix or suffix:\\n\",\n","          )\n","  response_text = remove_prefix_suffix(model_response)\n","  try:\n","    try:\n","      formatted_text = re.sub(r\"(?<=\\w)'(?=\\w|\\s)\", \"\\\\'\", response_text)\n","      if not formatted_text:\n","        formatted_text = \"{}\"\n","        print(\"Response_text is empty\")\n","      json_model_response = json5.loads(formatted_text)\n","    except Exception as e:  # pylint: disable=broad-except\n","      print(\"Skipping incomplete last item: \", e)\n","      print(\"***\", response_text)\n","      ind = [m.start() for m in re.finditer(r\",\\s*\\{\", response_text)][-1]\n","      json_model_response = json5.loads(response_text[:ind] + \"]\")\n","  except:\n","      return parse_model_response_dft(model_response, client, use_llm=True) if not use_llm else []\n","  return json_model_response\n","\n","\n","def dft_model_eval_paper(\n","    record_id: str | None,\n","    ground_truth: str,\n","    model_response: str,\n","    eval_prompt: str,\n","    client: Any,\n",") -> dict[str, Any]:\n","  \"\"\"Runs model evaluation on material properties for a single paper.\n","\n","  Args:\n","    record_id: record id or paper id.\n","    ground_truth: ground truth list in str type.\n","    model_response: model response list in str type.\n","    eval_prompt: eval prompt.\n","    client: llm client.\n","\n","  Returns:\n","    model eval response json.\n","  \"\"\"\n","  json_ground_truth = parse_ground_truth_dft(ground_truth, client)\n","  json_model_response = parse_model_response_dft(model_response, client)\n","  return model_eval_json(\n","      record_id=record_id,\n","      json_ground_truth=json_ground_truth,\n","      json_model_response=json_model_response,\n","      eval_prompt=eval_prompt,\n","      client=client,\n","  )\n","\n","\n","def dft_metadata_domain_expert_model_based_eval(\n","    ground_truth: str,\n","    model_response: str,\n","    client: Any | None = None,\n","    eval_prompt: str = _METADATA_EVAL_PROMPT_FILENAME,\n","    verbose: bool = True,\n",") -> dict[str, Any]:\n","  return dft_domain_expert_model_based_eval(\n","      ground_truth=ground_truth,\n","      model_response=model_response,\n","      client=client,\n","      eval_prompt=eval_prompt,\n","      verbose=verbose,\n","  )\n","\n","\n","def dft_structure_domain_expert_model_based_eval(\n","    ground_truth: str,\n","    model_response: str,\n","    client: Any | None = None,\n","    eval_prompt: str = _STRUCTURE_EVAL_PROMPT_FILENAME,\n","    verbose: bool = True,\n",") -> dict[str, Any]:\n","  return dft_domain_expert_model_based_eval(\n","      ground_truth=ground_truth,\n","      model_response=model_response,\n","      client=client,\n","      eval_prompt=eval_prompt,\n","      verbose=verbose,\n","  )\n","\n","\n","def dft_domain_expert_model_based_eval(\n","    ground_truth: str,\n","    model_response: str,\n","    client: Any | None = None,\n","    eval_prompt: str = _METADATA_EVAL_PROMPT_FILENAME,\n","    verbose: bool = True,\n",") -> dict[str, Any]:\n","  \"\"\"Runs model based eval on dft.\n","\n","  Args:\n","    ground_truth: ground truth list in str type.\n","    model_response: model response list in str type.\n","    client: llm client.\n","    eval_prompt: eval prompt.\n","    verbose: whether to print out eval results.\n","\n","  Returns:\n","    eval result.\n","  \"\"\"\n","  if verbose:\n","    print(\"Model eval started...\")\n","  eval_output_item = dft_model_eval_paper(\n","      record_id=None,\n","      ground_truth=ground_truth,\n","      model_response=model_response,\n","      eval_prompt=eval_prompt,\n","      client=client,\n","  )\n","  if verbose:\n","    print(\"Model eval finished.\")\n","  eval_result = eval_overall_result(\n","      eval_output_item, verbose=verbose\n","  )\n","  if verbose:\n","    print(\"Eval results:\\n\", eval_result)\n","  return eval_result"],"metadata":{"id":"cZpvEbZMHpD8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### LMSim mpve"],"metadata":{"id":"pukWSU7WHwQo"}},{"cell_type":"code","source":["def get_lmsim_score_mpve(prediction, reference):\n","  # TODO: Convert to external model client\n","  return mpve_domain_expert_model_based_eval(reference, prediction, client=None) # Client=None for external api\n","\n","\n","# TODO: Convert to Drive path\n","_EVAL_PROMPT_FILENAME = file_root_path + \"/prompts/mat_eval_output_1_shot.txt\"\n","\n","\n","def parse_ground_truth_mpve(ground_truth: str) -> list[dict[str, Any]]:\n","  json_ground_truth = json5.loads(ground_truth.replace(\"\\n\", \"\"))\n","  json_ground_truth.sort(key=lambda x: x[\"index\"])\n","  # remove unnecessary fields for model eval to prevent hallucination\n","  for item in json_ground_truth:\n","    if \"index\" in item:\n","      del item[\"index\"]\n","    if \"paper_id\" in item:\n","      del item[\"paper_id\"]\n","    if \"synonyms\" in item:\n","      del item[\"synonyms\"]\n","  return json_ground_truth\n","\n","\n","def parse_model_response_mpve(model_response: str) -> list[dict[str, Any]]:\n","  \"\"\"Parses model response.\n","\n","  Args:\n","    model_response:\n","\n","  Returns:\n","  \"\"\"\n","  response_text = (\n","      model_response.replace(\"\\n\", \"\")\n","      .removeprefix(\"```json\")\n","      .removesuffix(\"```json\")\n","      .removeprefix(\"```\")\n","      .removesuffix(\"```\")\n","      .removeprefix(\"`\")\n","      .removesuffix(\"`\")\n","  )\n","  try:\n","    formatted_text = re.sub(r\"(?<=\\w)'(?=\\w|\\s)\", \"\\\\'\", response_text)\n","    if not formatted_text:\n","      formatted_text = \"{}\"\n","      print(\"Response_text is empty\")\n","    json_model_response = json5.loads(formatted_text)\n","  except Exception as e:  # pylint: disable=broad-except\n","    print(\"Skipping incomplete last item: \", e)\n","    ind = [m.start() for m in re.finditer(r\",\\s*\\{\", response_text)][-1]\n","    json_model_response = json5.loads(response_text[:ind] + \"]\")\n","  return json_model_response\n","\n","\n","def mpv_model_eval_paper(\n","    record_id: str | None,\n","    ground_truth: str,\n","    model_response: str,\n","    eval_prompt: str,\n","    client: Any,\n",") -> dict[str, Any]:\n","  \"\"\"Runs model evaluation on material properties for a single paper.\n","\n","  Args:\n","    record_id: record id or paper id.\n","    ground_truth: ground truth list in str type.\n","    model_response: model response list in str type.\n","    eval_prompt: eval prompt.\n","    client: llm client.\n","\n","  Returns:\n","    model eval response json.\n","  \"\"\"\n","  json_ground_truth = parse_ground_truth_mpve(ground_truth)\n","  json_model_response = parse_model_response_mpve(model_response)\n","  return model_eval_json(\n","      record_id=record_id,\n","      json_ground_truth=json_ground_truth,\n","      json_model_response=json_model_response,\n","      eval_prompt=eval_prompt,\n","      client=client,\n","  )\n","\n","\n","def filter_ground_truth_properties(ground_truth: str) -> list[dict[str, Any]]:\n","  \"\"\"Filters ground truth to only keep the properties we want to evaluate.\n","\n","  Args:\n","    ground_truth: ground truth list in str type.\n","\n","  Returns:\n","    filtered ground truth list.\n","  \"\"\"\n","  json_ground_truth = json5.loads(ground_truth)\n","  filtered_ground_truth = []\n","  valid_property_names = [\n","      \"bandgap\",\n","      \"band gap\",\n","      \"gap energy\",\n","      \"energy gap\",\n","      \"refractive_index\",\n","      \"refractive index\",\n","      \"index of refraction\",\n","      \"n-value\",\n","      \"n value\",\n","  ]\n","  for item in json_ground_truth:\n","    for valid_property_name in valid_property_names:\n","      if valid_property_name in item[\"property_name\"].lower():\n","        filtered_ground_truth.append(item)\n","        break\n","  return filtered_ground_truth\n","\n","\n","def mpve_domain_expert_model_based_eval(\n","    ground_truth: str,\n","    model_response: str,\n","    client: Any | None = None,\n","    eval_prompt: str = _EVAL_PROMPT_FILENAME,\n","    verbose: bool = True,\n",") -> dict[str, Any]:\n","  \"\"\"Runs model based eval on material properties.\n","\n","  Args:\n","    ground_truth: ground truth list in str type.\n","    model_response: model response list in str type.\n","    client: llm client.\n","    eval_prompt: eval prompt.\n","    verbose: whether to print out eval results.\n","\n","  Returns:\n","    eval result.\n","  \"\"\"\n","  if verbose:\n","    print(\"Model eval started...\")\n","  eval_output_item = mpv_model_eval_paper(\n","      record_id=None,\n","      ground_truth=ground_truth,\n","      model_response=model_response,\n","      eval_prompt=eval_prompt,\n","      client=client,\n","  )\n","  if verbose:\n","    print(\"Model eval finished.\")\n","  eval_result = eval_overall_result(\n","      eval_output_item, verbose=verbose\n","  )\n","  if verbose:\n","    print(\"Eval results:\\n\", eval_result)\n","  return eval_result\n","\n","def load_matsci_prompt(filepath: str) -> str:\n","  \"\"\"Loads matsci prompt.\n","\n","  Args:\n","    filepath: filepath of prompt.\n","\n","  Returns:\n","    Loaded prompt.\n","  \"\"\"\n","  # return resources.GetResource(filepath).decode(\"utf-8\").strip()\n","  with open(filepath, 'r') as file:\n","    text_content = file.read()\n","  return text_content.strip()\n","\n","\n","\n","\n","\n","def eval_overall_result(\n","    eval_output_item: dict[str, Any], verbose: bool = False\n",") -> dict[str, Any]:\n","  \"\"\"Gets overall eval result.\n","\n","  Args:\n","    eval_output_item: eval output item.\n","    verbose: whether to print model eval original output.\n","\n","  Returns:\n","    overall eval result.\n","  \"\"\"\n","  num_match = sum([\n","      1 if (\"json_extracted_index\" in item) else 0\n","      for item in eval_output_item[\"response_json\"]\n","  ])\n","  if verbose:\n","    print(\"Model eval original output:\\n\", eval_output_item)\n","  num_gt = eval_output_item[\"ground_truth_length\"]\n","  num_response = eval_output_item[\"model_response_length\"]\n","  pre = min(num_match / num_response if num_response else np.nan, 1.0)\n","  rec = min(num_match / num_gt if num_gt else np.nan, 1.0)\n","  return {\n","      \"num_match\": num_match,\n","      \"num_ground_truth\": num_gt,\n","      \"num_model_response\": num_response,\n","      \"precision\": pre,\n","      \"recall\": rec,\n","      \"f1\": 2.0 * pre * rec / (pre + rec) if pre + rec else 0.0,\n","  }"],"metadata":{"id":"z6ufJ9PGHxo0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## bert eval"],"metadata":{"id":"NwlQaQlVmRcy"}},{"cell_type":"code","source":["def get_bert_score(prediction, reference):\n","  precision, recall, F1 = score([prediction], [reference], lang=\"en\", verbose=False)\n","  return {\"bert_precision\": precision.item(), \"bert_recall\" : recall.item(), \"bert_F1\": F1.item()}"],"metadata":{"id":"cXZW-yhWRkLv"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## rouge eval"],"metadata":{"id":"gHb00g_6mTRS"}},{"cell_type":"code","source":["import six\n","import collections\n","\n","class AggregateScore(\n","    collections.namedtuple(\"AggregateScore\", [\"low\", \"mid\", \"high\"])):\n","  \"\"\"Tuple containing confidence intervals for scores.\"\"\"\n","\n","class BootstrapAggregator(object):\n","  \"\"\"Aggregates scores to provide confidence intervals.\n","\n","  Sample usage:\n","    scorer = rouge_scorer.RougeScorer(['rouge1', 'rougeL'])\n","    aggregator = Aggregator()\n","    aggregator.add_scores(scorer.score(\"one two three\", \"one two\"))\n","    aggregator.add_scores(scorer.score(\"one two five six\", \"seven eight\"))\n","    result = aggregator.aggregate()\n","    print result\n","    {'rougeL': AggregateScore(\n","         low=Score(precision=0.0, recall=0.0, fmeasure=0.0),\n","         mid=Score(precision=0.5, recall=0.33, fmeasure=0.40),\n","         high=Score(precision=1.0, recall=0.66, fmeasure=0.80)),\n","     'rouge1': AggregateScore(\n","         low=Score(precision=0.0, recall=0.0, fmeasure=0.0),\n","         mid=Score(precision=0.5, recall=0.33, fmeasure=0.40),\n","         high=Score(precision=1.0, recall=0.66, fmeasure=0.80))}\n","  \"\"\"\n","\n","  def __init__(self, confidence_interval=0.95, n_samples=1000):\n","    \"\"\"Initializes a BootstrapAggregator object.\n","\n","    Args:\n","      confidence_interval: Confidence interval to compute on the mean as a\n","        decimal.\n","      n_samples: Number of samples to use for bootstrap resampling.\n","\n","    Raises:\n","      ValueError: If invalid argument is given.\n","    \"\"\"\n","\n","    if confidence_interval < 0 or confidence_interval > 1:\n","      raise ValueError(\"confidence_interval must be in range [0, 1]\")\n","    if n_samples <= 0:\n","      raise ValueError(\"n_samples must be positive\")\n","\n","    self._n_samples = n_samples\n","    self._confidence_interval = confidence_interval\n","    self._scores = collections.defaultdict(list)\n","\n","  def add_scores(self, scores):\n","    \"\"\"Adds a sample for future aggregation.\n","\n","    Args:\n","      scores: Dict mapping score_type strings to a namedtuple object/class\n","        representing a score.\n","    \"\"\"\n","\n","    for score_type, score in six.iteritems(scores):\n","      self._scores[score_type].append(score)\n","\n","  def aggregate(self):\n","    \"\"\"Aggregates scores previously added using add_scores.\n","\n","    Returns:\n","      A dict mapping score_type to AggregateScore objects.\n","    \"\"\"\n","\n","    result = {}\n","    for score_type, scores in six.iteritems(self._scores):\n","      # Stack scores into a 2-d matrix of (sample, measure).\n","      score_matrix = np.vstack(tuple(scores))\n","      # Percentiles are returned as (interval, measure).\n","      percentiles = self._bootstrap_resample(score_matrix)\n","      # Extract the three intervals (low, mid, high).\n","      intervals = tuple(\n","          (scores[0].__class__(*percentiles[j, :]) for j in range(3)))\n","      result[score_type] = AggregateScore(\n","          low=intervals[0], mid=intervals[1], high=intervals[2])\n","    return result\n","\n","  def _bootstrap_resample(self, matrix):\n","    \"\"\"Performs bootstrap resampling on a matrix of scores.\n","\n","    Args:\n","      matrix: A 2-d matrix of (sample, measure).\n","\n","    Returns:\n","      A 2-d matrix of (bounds, measure). There are three bounds: low (row 0),\n","      mid (row 1) and high (row 2). Mid is always the mean, while low and high\n","      bounds are specified by self._confidence_interval (which defaults to 0.95\n","      meaning it will return the 2.5th and 97.5th percentiles for a 95%\n","      confidence interval on the mean).\n","    \"\"\"\n","\n","    # Matrix of (bootstrap sample, measure).\n","    sample_mean = np.zeros((self._n_samples, matrix.shape[1]))\n","    for i in range(self._n_samples):\n","      sample_idx = np.random.choice(\n","          np.arange(matrix.shape[0]), size=matrix.shape[0])\n","      sample = matrix[sample_idx, :]\n","      sample_mean[i, :] = np.mean(sample, axis=0)\n","\n","    # Take percentiles on the estimate of the mean using bootstrap samples.\n","    # Final result is a (bounds, measure) matrix.\n","    percentile_delta = (1 - self._confidence_interval) / 2\n","    q = 100 * np.array([percentile_delta, 0.5, 1 - percentile_delta])\n","    return np.percentile(sample_mean, q, axis=0)\n","\n","def _prepare_summary_rouge(summary):\n","  # Make sure the summary is not bytes-type\n","  # Add newlines between sentences so that rougeLsum is computed correctly.\n","  summary = summary.replace(\" . \", \" .\\n\")\n","  return summary\n","\n","def get_rouge_score(prediction, reference):\n","  score_keys = ['rouge1', 'rouge2', 'rougeLsum']\n","  predictions = [prediction]\n","  targets = [reference]\n","  scorer = rouge_scorer.RougeScorer(score_keys)\n","  count = 0\n","  sum_scores = collections.defaultdict(float)\n","  for prediction, target in zip(predictions, targets):\n","    target = _prepare_summary_rouge(target)\n","    prediction = _prepare_summary_rouge(prediction)\n","    scores = scorer.score(target=target, prediction=prediction)\n","    count += 1\n","    for k, v in scores.items():\n","      sum_scores[k] += v.fmeasure\n","  if count == 0:\n","    raise ValueError(\"Predictions and targets must both have nonzero length\")\n","  result = {k: v / count for k, v in sum_scores.items()}\n","  return {key: result[key] * 100 for key in score_keys}"],"metadata":{"id":"4vaHHyi3VIyI"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## biogr eval"],"metadata":{"id":"7zqg5F8Ll9BO"}},{"cell_type":"code","source":["def center_of_bbox(json_coords: dict[str, float]) -> dict[str, float]:\n","  # NOTE: This doesn't work if you wrap around the 180 --> -179\n","  # longitude line in the Pacific but we don't have it in our data.\n","  bbox_center = {}\n","  bbox_center[\"lat\"] = np.mean([json_coords[\"S\"], json_coords[\"N\"]])\n","  bbox_center[\"lng\"] = np.mean([json_coords[\"E\"], json_coords[\"W\"]])\n","  return bbox_center\n","\n","\n","def compute_distance(\n","    lat1_deg: float, lng1_deg: float, lat2_deg: float, lng2_deg: float\n",") -> float:\n","  \"\"\"Computes the distance between two points on a sphere in meters.\n","\n","  Args:\n","    lat1_deg: Latitude of the first point in degrees.\n","    lng1_deg: Longitude of the first point in degrees.\n","    lat2_deg: Latitude of the second point in degrees.\n","    lng2_deg: Longitude of the second point in degrees.\n","\n","  Returns:\n","    The distance between the two points in meters.\n","  \"\"\"\n","  # Haversine Formula for the geodesic distance on a sphere.\n","  # See https://en.wikipedia.org/wiki/Haversine_formula.\n","  lat1 = np.deg2rad(lat1_deg)\n","  lng1 = np.deg2rad(lng1_deg)\n","  lat2 = np.deg2rad(lat2_deg)\n","  lng2 = np.deg2rad(lng2_deg)\n","\n","  alpha = np.sin((lat2 - lat1) * 0.5)\n","  gamma = np.sin((lng2 - lng1) * 0.5)\n","  alpha = alpha * alpha + np.cos(lat1) * np.cos(lat2) * gamma * gamma\n","  if alpha > 1.0:\n","    alpha = 1.0  # bulletproof sqrt(1-alpha)\n","  gamma = 2.0 * np.arctan2(np.sqrt(alpha), np.sqrt(1.0 - alpha))\n","  return 6371000 * gamma\n","\n","\n","def compute_center_error_km(\n","    center_prediction: dict[str, float], center_ground_truth: dict[str, float]\n",") -> float:\n","  return 0.001 * compute_distance(\n","      center_prediction[\"lat\"],\n","      center_prediction[\"lng\"],\n","      center_ground_truth[\"lat\"],\n","      center_ground_truth[\"lng\"],\n","  )\n","\n","\n","def compute_box_size_km(coords: dict[str, float]) -> float:\n","  # Returns half of the diagonal (e.g. like half of a TV). This corresponds\n","  # to the radius of a circle that inscribes the rectangle.\n","  return (\n","      0.001\n","      * 0.5\n","      * compute_distance(coords[\"S\"], coords[\"W\"], coords[\"N\"], coords[\"E\"])\n","  )\n","\n","\n","def compute_distance_metrics(\n","    prediction: dict[str, float], ground_truth: dict[str, float]\n",") -> dict[str, float]:\n","  \"\"\"Computes distance metrics between the prediction and ground truth.\n","\n","  Computes two distance metrics:\n","  normalized_distance_error - Distance between the center of the predicted\n","  bounding box and the center of the ground truth bounding box, normalized by\n","  the ground truth box radius.\n","  relative_box_size - Ratio of predicted box size to ground truth box size\n","  (using the diagonal length as the size metric).\n","\n","  Args:\n","    prediction: A dictionary with the prediction coordinates.\n","    ground_truth: A dictionary with the ground truth coordinates.\n","\n","  Returns:\n","    A dictionary with the normalized distance error between the predicted and\n","    ground truth box centers and the relative size of the predicted box.\n","  \"\"\"\n","\n","  center_ground_truth = center_of_bbox(ground_truth)\n","  center_prediction = center_of_bbox(prediction)\n","  center_error_km = compute_center_error_km(\n","      center_prediction, center_ground_truth\n","  )\n","\n","  ground_truth_box_size_km = compute_box_size_km(ground_truth)\n","  normalized_distance_error = center_error_km / ground_truth_box_size_km\n","\n","  prediction_box_size_km = compute_box_size_km(prediction)\n","  relative_size = prediction_box_size_km / ground_truth_box_size_km\n","\n","  return {\n","      \"normalized_distance_error\": normalized_distance_error,\n","      \"relative_box_size\": relative_size,\n","  }\n","\n","def coords_to_box(coords: dict[str, float]) -> np.ndarray:\n","  return np.array([coords[\"W\"], coords[\"S\"], coords[\"E\"], coords[\"N\"]])\n","\n","\n","def parse_biodiversity_response(model_response: str) -> dict[str, float]:\n","  \"\"\"Parses a model response string into a dictionary of coordinates.\n","\n","  Args:\n","    model_response: The model response string to be parsed.\n","\n","  Returns:\n","    A dictionary containing the W, E, S, N values.\n","\n","  Raises:\n","    ValueError: If the model response string cannot be parsed into either of the\n","      supported formats.\n","  \"\"\"\n","  if \"{\" in model_response and \"}\" in model_response:\n","    cleaned_response = model_response[\n","        model_response.find(\"{\") : model_response.rfind(\"}\") + 1\n","    ]\n","    return json5.loads(cleaned_response)\n","  if all(key in model_response for key in [\"W\", \"E\", \"S\", \"N\"]):\n","    return {\n","        \"W\": float(model_response.split('\"W\":')[-1].split(\",\")[0].split()[0]),\n","        \"E\": float(model_response.split('\"E\":')[-1].split(\",\")[0].split()[0]),\n","        \"S\": float(model_response.split('\"S\":')[-1].split(\",\")[0].split()[0]),\n","        \"N\": float(model_response.split('\"N\":')[-1].split(\",\")[0].split()[0]),\n","    }\n","  raise ValueError(\"Can not parse model response\")\n","\n","\n","def bb_intersection_over_union(box_a: np.ndarray, box_b: np.ndarray) -> float:\n","  \"\"\"Calculates the Intersection over Union (IoU) between two bounding boxes.\n","\n","  Args:\n","    box_a: A list of coordinates representing the first bounding box.\n","    box_b: A list of coordinates representing the second bounding box.\n","\n","  Returns:\n","    The IoU value, a float between 0 and 1.\n","    0 indicates no overlap and 1 indicates perfect overlap.\n","  \"\"\"\n","\n","  def _intersection_area(box_a: np.ndarray, box_b: np.ndarray) -> float:\n","    x_a = max(box_a[0], box_b[0])\n","    y_a = max(box_a[1], box_b[1])\n","    x_b = min(box_a[2], box_b[2])\n","    y_b = min(box_a[3], box_b[3])\n","\n","    width = x_b - x_a\n","    height = y_b - y_a\n","    if (width < 0) or (height < 0):\n","      return 0.0\n","    return width * height\n","\n","  def _area(box: np.ndarray) -> float:\n","    return (box[2] - box[0]) * (box[3] - box[1])\n","\n","  inter_area = _intersection_area(box_a, box_b)\n","  union_area = _area(box_a) + _area(box_b) - inter_area\n","  return inter_area / float(union_area)\n","\n","\n","def biodiversity_georeferencing_eval(\n","    model_response: str, ground_truth: str, verbosity: int = 0\n",") -> dict[str, Union[float, str]]:\n","  \"\"\"Computes IOU between ground truth and model response bounding boxes.\n","\n","  Args:\n","    ground_truth: A JSON string with lat/lng bounding box coordinates\n","    model_response: A JSON string with the model response.\n","    verbosity: Used for debugging.\n","\n","  Returns:\n","    A dictionary with IOU keyed as \"iou\".\n","  \"\"\"\n","  # Load in ground truth coordinates.\n","  ground_truth_coords = json5.loads(ground_truth)\n","\n","  try:\n","    predicted_coords = parse_biodiversity_response(model_response)\n","  except Exception:  # pylint: disable=broad-except\n","    if verbosity > 0:\n","      print(\"Failed to extract coords from model response: \", model_response)\n","    return {\"iou\": \"Can not parse model response\"}\n","\n","  iou = bb_intersection_over_union(\n","      coords_to_box(ground_truth_coords), coords_to_box(predicted_coords)\n","  )\n","\n","  distance_metrics = compute_distance_metrics(\n","      predicted_coords, ground_truth_coords\n","  )\n","  biogr_metrics = {\n","      \"iou\": iou,\n","      \"normalized_distance_error\": distance_metrics[\n","          \"normalized_distance_error\"\n","      ],\n","      \"relative_box_size\": distance_metrics[\"relative_box_size\"],\n","  }\n","  return biogr_metrics"],"metadata":{"id":"9m4pj32Pi2y_"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## pdb eval"],"metadata":{"id":"SBaTJhefmM8l"}},{"cell_type":"code","source":["def best_sequence_alignment_counts(\n","    sequence_1: str, sequence_2: str\n",") -> Dict[str, Union[str, int]]:\n","  \"\"\"Calculates the counts of gaps, identities, and mismatches in the best alignment of two sequences.\n","\n","  Args:\n","    sequence_1: The first sequence to be aligned.\n","    sequence_2: The second sequence to be aligned.\n","\n","  Returns:\n","    A dictionary containing the counts of gaps, identities, and mismatches:\n","      - \"n_gaps\": Number of gap characters introduced in the alignment.\n","      - \"n_identities\": Number of positions where the characters are identical.\n","      - \"n_mismatches\": Number of positions where the characters are different.\n","      - \"normalized_levenshtein_distance\": Levenshtein distance divided by the\n","          length of the longer sequence. Levenshtein distance is the minimum\n","          number of edits needed to transform one sequence into another.\n","      - \"identity_ratio\": n_identities divided by the length of the alignment.\n","  \"\"\"\n","  # Create an alignment object.\n","  sequence_1 = sequence_1 if sequence_1 else \" \"\n","  sequence_2 = sequence_2 if sequence_2 else \" \"\n","  aligner = Align.PairwiseAligner()\n","  best_alignment = aligner.align(sequence_1, sequence_2)[0]\n","\n","  max_length = max(len(sequence_1), len(sequence_2))\n","  if max_length == 0:\n","    normalized_distance = \"Zero length sequences\"\n","  else:\n","    normalized_distance = (\n","        Levenshtein.distance(sequence_1, sequence_2) / max_length\n","    )\n","  if not best_alignment[0]:\n","    identity_ratio = \"Zero length alignment\"\n","  else:\n","    identity_ratio = best_alignment.counts().identities / len(best_alignment[0])\n","\n","  return {\n","      \"n_gaps\": best_alignment.counts().gaps,\n","      \"n_identities\": best_alignment.counts().identities,\n","      \"n_mismatches\": best_alignment.counts().mismatches,\n","      \"normalized_levenshtein_distance\": normalized_distance,\n","      \"identity_ratio\": identity_ratio,\n","  }\n","\n","def pdb_reconstruction_eval(\n","    model_response: str,\n","    ground_truth_json_str: str,\n",") -> dict[str, Union[str, float]]:\n","  \"\"\"Evaluates the alignment of a predicted sequence.\n","\n","  Args:\n","    ground_truth_json_str: A json string containing the ground truth protein\n","      sequence data.\n","    model_response: A string containing the model's response, also expected to\n","      have the predicted protein sequence on the line following a '>' line.\n","\n","  Returns:\n","    A dictionary containing sequence alignment metrics.\n","  \"\"\"\n","  try:\n","    targets = json5.loads(ground_truth_json_str)[\"sequence\"]\n","  except ValueError:\n","    return {\n","        \"n_gaps\": \"Can not parse ground turh\",\n","        \"n_identities\": \"Can not parse ground turh\",\n","        \"n_mismatches\": \"Can not parse ground turh\",\n","        \"normalized_levenshtein_distance\": \"Can not parse ground turh\",\n","        \"identity_ratio\": \"Can not parse ground turh\",\n","        \"rouge1\": \"Can not parse ground turh\",\n","        \"rouge2\": \"Can not parse ground turh\",\n","        \"rougeLsum\": \"Can not parse ground turh\",\n","    }\n","  model_response = model_response.replace(\"\\u003E\", \">\")\n","  lines = model_response.splitlines()\n","  for i, line in enumerate(lines):\n","    if line.startswith(\">\") and i < len(lines) - 1:\n","      parsed_model_response = lines[i + 1]\n","      pdb_eval_results = best_sequence_alignment_counts(\n","          targets, parsed_model_response\n","      )\n","\n","      return pdb_eval_results\n","  return {\n","      \"n_gaps\": \"Can not parse model response\",\n","      \"n_identities\": \"Can not parse model response\",\n","      \"n_mismatches\": \"Can not parse model response\",\n","      \"normalized_levenshtein_distance\": \"Can not parse model response\",\n","      \"identity_ratio\": \"Can not parse model response\",\n","      \"rouge1\": \"Can not parse model response\",\n","      \"rouge2\": \"Can not parse model response\",\n","      \"rougeLsum\": \"Can not parse model response\",\n","  }\n"],"metadata":{"id":"4A4r9tDe-itO"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# run to get eval results"],"metadata":{"id":"wH5McmXXBnEp"}},{"cell_type":"markdown","source":["## static configs"],"metadata":{"id":"brIrWo-gPzB8"}},{"cell_type":"code","source":["_SHARED_METRCS = [get_rouge_score, get_bert_score]\n","_ADDITIONAL_METRICS = {\n","    \"pdb\": {\n","        \"reconstruct_protein_amino_acid_sequence_0_shot\": {\n","            pdb_reconstruction_eval\n","        },\n","    },\n","    \"mpve\": {\n","        \"mat_paper_to_property_1_shot\": {\n","            get_lmsim_score_mpve\n","        },\n","        \"mat_paper_to_property_1_shot_exclude_trivia\": {\n","            get_lmsim_score_mpve\n","        },\n","        \"mat_paper_to_property_1_shot_bandgap_refractive\": {\n","            get_lmsim_score_mpve\n","        }\n","    },\n","    \"dft\": {\n","        \"extract_structure_data_1_shot\": {\n","            get_lmsim_score_dft\n","        },\n","        \"extract_dft_metadata_1_shot\": {\n","            get_lmsim_score_dft\n","        },\n","    },\n","    \"biogr\": {\n","        \"georeference_image_0_shot\": {\n","            biodiversity_georeferencing_eval\n","        }\n","    }\n","\n","}\n","_LLM_LIST = [\"command-r-plus\", \"longllama\", \"mixtral-gcp\",\n","             \"gemini-1.5-flash-latest\", \"gemini-1.0-pro\", \"gemini-1.5-pro-latest\",\n","             \"gpt-4o\", \"claude-3-opus-20240229\"]\n","_BIOGR_EXCLUDE_LLM = [\"command-r-plus\", \"longllama\", \"mixtral-gcp\"]\n","_TASK_EVAL_CONFIGS = {\n","    \"hfe\": {\n","        \"extract_hamiltonian_0_shot\": {\n","        }\n","    },\n","    \"hfd\": {\n","        \"derivation_prompt\": {\n","        }\n","    },\n","    \"qecc_65\": {\n","        \"describe_code_in_paper\": {\n","        }\n","    },\n","    \"qecc_pdf\": {\n","        \"describe_code_in_paper\": {\n","        }\n","    },\n","    \"qecc_clean_raw\": {\n","        \"describe_code_in_paper\": {\n","        }\n","    },\n","    \"qecc_clean_curated\": {\n","        \"describe_code_in_paper\": {\n","        }\n","    },\n","    \"pdb\": {\n","        \"reconstruct_protein_amino_acid_sequence_0_shot\": {\n","        }\n","    },\n","    \"mpve\": {\n","        \"mat_paper_to_property_1_shot\": {\n","        },\n","        \"mat_paper_to_property_1_shot_bandgap_refractive\": {\n","        },\n","        \"mat_paper_to_property_1_shot_exclude_trivia\": {\n","        },\n","    },\n","    \"dft\": {\n","        \"write_code_for_paper_0_shot\": {\n","        },\n","        \"extract_structure_data_1_shot\": {\n","        },\n","        \"extract_dft_metadata_1_shot\": {\n","        },\n","    },\n","    \"geo\": {\n","        \"extract_dataset_from_geo_papers_0_shot\": {\n","        }\n","    },\n","    \"biogr\": {\n","        \"georeference_image_0_shot\": {\n","        }\n","    },\n","}\n","all_ids_per_task = {'pdb': ['1A12', '1A33', '1AIL', '1AOA', '1AQA', '1AZS', '1BL8', '1BM8', '1BXO', '1CC5', '1CDK', '1CGF', '1CLL', '1CTF', '1DIN', '1DXX', '1E9H', '1EST', '1F9V', '1G6X', '1GOF', '1GP1', '1HCG', '1HHO', '1HNF', '1HNV', '1IAV', '1IGM', '1IGT', '1JM1', '1KXQ', '1M03', '1M17', '1M8Q', '1MBG', '1MBO', '1MHC', '1NKO', '1POH', '1PRC', '1R09', '1RCP', '1RGS', '1SBT', '1SU4', '1TIT', '1TNK', '1UBQ', '2A99', '2ACE', '2AYN', '2J1N', '2POR', '2R6G', '3ADN', '3C7E', '3LCK', '3R2E', '4CPA', '5CPA', '5HZN', '7B3N', '7L1E', '7V8O'], 'biogr': ['10212153_1', '260729_2', '531730_1', '556058_2', '563682_1', '564487_1', '575983_2', '578304_2', '583537_1', '585031_1', '587419_1', '590257_1', '591038_1', '592166_1', '592526_1', '592805_4', '594665_1', 'S0048969724009641_1', 'S1470160X22006951_1', 'ece310733_1', 'jwmg22383_1', 's41598022209644_1', 's41598023276709_1', 's4159802334533_1'], 'geo': ['00000', '14614a88b3e44e601c5cf8f71b5e07ca989beb0b', '213d2232a49507f81b4e17e50de7675c88fbc672', '33b0925f7681f3199a5d075324e7f3c5e33f2c76', '41f20bb04729a55ca9c2eaf579adf3ed5729044b', '54a9885771350f38135f30f43ef874e0a30be07b', '5c37c2aa2e108e17e37c6db29a4e5afe6a811119', '7dc47696eb876d85a3dfc6884f61fa8832d5e5e8', '83a1a10e3a2416e1d93bc3dbb482db4ccb707eda', '850ca33e8c1853c1735da63073ec3910bce91ddc', '9bdabc37e4af91c4fb53e205502204b510e3b972', 'a09b49e5f2c6b818e479bd29343eae9005f8ca26', 'ab6d648944f306fa1e2d275115b94d36478d9d2a', 'b90358f971e19a60c305acff2867b89dd197fdf6', 'c3a3a5a24206a9b38d9f4727f78cc8f323e398b2', 'e57ae1987bce88add50696843c8979456ce55561', 'e88aa0bccedc5f07bfee8f2db7a85351e65ec24a', 'e900993457d4d256cbfbe8a7527b6745f130a98e', 'e9c8932d5fcdf067821f8bf24b7462e5c7f73054'], 'hfd': ['1010.1819', '1106.6060', '1208.0116', '1310.2674', '1508.00296', '1812.04213', '2004.04168', '2008.08998', '2012.04554', '2108.02159', '2110.11330', '2111.01152', '2112.07523', '2308.03843', '2308.07488'], 'hfe': ['1010.1819', '1112.4222', '1202.4956', '1206.0608', '1208.0116', '1212.5363', '1401.2167', '1506.01488', '1507.06420', '1510.06887', '1512.02398', '1601.00996', '1812.04213', '1908.05417', '2007.15166', '2008.08998', '2102.13507', '2108.02159', '2111.09813', '2112.07523', '2206.10024', '2208.07620', '2209.15374', '2210.06674', '2210.08025', '2210.14517', '2302.04864', '2303.09821', '2303.18025', '2306.02127', '2306.12486', '2307.03793', '2307.04307', '2307.07531', '2307.11810', '2308.01997', '2308.03843', '2311.13191'], 'qecc_65': ['1501.07779', '1502.05267', '1503.06237', '1503.08800', '1505.02576', '1602.00008', '1603.04442', '1604.07925', '1703.02973', '1707.02308', '1708.08474', '1709.04471', '1709.08658', '1710.04631', '1712.07666', '1801.05897', '1802.07419', '1805.01474', '1809.09801', '1903.03937', '1906.11394', '1907.09528', '1910.10746', '2003.02717', '2007.09154', '2007.12152', '2008.09495', '2009.03921', '2010.06628', '2106.02649', '2107.02194', '2110.11510', '2112.01446', '2201.07802', '2203.00103', '2203.16534', '2209.11405', '2210.10808', '2210.16957', '2212.09935', '2303.02432', '2303.04798', '2306.11621', '2309.16503', '2311.07679', '2311.08653', '2311.13040', '2312.04522', '2402.07476', 'cond-mat_0010440', 'cond-mat_0607736', 'cond-mat_9707273', 'cs_0509062', 'quant-ph_0008040', 'quant-ph_0210097', 'quant-ph_0502086', 'quant-ph_0605138', 'quant-ph_0701020', 'quant-ph_0702075', 'quant-ph_9703002', 'quant-ph_9705052', 'quant-ph_9711021', 'quant-ph_9711049', 'quant-ph_9810055', 'quant-ph_9906114'], 'dft': ['2023_09_22_01b9cdba467fd7882e42g', '2023_09_22_07b4d66e23971ccb85c0g', '2023_09_22_0ce1b5ea9a8637db5435g', '2023_09_22_109a6cd5d015ce89e7f3g', '2023_09_22_12cb692c6b82606615a6g', '2023_09_22_13bcf90c3ef43f1413deg', '2023_09_22_14ab0a44fc8fc33fa338g', '2023_09_22_14ddd903c0b77b5e50c2g', '2023_09_22_182e0132c513bc81a414g', '2023_09_22_1a3a4803f9d9cec16d38g', '2023_09_22_1af7e6342ebcf1ce3ea5g', '2023_09_22_1b00ed3a142a7a1b2582g', '2023_09_22_1def59bea80d6e9f67ccg', '2023_09_22_22c19cfc32d2575f9a52g', '2023_09_22_24d7d9ed97e042af9f29g', '2023_09_22_2d35eebe2e85cecf4103g', '2023_09_22_2d44dda253969d6ce7f6g', '2023_09_22_2e5b7c3f50b6a643e33ag', '2023_09_22_2e9b1b9bffe7fd47b18fg', '2023_09_22_39b7d4444fd6ff852b12g', '2023_09_22_3ae1fab1e33569c30b8dg', '2023_09_22_430c3ddffa99af6a2545g', '2023_09_22_433b6bb3bfc2391f7300g', '2023_09_22_48fb54662c601e035a91g', '2023_09_22_49d6cc9c5e7a469afee0g', '2023_09_22_4eeeb89f0a6f52e58610g', '2023_09_22_4ef39bb4116ac1dad9e9g', '2023_09_22_5237e17b3b341fecc9d9g', '2023_09_22_54050a76c33463a8157fg', '2023_09_22_55f975d508230ef05caeg', '2023_09_22_63a752c620bbc784200cg', '2023_09_22_67e874a3c664208e2d2fg', '2023_09_22_6ac063e0fb85cfc10dd0g', '2023_09_22_70326f83ce0dcec87b50g', '2023_09_22_7433a6c7542334063731g', '2023_09_22_77a765fcab6029c666b4g', '2023_09_22_799ee1c298d190145c70g', '2023_09_22_7c5bbe7e076779b790ccg', '2023_09_22_7c76b066edb1f6f53739g', '2023_09_22_7dab45b11a3ede362147g', '2023_09_22_8181c4d6fa78a2ea82dag', '2023_09_22_81b3dfeb3597db5200c5g', '2023_09_22_84af4abb781aeead403eg', '2023_09_22_87d405f182ae3706ea0cg', '2023_09_22_8b46d7b3e561e7f28495g', '2023_09_22_8df0b56e310badc55de3g', '2023_09_22_900c617369212d6bc72fg', '2023_09_22_910aca2a500d3bf9bf47g', '2023_09_22_980121c407cbdaa46afdg', '2023_09_22_984f5b905c02b6f21733g', '2023_09_22_995805c76f676dddab4fg', '2023_09_22_9a007c3865721f379b39g', '2023_09_22_9a591ebf98377fd0ebe2g', '2023_09_22_9e2bc88db643c6ba8aa0g', '2023_09_22_a0271d2dc7b0f2506498g', '2023_09_22_b0501f9057db320b8ad9g', '2023_09_22_b2865949a80ad08a2835g', '2023_09_22_bba019fc933fc84ad347g', '2023_09_22_cb81fee8faa69f4d7078g', '2023_09_22_cc792b66f9a5779f9798g', '2023_09_22_cff3389f103b8f7971d0g', '2023_09_22_d84d81c022c4b2981048g', '2023_09_22_d90e94cbd96e4b6ddb8bg', '2023_09_22_dd9f0f77c116dc99583ag', '2023_09_22_ddfb75e0fb765dc682bbg', '2023_09_22_e06d11a6e698afe5f2d7g', '2023_09_22_e32d0198a1f3dddb5ba2g', '2023_09_22_e69f3d7ce6c4ff487115g', '2023_09_22_e8d1bc2fb9f3dce5f341g', '2023_09_22_edae82c7fbe0c4062118g', '2023_09_22_efbe854b8da1545fbe9bg', '2023_09_22_f752dc9d5ac72657e3f5g', '2023_09_22_f7714e3a468c91c6f56ag', '2023_09_22_f8875eb68affb0a6cb2bg'], 'mpve': ['10222315', '11093908', '11181068', '12841719', '135893324', '137261967', '137362119', '15804005', '17645319', '2837337', '317542', '53384093', '53519111', '55005437', '6183251', '68518', '97574650']}"],"metadata":{"id":"sTqvJmb_BxBa"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## helper functions"],"metadata":{"id":"lsiSmrqpPslm"}},{"cell_type":"code","source":["def get_annotated_structure_metadata_and_dft_params(\n","    gt_paper_code: str, verbose: int = 0\n",") -> dict[str, list[str]]:\n","  \"\"\"Returns structure metadata and dft params from the ground truth code.\n","\n","  Args:\n","    gt_paper_code: The ground truth code from .py file as a string.\n","    verbose: The verbosity level.\n","  \"\"\"\n","  structures = []\n","  dft_params = []\n","\n","  paper = gt_paper_code\n","  if \"structure_metadata_\" in paper:\n","    parts = paper.split(\"structure_metadata_\")[1:]\n","    whole_parts = [\"structure_metadata_\" + part for part in parts]\n","\n","    for part in whole_parts:\n","      if verbose > 1:\n","        print(\"PART:\\n\", part)\n","      if \"parse_raw(\" not in part:\n","        continue\n","      left, right, *_ = part.split(\"parse_raw(\")\n","      if \"StructureMetadata\" in left:\n","        end_struc = \")\"\n","        if \"')\" in right:\n","          end_struc = \"')\"\n","        elif \"'\\n)\" in right:\n","          end_struc = \"'\\n)\"\n","        struc_json = right.split(end_struc)[0].strip()\n","        if verbose > 0:\n","          print(\"Extracted structure:\\n\", struc_json)\n","        # clean_json = struc_json.replace('NaN', '\"NaN\"')\n","        # struc_json = ast.literal_eval(clean_json)\n","        structures.append(struc_json)\n","\n","  if \"dft_params_\" in paper:\n","    parts = paper.split(\"dft_params_\")[1:]\n","    # print(parts)\n","    whole_parts = [\"dft_params_\" + part for part in parts]\n","\n","    for part in whole_parts:\n","      if verbose > 1:\n","        print(\"PART:\\n\", part)\n","      if \"parse_raw(\" not in part:\n","        continue\n","      left, right, *_ = part.split(\"parse_raw(\")\n","      if \"DFTParameters\" in left:\n","        end_struc = \")\"\n","        if \"')\" in right:\n","          end_struc = \"')\"\n","        elif \"'\\n)\" in right:\n","          end_struc = \"'\\n)\"\n","        dft_params_str = right.split(end_struc)[0].strip()\n","        if verbose > 0:\n","          print(\"Extracted dft_param:\\n\", dft_params_str)\n","        # clean_json = dft_params_str.replace('NaN', '\"NaN\"')\n","        # dft_params_str = ast.literal_eval(clean_json)\n","        dft_params.append(dft_params_str)\n","\n","  gt_struc_jsons = []\n","  for struct_metadata in structures:\n","    gt_json = struct_metadata.split(\"'\")[1]\n","    clean_json = gt_json.replace(\"NaN\", '\"NaN\"')\n","    try:\n","      gt_structure_json = ast.literal_eval(clean_json)\n","      gt_struc_jsons.append(gt_structure_json)\n","    except Exception:  # pylint: disable=broad-exception-caught\n","      gt_struc_jsons.append(clean_json)\n","\n","  gt_dft_params_jsons = []\n","  for dft_param in dft_params:\n","    gt_json = dft_param.split(\"'\")[1]\n","    clean_json = gt_json.replace(\"NaN\", '\"NaN\"')\n","    try:\n","      gt_dft_json = ast.literal_eval(clean_json)\n","      gt_dft_params_jsons.append(gt_dft_json)\n","    except Exception:  # pylint: disable=broad-exception-caught\n","      gt_dft_params_jsons.append(clean_json)\n","\n","  return {\n","      \"structures_metadata\": gt_struc_jsons,\n","      \"dft_params\": gt_dft_params_jsons,\n","  }\n","\n","\n","def preprocess_ground_truth(\n","    ground_truth: str, task_name: str, prompt: str\n",") -> str:\n","  \"\"\"Preprocesses the ground truth before sending to eval.\"\"\"\n","  # Drops the record_ids.\n","  json_gt = json5.loads(ground_truth)\n","  if isinstance(json_gt, dict):\n","    json_gt.pop(\"record_id\", None)\n","    json_gt.pop(\"arxiv_id\", None)\n","    json_gt.pop(\"paper_id\", None)\n","  if isinstance(json_gt, list):\n","    for item in json_gt:\n","      if isinstance(item, dict):\n","        item.pop(\"record_id\", None)\n","        item.pop(\"arxiv_id\", None)\n","        item.pop(\"paper_id\", None)\n","  groundtruth_with_no_ids = json5.dumps(json_gt)\n","  # Preprocess for dft metadata tasks.\n","  if task_name == \"dft\" and prompt == \"extract_dft_metadata_1_shot\":\n","    processed = get_annotated_structure_metadata_and_dft_params(\n","        groundtruth_with_no_ids\n","    )[\"dft_params\"]\n","  elif task_name == \"dft\" and prompt == \"extract_structure_data_1_shot\":\n","    processed = get_annotated_structure_metadata_and_dft_params(\n","        groundtruth_with_no_ids\n","    )[\"structures_metadata\"]\n","  else:\n","    processed = groundtruth_with_no_ids\n","  return str(processed)\n","\n","\n","def read_task_ground_truth_and_response(\n","    ground_truth_path: str,\n","    model_response_path: str,\n",") -> Tuple[str, str, str]:\n","  \"\"\"Reads in the ground truth and response for all tasks.\"\"\"\n","\n","  # Gets the ground truth.\n","  with open(ground_truth_path, \"r\") as f:\n","    ground_truth_info = f.read()\n","\n","  model_response = \"\"\n","  if os.path.exists(model_response_path):\n","    with open(model_response_path, \"r\") as f:\n","      model_response = json5.loads(f.read())\n","      if \"response_text\" in model_response:\n","        model_response = model_response[\"response_text\"]\n","      else:\n","        raise ValueError(\n","            f\"ERROR: The succeeded response for {model_response_path} does not contain response_text.\"\n","        )\n","\n","  failed_model_response = model_response_path.replace(\"success\", \"failure\")\n","  # Gets the response.\n","  exception_message = \"\"\n","  if os.path.exists(failed_model_response):\n","    with open(failed_model_response, \"r\") as f:\n","      ori_model_response = json5.loads(f.read())\n","      if \"exception_message\" in ori_model_response:\n","        exception_message = ori_model_response[\"exception_message\"]\n","      elif \"command-r-plus\" in failed_model_response and \"response_text\" in ori_model_response:\n","        exception_message = ori_model_response[\"response_text\"]\n","      else:\n","        raise ValueError(\n","            f\"ERROR: The failure response for {failed_model_response} does not contain exception message.\"\n","        )\n","\n","  return ground_truth_info, model_response, exception_message"],"metadata":{"id":"Kdc30iBVLY9-"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":[],"metadata":{"id":"qeftS2hwVBKn"}},{"cell_type":"markdown","source":["## calculates metrics"],"metadata":{"id":"mGlcBn9IVDJd"}},{"cell_type":"code","source":["results_json = {}\n","for task in [\"pdb\", \"biogr\", \"geo\", \"hfd\", \"hfe\", \"qecc_65\", \"dft\", \"mpve\"]:\n","  results_json[task] = {}\n","  for prompt in _TASK_EVAL_CONFIGS[task]:\n","    results_json[task][prompt] = {}\n","    for llm_name in _LLM_LIST:\n","      results_json[task][prompt][llm_name] = {}\n","      for record_id in all_ids_per_task[task]:\n","        print(f\"task: {task}, prompt: {prompt}, llm_name: {llm_name}, record_id: {record_id}\")\n","        results_json[task][prompt][llm_name][record_id] = {}\n","        print(f\"{task}, {prompt}, {llm_name}, {record_id}\")\n","        gt_path = os.path.join(file_root_path, \"data\", task, \"ground_truth\", record_id + \".json\")\n","        model_response_path = os.path.join(file_root_path, \"inference_outputs\", task, prompt, llm_name, \"success\", record_id + \".json\")\n","        ground_truth_info, model_response, exception_message = read_task_ground_truth_and_response(gt_path, model_response_path)\n","        ground_truth_info = preprocess_ground_truth(ground_truth_info, task, prompt)\n","        if model_response:\n","          for metric in [_SHARED_METRCS + _ADDITIONAL_METRICS[task]]:\n","            try:\n","              res = metric(model_response, ground_truth_info)\n","              results_json[task][prompt][llm_name][record_id].update(res)\n","            except Exception as e:\n","              print(\"##### ERROR #####\")\n","              print(e)\n","              print(f\"##### skipped {task}, {prompt}, {llm_name}, {record_id} #####\")\n","              continue\n"],"metadata":{"id":"cIgjlh5IVGlW","colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["cbf536fcf00447e3b784304dd29b32fa","bc034f1a7fb44e51a58064275e1e684b","2b58344741ee45ad81cc61650e70c9b1","3018ee985b0d49c6b9f83178a8bff765","8bfcfa9ea642448593d0ff7fac92a995","d5de0e7a099f44e39427782916c3fffc","cccd7a57fc5841649c50e0f875a2607a","5a093e9b94654fdd95dcfc4b71861403","cddf8f1032624f69b66df46b8812c5e9","cbe1d68152d04536b29071d9d8dcbf05","2057d6248e7b45c88267301e3ea0df8f","38a5f31d35ec4d4f919fb8c38dcc9d2d","b1210c7b67144f128e7a5950c89fc76a","6503abd2b4e245bda7e7d88e55673335","50fbac13ff2c49c484259e052e9c0e9b","ce6357ae048f4bb397a5e2cf6f5a0bb9","a90aa476f24e4ced9ec3a57df8534603","75e04c5bccd745fd93a565d10dad2939","8a850f0c410d4ec2995f716008567e81","14bbf20fa7a842739fca7a7bd9f370b3","a081d464af6d470ca1533c2e5564dea6","fec6aa6ccf9b44dd9a6d5758aaa1fda7","496bfd47e50b4c38bfbc213a0cd58d7f","47e9da216afc4280b74d7a312d8d9fe7","16f5d222298b4dce8ccae92a710887da","f1b1c4217ef1424daffb3ca4fd03e75c","a53470e82a3745978b678e02159eaccd","5212e01ecda6495ab7147a97ae79a7c2","3a7b3bd231084bcd8a7cb092d77049aa","521904df4caf4d5b92c414beb2ec5a66","e9af6d04145e4b4ead090f42ff1c0722","9c289b8598cd4336afee7654d5281a3b","82ffad66c60c4c9781a35920dc29227d","afc564454e1a4b75824f916ea8ec8d8b","3c41b40636c44e72a96c82a938442ff2","680334fe747c4bc2bc1e935c8b0b2c63","4ee91bf0763f4a13bba5f8c12021d897","96a86dd3a7b54310bb115030550b1056","79c477295ce047e49bcb7d497c33292b","afd1a7c3f5534608a3a51f48ca2eb6e0","660cb110ccfd44018352e1e7a9c6da02","d33ce93035f14bad9fe5145a43714850","6eebb8beaa14441ba2e819998166cbd0","fcbc36a563894dad980152388e3354df","147941c1ccd84f8fa0f99c6320f6d2a3","573b724d327f4497bea1b071e9638081","15715bc76f2343468b24f7a1415344d1","0ddde77a7b18447f99a16746af30dc9a","c034520d064f4142a09b54b96b246b26","50bea7706d2f44f1834a2f71fa5b581e","5e3dcebc234e4a4cbb93e15364072047","664bed347d6d41158116c427637d7788","aef062741a204d4ba0a98f46d801c929","0e6d40604e7d432697c95a0c8e1fb374","8ae7b0f28a944c72875cb8cc4f26cc1f","3aef8b52cdd14f5f8095455b61efb63a","746833f30a7f482ea229bb9cc5605a74","1c675640c6e64fae9b2442fdd23c1abb","a6f506709cab41e79543a42ab8deb4d0","60398a3b6bdf4f858531737a20b7293e","6bfa536f4f2b44559a55747c58073f9f","6b53c11771cf4a298329718e5a25515f","4e478d6e27b04b99b79bd1fb992ea9d0","d906b7fd8b104f9ba5decdad9ad59928","fa54d587c88343dd8bdbb5aa19d3622c","e422f2af61ca4c989100597d3aa1f515"]},"outputId":"96c045b6-9f99-4717-b1ea-54dc3896b975","executionInfo":{"status":"ok","timestamp":1737489029589,"user_tz":480,"elapsed":4036340,"user":{"displayName":"Jackson Cui","userId":"10266610839923849092"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot, llm_name: command-r-plus, record_id: 10222315\n","mpve, mat_paper_to_property_1_shot, command-r-plus, 10222315\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cbf536fcf00447e3b784304dd29b32fa"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["config.json:   0%|          | 0.00/482 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"38a5f31d35ec4d4f919fb8c38dcc9d2d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"496bfd47e50b4c38bfbc213a0cd58d7f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"afc564454e1a4b75824f916ea8ec8d8b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"147941c1ccd84f8fa0f99c6320f6d2a3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["model.safetensors:   0%|          | 0.00/1.42G [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3aef8b52cdd14f5f8095455b61efb63a"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot, llm_name: command-r-plus, record_id: 11093908\n","mpve, mat_paper_to_property_1_shot, command-r-plus, 11093908\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot, llm_name: command-r-plus, record_id: 11181068\n","mpve, mat_paper_to_property_1_shot, command-r-plus, 11181068\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot, llm_name: command-r-plus, record_id: 12841719\n","mpve, mat_paper_to_property_1_shot, command-r-plus, 12841719\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot, llm_name: command-r-plus, record_id: 135893324\n","mpve, mat_paper_to_property_1_shot, command-r-plus, 135893324\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot, llm_name: command-r-plus, record_id: 137261967\n","mpve, mat_paper_to_property_1_shot, command-r-plus, 137261967\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot, llm_name: command-r-plus, record_id: 137362119\n","mpve, mat_paper_to_property_1_shot, command-r-plus, 137362119\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot, llm_name: command-r-plus, record_id: 15804005\n","mpve, mat_paper_to_property_1_shot, command-r-plus, 15804005\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot, llm_name: command-r-plus, record_id: 17645319\n","mpve, mat_paper_to_property_1_shot, command-r-plus, 17645319\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot, llm_name: command-r-plus, record_id: 2837337\n","mpve, mat_paper_to_property_1_shot, command-r-plus, 2837337\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot, llm_name: command-r-plus, record_id: 317542\n","mpve, mat_paper_to_property_1_shot, command-r-plus, 317542\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot, llm_name: command-r-plus, record_id: 53384093\n","mpve, mat_paper_to_property_1_shot, command-r-plus, 53384093\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot, llm_name: command-r-plus, record_id: 53519111\n","mpve, mat_paper_to_property_1_shot, command-r-plus, 53519111\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot, llm_name: command-r-plus, record_id: 55005437\n","mpve, mat_paper_to_property_1_shot, command-r-plus, 55005437\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot, llm_name: command-r-plus, record_id: 6183251\n","mpve, mat_paper_to_property_1_shot, command-r-plus, 6183251\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot, llm_name: command-r-plus, record_id: 68518\n","mpve, mat_paper_to_property_1_shot, command-r-plus, 68518\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot, llm_name: command-r-plus, record_id: 97574650\n","mpve, mat_paper_to_property_1_shot, command-r-plus, 97574650\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot, llm_name: longllama, record_id: 10222315\n","mpve, mat_paper_to_property_1_shot, longllama, 10222315\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot, llm_name: longllama, record_id: 11093908\n","mpve, mat_paper_to_property_1_shot, longllama, 11093908\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot, llm_name: longllama, record_id: 11181068\n","mpve, mat_paper_to_property_1_shot, longllama, 11181068\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot, llm_name: longllama, record_id: 12841719\n","mpve, mat_paper_to_property_1_shot, longllama, 12841719\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot, llm_name: longllama, record_id: 135893324\n","mpve, mat_paper_to_property_1_shot, longllama, 135893324\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot, llm_name: longllama, record_id: 137261967\n","mpve, mat_paper_to_property_1_shot, longllama, 137261967\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot, llm_name: longllama, record_id: 137362119\n","mpve, mat_paper_to_property_1_shot, longllama, 137362119\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot, llm_name: longllama, record_id: 15804005\n","mpve, mat_paper_to_property_1_shot, longllama, 15804005\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot, llm_name: longllama, record_id: 17645319\n","mpve, mat_paper_to_property_1_shot, longllama, 17645319\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot, llm_name: longllama, record_id: 2837337\n","mpve, mat_paper_to_property_1_shot, longllama, 2837337\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot, llm_name: longllama, record_id: 317542\n","mpve, mat_paper_to_property_1_shot, longllama, 317542\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot, llm_name: longllama, record_id: 53384093\n","mpve, mat_paper_to_property_1_shot, longllama, 53384093\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot, llm_name: longllama, record_id: 53519111\n","mpve, mat_paper_to_property_1_shot, longllama, 53519111\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot, llm_name: longllama, record_id: 55005437\n","mpve, mat_paper_to_property_1_shot, longllama, 55005437\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot, llm_name: longllama, record_id: 6183251\n","mpve, mat_paper_to_property_1_shot, longllama, 6183251\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot, llm_name: longllama, record_id: 68518\n","mpve, mat_paper_to_property_1_shot, longllama, 68518\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot, llm_name: longllama, record_id: 97574650\n","mpve, mat_paper_to_property_1_shot, longllama, 97574650\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot, llm_name: mixtral-gcp, record_id: 10222315\n","mpve, mat_paper_to_property_1_shot, mixtral-gcp, 10222315\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot, llm_name: mixtral-gcp, record_id: 11093908\n","mpve, mat_paper_to_property_1_shot, mixtral-gcp, 11093908\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot, llm_name: mixtral-gcp, record_id: 11181068\n","mpve, mat_paper_to_property_1_shot, mixtral-gcp, 11181068\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot, llm_name: mixtral-gcp, record_id: 12841719\n","mpve, mat_paper_to_property_1_shot, mixtral-gcp, 12841719\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot, llm_name: mixtral-gcp, record_id: 135893324\n","mpve, mat_paper_to_property_1_shot, mixtral-gcp, 135893324\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot, llm_name: mixtral-gcp, record_id: 137261967\n","mpve, mat_paper_to_property_1_shot, mixtral-gcp, 137261967\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot, llm_name: mixtral-gcp, record_id: 137362119\n","mpve, mat_paper_to_property_1_shot, mixtral-gcp, 137362119\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot, llm_name: mixtral-gcp, record_id: 15804005\n","mpve, mat_paper_to_property_1_shot, mixtral-gcp, 15804005\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot, llm_name: mixtral-gcp, record_id: 17645319\n","mpve, mat_paper_to_property_1_shot, mixtral-gcp, 17645319\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot, llm_name: mixtral-gcp, record_id: 2837337\n","mpve, mat_paper_to_property_1_shot, mixtral-gcp, 2837337\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot, llm_name: mixtral-gcp, record_id: 317542\n","mpve, mat_paper_to_property_1_shot, mixtral-gcp, 317542\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot, llm_name: mixtral-gcp, record_id: 53384093\n","mpve, mat_paper_to_property_1_shot, mixtral-gcp, 53384093\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot, llm_name: mixtral-gcp, record_id: 53519111\n","mpve, mat_paper_to_property_1_shot, mixtral-gcp, 53519111\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot, llm_name: mixtral-gcp, record_id: 55005437\n","mpve, mat_paper_to_property_1_shot, mixtral-gcp, 55005437\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot, llm_name: mixtral-gcp, record_id: 6183251\n","mpve, mat_paper_to_property_1_shot, mixtral-gcp, 6183251\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot, llm_name: mixtral-gcp, record_id: 68518\n","mpve, mat_paper_to_property_1_shot, mixtral-gcp, 68518\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot, llm_name: mixtral-gcp, record_id: 97574650\n","mpve, mat_paper_to_property_1_shot, mixtral-gcp, 97574650\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot, llm_name: gemini-1.5-flash-latest, record_id: 10222315\n","mpve, mat_paper_to_property_1_shot, gemini-1.5-flash-latest, 10222315\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot, llm_name: gemini-1.5-flash-latest, record_id: 11093908\n","mpve, mat_paper_to_property_1_shot, gemini-1.5-flash-latest, 11093908\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot, llm_name: gemini-1.5-flash-latest, record_id: 11181068\n","mpve, mat_paper_to_property_1_shot, gemini-1.5-flash-latest, 11181068\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot, llm_name: gemini-1.5-flash-latest, record_id: 12841719\n","mpve, mat_paper_to_property_1_shot, gemini-1.5-flash-latest, 12841719\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot, llm_name: gemini-1.5-flash-latest, record_id: 135893324\n","mpve, mat_paper_to_property_1_shot, gemini-1.5-flash-latest, 135893324\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot, llm_name: gemini-1.5-flash-latest, record_id: 137261967\n","mpve, mat_paper_to_property_1_shot, gemini-1.5-flash-latest, 137261967\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot, llm_name: gemini-1.5-flash-latest, record_id: 137362119\n","mpve, mat_paper_to_property_1_shot, gemini-1.5-flash-latest, 137362119\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot, llm_name: gemini-1.5-flash-latest, record_id: 15804005\n","mpve, mat_paper_to_property_1_shot, gemini-1.5-flash-latest, 15804005\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot, llm_name: gemini-1.5-flash-latest, record_id: 17645319\n","mpve, mat_paper_to_property_1_shot, gemini-1.5-flash-latest, 17645319\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot, llm_name: gemini-1.5-flash-latest, record_id: 2837337\n","mpve, mat_paper_to_property_1_shot, gemini-1.5-flash-latest, 2837337\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot, llm_name: gemini-1.5-flash-latest, record_id: 317542\n","mpve, mat_paper_to_property_1_shot, gemini-1.5-flash-latest, 317542\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot, llm_name: gemini-1.5-flash-latest, record_id: 53384093\n","mpve, mat_paper_to_property_1_shot, gemini-1.5-flash-latest, 53384093\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot, llm_name: gemini-1.5-flash-latest, record_id: 53519111\n","mpve, mat_paper_to_property_1_shot, gemini-1.5-flash-latest, 53519111\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot, llm_name: gemini-1.5-flash-latest, record_id: 55005437\n","mpve, mat_paper_to_property_1_shot, gemini-1.5-flash-latest, 55005437\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot, llm_name: gemini-1.5-flash-latest, record_id: 6183251\n","mpve, mat_paper_to_property_1_shot, gemini-1.5-flash-latest, 6183251\n","task: mpve, prompt: mat_paper_to_property_1_shot, llm_name: gemini-1.5-flash-latest, record_id: 68518\n","mpve, mat_paper_to_property_1_shot, gemini-1.5-flash-latest, 68518\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot, llm_name: gemini-1.5-flash-latest, record_id: 97574650\n","mpve, mat_paper_to_property_1_shot, gemini-1.5-flash-latest, 97574650\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot, llm_name: gemini-1.0-pro, record_id: 10222315\n","mpve, mat_paper_to_property_1_shot, gemini-1.0-pro, 10222315\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot, llm_name: gemini-1.0-pro, record_id: 11093908\n","mpve, mat_paper_to_property_1_shot, gemini-1.0-pro, 11093908\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot, llm_name: gemini-1.0-pro, record_id: 11181068\n","mpve, mat_paper_to_property_1_shot, gemini-1.0-pro, 11181068\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot, llm_name: gemini-1.0-pro, record_id: 12841719\n","mpve, mat_paper_to_property_1_shot, gemini-1.0-pro, 12841719\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot, llm_name: gemini-1.0-pro, record_id: 135893324\n","mpve, mat_paper_to_property_1_shot, gemini-1.0-pro, 135893324\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot, llm_name: gemini-1.0-pro, record_id: 137261967\n","mpve, mat_paper_to_property_1_shot, gemini-1.0-pro, 137261967\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot, llm_name: gemini-1.0-pro, record_id: 137362119\n","mpve, mat_paper_to_property_1_shot, gemini-1.0-pro, 137362119\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot, llm_name: gemini-1.0-pro, record_id: 15804005\n","mpve, mat_paper_to_property_1_shot, gemini-1.0-pro, 15804005\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot, llm_name: gemini-1.0-pro, record_id: 17645319\n","mpve, mat_paper_to_property_1_shot, gemini-1.0-pro, 17645319\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot, llm_name: gemini-1.0-pro, record_id: 2837337\n","mpve, mat_paper_to_property_1_shot, gemini-1.0-pro, 2837337\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot, llm_name: gemini-1.0-pro, record_id: 317542\n","mpve, mat_paper_to_property_1_shot, gemini-1.0-pro, 317542\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot, llm_name: gemini-1.0-pro, record_id: 53384093\n","mpve, mat_paper_to_property_1_shot, gemini-1.0-pro, 53384093\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot, llm_name: gemini-1.0-pro, record_id: 53519111\n","mpve, mat_paper_to_property_1_shot, gemini-1.0-pro, 53519111\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot, llm_name: gemini-1.0-pro, record_id: 55005437\n","mpve, mat_paper_to_property_1_shot, gemini-1.0-pro, 55005437\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot, llm_name: gemini-1.0-pro, record_id: 6183251\n","mpve, mat_paper_to_property_1_shot, gemini-1.0-pro, 6183251\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot, llm_name: gemini-1.0-pro, record_id: 68518\n","mpve, mat_paper_to_property_1_shot, gemini-1.0-pro, 68518\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot, llm_name: gemini-1.0-pro, record_id: 97574650\n","mpve, mat_paper_to_property_1_shot, gemini-1.0-pro, 97574650\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot, llm_name: gemini-1.5-pro-latest, record_id: 10222315\n","mpve, mat_paper_to_property_1_shot, gemini-1.5-pro-latest, 10222315\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot, llm_name: gemini-1.5-pro-latest, record_id: 11093908\n","mpve, mat_paper_to_property_1_shot, gemini-1.5-pro-latest, 11093908\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot, llm_name: gemini-1.5-pro-latest, record_id: 11181068\n","mpve, mat_paper_to_property_1_shot, gemini-1.5-pro-latest, 11181068\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot, llm_name: gemini-1.5-pro-latest, record_id: 12841719\n","mpve, mat_paper_to_property_1_shot, gemini-1.5-pro-latest, 12841719\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot, llm_name: gemini-1.5-pro-latest, record_id: 135893324\n","mpve, mat_paper_to_property_1_shot, gemini-1.5-pro-latest, 135893324\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot, llm_name: gemini-1.5-pro-latest, record_id: 137261967\n","mpve, mat_paper_to_property_1_shot, gemini-1.5-pro-latest, 137261967\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot, llm_name: gemini-1.5-pro-latest, record_id: 137362119\n","mpve, mat_paper_to_property_1_shot, gemini-1.5-pro-latest, 137362119\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot, llm_name: gemini-1.5-pro-latest, record_id: 15804005\n","mpve, mat_paper_to_property_1_shot, gemini-1.5-pro-latest, 15804005\n","task: mpve, prompt: mat_paper_to_property_1_shot, llm_name: gemini-1.5-pro-latest, record_id: 17645319\n","mpve, mat_paper_to_property_1_shot, gemini-1.5-pro-latest, 17645319\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot, llm_name: gemini-1.5-pro-latest, record_id: 2837337\n","mpve, mat_paper_to_property_1_shot, gemini-1.5-pro-latest, 2837337\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot, llm_name: gemini-1.5-pro-latest, record_id: 317542\n","mpve, mat_paper_to_property_1_shot, gemini-1.5-pro-latest, 317542\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot, llm_name: gemini-1.5-pro-latest, record_id: 53384093\n","mpve, mat_paper_to_property_1_shot, gemini-1.5-pro-latest, 53384093\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot, llm_name: gemini-1.5-pro-latest, record_id: 53519111\n","mpve, mat_paper_to_property_1_shot, gemini-1.5-pro-latest, 53519111\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot, llm_name: gemini-1.5-pro-latest, record_id: 55005437\n","mpve, mat_paper_to_property_1_shot, gemini-1.5-pro-latest, 55005437\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot, llm_name: gemini-1.5-pro-latest, record_id: 6183251\n","mpve, mat_paper_to_property_1_shot, gemini-1.5-pro-latest, 6183251\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot, llm_name: gemini-1.5-pro-latest, record_id: 68518\n","mpve, mat_paper_to_property_1_shot, gemini-1.5-pro-latest, 68518\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot, llm_name: gemini-1.5-pro-latest, record_id: 97574650\n","mpve, mat_paper_to_property_1_shot, gemini-1.5-pro-latest, 97574650\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot, llm_name: gpt-4o, record_id: 10222315\n","mpve, mat_paper_to_property_1_shot, gpt-4o, 10222315\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot, llm_name: gpt-4o, record_id: 11093908\n","mpve, mat_paper_to_property_1_shot, gpt-4o, 11093908\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot, llm_name: gpt-4o, record_id: 11181068\n","mpve, mat_paper_to_property_1_shot, gpt-4o, 11181068\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot, llm_name: gpt-4o, record_id: 12841719\n","mpve, mat_paper_to_property_1_shot, gpt-4o, 12841719\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot, llm_name: gpt-4o, record_id: 135893324\n","mpve, mat_paper_to_property_1_shot, gpt-4o, 135893324\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot, llm_name: gpt-4o, record_id: 137261967\n","mpve, mat_paper_to_property_1_shot, gpt-4o, 137261967\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot, llm_name: gpt-4o, record_id: 137362119\n","mpve, mat_paper_to_property_1_shot, gpt-4o, 137362119\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot, llm_name: gpt-4o, record_id: 15804005\n","mpve, mat_paper_to_property_1_shot, gpt-4o, 15804005\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot, llm_name: gpt-4o, record_id: 17645319\n","mpve, mat_paper_to_property_1_shot, gpt-4o, 17645319\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot, llm_name: gpt-4o, record_id: 2837337\n","mpve, mat_paper_to_property_1_shot, gpt-4o, 2837337\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot, llm_name: gpt-4o, record_id: 317542\n","mpve, mat_paper_to_property_1_shot, gpt-4o, 317542\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot, llm_name: gpt-4o, record_id: 53384093\n","mpve, mat_paper_to_property_1_shot, gpt-4o, 53384093\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot, llm_name: gpt-4o, record_id: 53519111\n","mpve, mat_paper_to_property_1_shot, gpt-4o, 53519111\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot, llm_name: gpt-4o, record_id: 55005437\n","mpve, mat_paper_to_property_1_shot, gpt-4o, 55005437\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot, llm_name: gpt-4o, record_id: 6183251\n","mpve, mat_paper_to_property_1_shot, gpt-4o, 6183251\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot, llm_name: gpt-4o, record_id: 68518\n","mpve, mat_paper_to_property_1_shot, gpt-4o, 68518\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot, llm_name: gpt-4o, record_id: 97574650\n","mpve, mat_paper_to_property_1_shot, gpt-4o, 97574650\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot, llm_name: claude-3-opus-20240229, record_id: 10222315\n","mpve, mat_paper_to_property_1_shot, claude-3-opus-20240229, 10222315\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot, llm_name: claude-3-opus-20240229, record_id: 11093908\n","mpve, mat_paper_to_property_1_shot, claude-3-opus-20240229, 11093908\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot, llm_name: claude-3-opus-20240229, record_id: 11181068\n","mpve, mat_paper_to_property_1_shot, claude-3-opus-20240229, 11181068\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot, llm_name: claude-3-opus-20240229, record_id: 12841719\n","mpve, mat_paper_to_property_1_shot, claude-3-opus-20240229, 12841719\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot, llm_name: claude-3-opus-20240229, record_id: 135893324\n","mpve, mat_paper_to_property_1_shot, claude-3-opus-20240229, 135893324\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot, llm_name: claude-3-opus-20240229, record_id: 137261967\n","mpve, mat_paper_to_property_1_shot, claude-3-opus-20240229, 137261967\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot, llm_name: claude-3-opus-20240229, record_id: 137362119\n","mpve, mat_paper_to_property_1_shot, claude-3-opus-20240229, 137362119\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot, llm_name: claude-3-opus-20240229, record_id: 15804005\n","mpve, mat_paper_to_property_1_shot, claude-3-opus-20240229, 15804005\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot, llm_name: claude-3-opus-20240229, record_id: 17645319\n","mpve, mat_paper_to_property_1_shot, claude-3-opus-20240229, 17645319\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot, llm_name: claude-3-opus-20240229, record_id: 2837337\n","mpve, mat_paper_to_property_1_shot, claude-3-opus-20240229, 2837337\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot, llm_name: claude-3-opus-20240229, record_id: 317542\n","mpve, mat_paper_to_property_1_shot, claude-3-opus-20240229, 317542\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot, llm_name: claude-3-opus-20240229, record_id: 53384093\n","mpve, mat_paper_to_property_1_shot, claude-3-opus-20240229, 53384093\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot, llm_name: claude-3-opus-20240229, record_id: 53519111\n","mpve, mat_paper_to_property_1_shot, claude-3-opus-20240229, 53519111\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot, llm_name: claude-3-opus-20240229, record_id: 55005437\n","mpve, mat_paper_to_property_1_shot, claude-3-opus-20240229, 55005437\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot, llm_name: claude-3-opus-20240229, record_id: 6183251\n","mpve, mat_paper_to_property_1_shot, claude-3-opus-20240229, 6183251\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot, llm_name: claude-3-opus-20240229, record_id: 68518\n","mpve, mat_paper_to_property_1_shot, claude-3-opus-20240229, 68518\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot, llm_name: claude-3-opus-20240229, record_id: 97574650\n","mpve, mat_paper_to_property_1_shot, claude-3-opus-20240229, 97574650\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_bandgap_refractive, llm_name: command-r-plus, record_id: 10222315\n","mpve, mat_paper_to_property_1_shot_bandgap_refractive, command-r-plus, 10222315\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_bandgap_refractive, llm_name: command-r-plus, record_id: 11093908\n","mpve, mat_paper_to_property_1_shot_bandgap_refractive, command-r-plus, 11093908\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_bandgap_refractive, llm_name: command-r-plus, record_id: 11181068\n","mpve, mat_paper_to_property_1_shot_bandgap_refractive, command-r-plus, 11181068\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_bandgap_refractive, llm_name: command-r-plus, record_id: 12841719\n","mpve, mat_paper_to_property_1_shot_bandgap_refractive, command-r-plus, 12841719\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_bandgap_refractive, llm_name: command-r-plus, record_id: 135893324\n","mpve, mat_paper_to_property_1_shot_bandgap_refractive, command-r-plus, 135893324\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_bandgap_refractive, llm_name: command-r-plus, record_id: 137261967\n","mpve, mat_paper_to_property_1_shot_bandgap_refractive, command-r-plus, 137261967\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_bandgap_refractive, llm_name: command-r-plus, record_id: 137362119\n","mpve, mat_paper_to_property_1_shot_bandgap_refractive, command-r-plus, 137362119\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_bandgap_refractive, llm_name: command-r-plus, record_id: 15804005\n","mpve, mat_paper_to_property_1_shot_bandgap_refractive, command-r-plus, 15804005\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_bandgap_refractive, llm_name: command-r-plus, record_id: 17645319\n","mpve, mat_paper_to_property_1_shot_bandgap_refractive, command-r-plus, 17645319\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_bandgap_refractive, llm_name: command-r-plus, record_id: 2837337\n","mpve, mat_paper_to_property_1_shot_bandgap_refractive, command-r-plus, 2837337\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_bandgap_refractive, llm_name: command-r-plus, record_id: 317542\n","mpve, mat_paper_to_property_1_shot_bandgap_refractive, command-r-plus, 317542\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_bandgap_refractive, llm_name: command-r-plus, record_id: 53384093\n","mpve, mat_paper_to_property_1_shot_bandgap_refractive, command-r-plus, 53384093\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_bandgap_refractive, llm_name: command-r-plus, record_id: 53519111\n","mpve, mat_paper_to_property_1_shot_bandgap_refractive, command-r-plus, 53519111\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_bandgap_refractive, llm_name: command-r-plus, record_id: 55005437\n","mpve, mat_paper_to_property_1_shot_bandgap_refractive, command-r-plus, 55005437\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_bandgap_refractive, llm_name: command-r-plus, record_id: 6183251\n","mpve, mat_paper_to_property_1_shot_bandgap_refractive, command-r-plus, 6183251\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_bandgap_refractive, llm_name: command-r-plus, record_id: 68518\n","mpve, mat_paper_to_property_1_shot_bandgap_refractive, command-r-plus, 68518\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_bandgap_refractive, llm_name: command-r-plus, record_id: 97574650\n","mpve, mat_paper_to_property_1_shot_bandgap_refractive, command-r-plus, 97574650\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_bandgap_refractive, llm_name: longllama, record_id: 10222315\n","mpve, mat_paper_to_property_1_shot_bandgap_refractive, longllama, 10222315\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_bandgap_refractive, llm_name: longllama, record_id: 11093908\n","mpve, mat_paper_to_property_1_shot_bandgap_refractive, longllama, 11093908\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_bandgap_refractive, llm_name: longllama, record_id: 11181068\n","mpve, mat_paper_to_property_1_shot_bandgap_refractive, longllama, 11181068\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_bandgap_refractive, llm_name: longllama, record_id: 12841719\n","mpve, mat_paper_to_property_1_shot_bandgap_refractive, longllama, 12841719\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_bandgap_refractive, llm_name: longllama, record_id: 135893324\n","mpve, mat_paper_to_property_1_shot_bandgap_refractive, longllama, 135893324\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_bandgap_refractive, llm_name: longllama, record_id: 137261967\n","mpve, mat_paper_to_property_1_shot_bandgap_refractive, longllama, 137261967\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_bandgap_refractive, llm_name: longllama, record_id: 137362119\n","mpve, mat_paper_to_property_1_shot_bandgap_refractive, longllama, 137362119\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_bandgap_refractive, llm_name: longllama, record_id: 15804005\n","mpve, mat_paper_to_property_1_shot_bandgap_refractive, longllama, 15804005\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_bandgap_refractive, llm_name: longllama, record_id: 17645319\n","mpve, mat_paper_to_property_1_shot_bandgap_refractive, longllama, 17645319\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_bandgap_refractive, llm_name: longllama, record_id: 2837337\n","mpve, mat_paper_to_property_1_shot_bandgap_refractive, longllama, 2837337\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_bandgap_refractive, llm_name: longllama, record_id: 317542\n","mpve, mat_paper_to_property_1_shot_bandgap_refractive, longllama, 317542\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_bandgap_refractive, llm_name: longllama, record_id: 53384093\n","mpve, mat_paper_to_property_1_shot_bandgap_refractive, longllama, 53384093\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_bandgap_refractive, llm_name: longllama, record_id: 53519111\n","mpve, mat_paper_to_property_1_shot_bandgap_refractive, longllama, 53519111\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_bandgap_refractive, llm_name: longllama, record_id: 55005437\n","mpve, mat_paper_to_property_1_shot_bandgap_refractive, longllama, 55005437\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_bandgap_refractive, llm_name: longllama, record_id: 6183251\n","mpve, mat_paper_to_property_1_shot_bandgap_refractive, longllama, 6183251\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_bandgap_refractive, llm_name: longllama, record_id: 68518\n","mpve, mat_paper_to_property_1_shot_bandgap_refractive, longllama, 68518\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_bandgap_refractive, llm_name: longllama, record_id: 97574650\n","mpve, mat_paper_to_property_1_shot_bandgap_refractive, longllama, 97574650\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_bandgap_refractive, llm_name: mixtral-gcp, record_id: 10222315\n","mpve, mat_paper_to_property_1_shot_bandgap_refractive, mixtral-gcp, 10222315\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_bandgap_refractive, llm_name: mixtral-gcp, record_id: 11093908\n","mpve, mat_paper_to_property_1_shot_bandgap_refractive, mixtral-gcp, 11093908\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_bandgap_refractive, llm_name: mixtral-gcp, record_id: 11181068\n","mpve, mat_paper_to_property_1_shot_bandgap_refractive, mixtral-gcp, 11181068\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_bandgap_refractive, llm_name: mixtral-gcp, record_id: 12841719\n","mpve, mat_paper_to_property_1_shot_bandgap_refractive, mixtral-gcp, 12841719\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_bandgap_refractive, llm_name: mixtral-gcp, record_id: 135893324\n","mpve, mat_paper_to_property_1_shot_bandgap_refractive, mixtral-gcp, 135893324\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_bandgap_refractive, llm_name: mixtral-gcp, record_id: 137261967\n","mpve, mat_paper_to_property_1_shot_bandgap_refractive, mixtral-gcp, 137261967\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_bandgap_refractive, llm_name: mixtral-gcp, record_id: 137362119\n","mpve, mat_paper_to_property_1_shot_bandgap_refractive, mixtral-gcp, 137362119\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_bandgap_refractive, llm_name: mixtral-gcp, record_id: 15804005\n","mpve, mat_paper_to_property_1_shot_bandgap_refractive, mixtral-gcp, 15804005\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_bandgap_refractive, llm_name: mixtral-gcp, record_id: 17645319\n","mpve, mat_paper_to_property_1_shot_bandgap_refractive, mixtral-gcp, 17645319\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_bandgap_refractive, llm_name: mixtral-gcp, record_id: 2837337\n","mpve, mat_paper_to_property_1_shot_bandgap_refractive, mixtral-gcp, 2837337\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_bandgap_refractive, llm_name: mixtral-gcp, record_id: 317542\n","mpve, mat_paper_to_property_1_shot_bandgap_refractive, mixtral-gcp, 317542\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_bandgap_refractive, llm_name: mixtral-gcp, record_id: 53384093\n","mpve, mat_paper_to_property_1_shot_bandgap_refractive, mixtral-gcp, 53384093\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_bandgap_refractive, llm_name: mixtral-gcp, record_id: 53519111\n","mpve, mat_paper_to_property_1_shot_bandgap_refractive, mixtral-gcp, 53519111\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_bandgap_refractive, llm_name: mixtral-gcp, record_id: 55005437\n","mpve, mat_paper_to_property_1_shot_bandgap_refractive, mixtral-gcp, 55005437\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_bandgap_refractive, llm_name: mixtral-gcp, record_id: 6183251\n","mpve, mat_paper_to_property_1_shot_bandgap_refractive, mixtral-gcp, 6183251\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_bandgap_refractive, llm_name: mixtral-gcp, record_id: 68518\n","mpve, mat_paper_to_property_1_shot_bandgap_refractive, mixtral-gcp, 68518\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_bandgap_refractive, llm_name: mixtral-gcp, record_id: 97574650\n","mpve, mat_paper_to_property_1_shot_bandgap_refractive, mixtral-gcp, 97574650\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_bandgap_refractive, llm_name: gemini-1.5-flash-latest, record_id: 10222315\n","mpve, mat_paper_to_property_1_shot_bandgap_refractive, gemini-1.5-flash-latest, 10222315\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_bandgap_refractive, llm_name: gemini-1.5-flash-latest, record_id: 11093908\n","mpve, mat_paper_to_property_1_shot_bandgap_refractive, gemini-1.5-flash-latest, 11093908\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_bandgap_refractive, llm_name: gemini-1.5-flash-latest, record_id: 11181068\n","mpve, mat_paper_to_property_1_shot_bandgap_refractive, gemini-1.5-flash-latest, 11181068\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_bandgap_refractive, llm_name: gemini-1.5-flash-latest, record_id: 12841719\n","mpve, mat_paper_to_property_1_shot_bandgap_refractive, gemini-1.5-flash-latest, 12841719\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_bandgap_refractive, llm_name: gemini-1.5-flash-latest, record_id: 135893324\n","mpve, mat_paper_to_property_1_shot_bandgap_refractive, gemini-1.5-flash-latest, 135893324\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_bandgap_refractive, llm_name: gemini-1.5-flash-latest, record_id: 137261967\n","mpve, mat_paper_to_property_1_shot_bandgap_refractive, gemini-1.5-flash-latest, 137261967\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_bandgap_refractive, llm_name: gemini-1.5-flash-latest, record_id: 137362119\n","mpve, mat_paper_to_property_1_shot_bandgap_refractive, gemini-1.5-flash-latest, 137362119\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_bandgap_refractive, llm_name: gemini-1.5-flash-latest, record_id: 15804005\n","mpve, mat_paper_to_property_1_shot_bandgap_refractive, gemini-1.5-flash-latest, 15804005\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_bandgap_refractive, llm_name: gemini-1.5-flash-latest, record_id: 17645319\n","mpve, mat_paper_to_property_1_shot_bandgap_refractive, gemini-1.5-flash-latest, 17645319\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_bandgap_refractive, llm_name: gemini-1.5-flash-latest, record_id: 2837337\n","mpve, mat_paper_to_property_1_shot_bandgap_refractive, gemini-1.5-flash-latest, 2837337\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_bandgap_refractive, llm_name: gemini-1.5-flash-latest, record_id: 317542\n","mpve, mat_paper_to_property_1_shot_bandgap_refractive, gemini-1.5-flash-latest, 317542\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_bandgap_refractive, llm_name: gemini-1.5-flash-latest, record_id: 53384093\n","mpve, mat_paper_to_property_1_shot_bandgap_refractive, gemini-1.5-flash-latest, 53384093\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_bandgap_refractive, llm_name: gemini-1.5-flash-latest, record_id: 53519111\n","mpve, mat_paper_to_property_1_shot_bandgap_refractive, gemini-1.5-flash-latest, 53519111\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_bandgap_refractive, llm_name: gemini-1.5-flash-latest, record_id: 55005437\n","mpve, mat_paper_to_property_1_shot_bandgap_refractive, gemini-1.5-flash-latest, 55005437\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_bandgap_refractive, llm_name: gemini-1.5-flash-latest, record_id: 6183251\n","mpve, mat_paper_to_property_1_shot_bandgap_refractive, gemini-1.5-flash-latest, 6183251\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_bandgap_refractive, llm_name: gemini-1.5-flash-latest, record_id: 68518\n","mpve, mat_paper_to_property_1_shot_bandgap_refractive, gemini-1.5-flash-latest, 68518\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_bandgap_refractive, llm_name: gemini-1.5-flash-latest, record_id: 97574650\n","mpve, mat_paper_to_property_1_shot_bandgap_refractive, gemini-1.5-flash-latest, 97574650\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_bandgap_refractive, llm_name: gemini-1.0-pro, record_id: 10222315\n","mpve, mat_paper_to_property_1_shot_bandgap_refractive, gemini-1.0-pro, 10222315\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_bandgap_refractive, llm_name: gemini-1.0-pro, record_id: 11093908\n","mpve, mat_paper_to_property_1_shot_bandgap_refractive, gemini-1.0-pro, 11093908\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_bandgap_refractive, llm_name: gemini-1.0-pro, record_id: 11181068\n","mpve, mat_paper_to_property_1_shot_bandgap_refractive, gemini-1.0-pro, 11181068\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_bandgap_refractive, llm_name: gemini-1.0-pro, record_id: 12841719\n","mpve, mat_paper_to_property_1_shot_bandgap_refractive, gemini-1.0-pro, 12841719\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_bandgap_refractive, llm_name: gemini-1.0-pro, record_id: 135893324\n","mpve, mat_paper_to_property_1_shot_bandgap_refractive, gemini-1.0-pro, 135893324\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_bandgap_refractive, llm_name: gemini-1.0-pro, record_id: 137261967\n","mpve, mat_paper_to_property_1_shot_bandgap_refractive, gemini-1.0-pro, 137261967\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_bandgap_refractive, llm_name: gemini-1.0-pro, record_id: 137362119\n","mpve, mat_paper_to_property_1_shot_bandgap_refractive, gemini-1.0-pro, 137362119\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_bandgap_refractive, llm_name: gemini-1.0-pro, record_id: 15804005\n","mpve, mat_paper_to_property_1_shot_bandgap_refractive, gemini-1.0-pro, 15804005\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_bandgap_refractive, llm_name: gemini-1.0-pro, record_id: 17645319\n","mpve, mat_paper_to_property_1_shot_bandgap_refractive, gemini-1.0-pro, 17645319\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_bandgap_refractive, llm_name: gemini-1.0-pro, record_id: 2837337\n","mpve, mat_paper_to_property_1_shot_bandgap_refractive, gemini-1.0-pro, 2837337\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_bandgap_refractive, llm_name: gemini-1.0-pro, record_id: 317542\n","mpve, mat_paper_to_property_1_shot_bandgap_refractive, gemini-1.0-pro, 317542\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_bandgap_refractive, llm_name: gemini-1.0-pro, record_id: 53384093\n","mpve, mat_paper_to_property_1_shot_bandgap_refractive, gemini-1.0-pro, 53384093\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_bandgap_refractive, llm_name: gemini-1.0-pro, record_id: 53519111\n","mpve, mat_paper_to_property_1_shot_bandgap_refractive, gemini-1.0-pro, 53519111\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_bandgap_refractive, llm_name: gemini-1.0-pro, record_id: 55005437\n","mpve, mat_paper_to_property_1_shot_bandgap_refractive, gemini-1.0-pro, 55005437\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_bandgap_refractive, llm_name: gemini-1.0-pro, record_id: 6183251\n","mpve, mat_paper_to_property_1_shot_bandgap_refractive, gemini-1.0-pro, 6183251\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_bandgap_refractive, llm_name: gemini-1.0-pro, record_id: 68518\n","mpve, mat_paper_to_property_1_shot_bandgap_refractive, gemini-1.0-pro, 68518\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_bandgap_refractive, llm_name: gemini-1.0-pro, record_id: 97574650\n","mpve, mat_paper_to_property_1_shot_bandgap_refractive, gemini-1.0-pro, 97574650\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_bandgap_refractive, llm_name: gemini-1.5-pro-latest, record_id: 10222315\n","mpve, mat_paper_to_property_1_shot_bandgap_refractive, gemini-1.5-pro-latest, 10222315\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_bandgap_refractive, llm_name: gemini-1.5-pro-latest, record_id: 11093908\n","mpve, mat_paper_to_property_1_shot_bandgap_refractive, gemini-1.5-pro-latest, 11093908\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_bandgap_refractive, llm_name: gemini-1.5-pro-latest, record_id: 11181068\n","mpve, mat_paper_to_property_1_shot_bandgap_refractive, gemini-1.5-pro-latest, 11181068\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_bandgap_refractive, llm_name: gemini-1.5-pro-latest, record_id: 12841719\n","mpve, mat_paper_to_property_1_shot_bandgap_refractive, gemini-1.5-pro-latest, 12841719\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_bandgap_refractive, llm_name: gemini-1.5-pro-latest, record_id: 135893324\n","mpve, mat_paper_to_property_1_shot_bandgap_refractive, gemini-1.5-pro-latest, 135893324\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_bandgap_refractive, llm_name: gemini-1.5-pro-latest, record_id: 137261967\n","mpve, mat_paper_to_property_1_shot_bandgap_refractive, gemini-1.5-pro-latest, 137261967\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_bandgap_refractive, llm_name: gemini-1.5-pro-latest, record_id: 137362119\n","mpve, mat_paper_to_property_1_shot_bandgap_refractive, gemini-1.5-pro-latest, 137362119\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_bandgap_refractive, llm_name: gemini-1.5-pro-latest, record_id: 15804005\n","mpve, mat_paper_to_property_1_shot_bandgap_refractive, gemini-1.5-pro-latest, 15804005\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_bandgap_refractive, llm_name: gemini-1.5-pro-latest, record_id: 17645319\n","mpve, mat_paper_to_property_1_shot_bandgap_refractive, gemini-1.5-pro-latest, 17645319\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_bandgap_refractive, llm_name: gemini-1.5-pro-latest, record_id: 2837337\n","mpve, mat_paper_to_property_1_shot_bandgap_refractive, gemini-1.5-pro-latest, 2837337\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_bandgap_refractive, llm_name: gemini-1.5-pro-latest, record_id: 317542\n","mpve, mat_paper_to_property_1_shot_bandgap_refractive, gemini-1.5-pro-latest, 317542\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_bandgap_refractive, llm_name: gemini-1.5-pro-latest, record_id: 53384093\n","mpve, mat_paper_to_property_1_shot_bandgap_refractive, gemini-1.5-pro-latest, 53384093\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_bandgap_refractive, llm_name: gemini-1.5-pro-latest, record_id: 53519111\n","mpve, mat_paper_to_property_1_shot_bandgap_refractive, gemini-1.5-pro-latest, 53519111\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_bandgap_refractive, llm_name: gemini-1.5-pro-latest, record_id: 55005437\n","mpve, mat_paper_to_property_1_shot_bandgap_refractive, gemini-1.5-pro-latest, 55005437\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_bandgap_refractive, llm_name: gemini-1.5-pro-latest, record_id: 6183251\n","mpve, mat_paper_to_property_1_shot_bandgap_refractive, gemini-1.5-pro-latest, 6183251\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_bandgap_refractive, llm_name: gemini-1.5-pro-latest, record_id: 68518\n","mpve, mat_paper_to_property_1_shot_bandgap_refractive, gemini-1.5-pro-latest, 68518\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_bandgap_refractive, llm_name: gemini-1.5-pro-latest, record_id: 97574650\n","mpve, mat_paper_to_property_1_shot_bandgap_refractive, gemini-1.5-pro-latest, 97574650\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_bandgap_refractive, llm_name: gpt-4o, record_id: 10222315\n","mpve, mat_paper_to_property_1_shot_bandgap_refractive, gpt-4o, 10222315\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_bandgap_refractive, llm_name: gpt-4o, record_id: 11093908\n","mpve, mat_paper_to_property_1_shot_bandgap_refractive, gpt-4o, 11093908\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_bandgap_refractive, llm_name: gpt-4o, record_id: 11181068\n","mpve, mat_paper_to_property_1_shot_bandgap_refractive, gpt-4o, 11181068\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_bandgap_refractive, llm_name: gpt-4o, record_id: 12841719\n","mpve, mat_paper_to_property_1_shot_bandgap_refractive, gpt-4o, 12841719\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_bandgap_refractive, llm_name: gpt-4o, record_id: 135893324\n","mpve, mat_paper_to_property_1_shot_bandgap_refractive, gpt-4o, 135893324\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_bandgap_refractive, llm_name: gpt-4o, record_id: 137261967\n","mpve, mat_paper_to_property_1_shot_bandgap_refractive, gpt-4o, 137261967\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_bandgap_refractive, llm_name: gpt-4o, record_id: 137362119\n","mpve, mat_paper_to_property_1_shot_bandgap_refractive, gpt-4o, 137362119\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_bandgap_refractive, llm_name: gpt-4o, record_id: 15804005\n","mpve, mat_paper_to_property_1_shot_bandgap_refractive, gpt-4o, 15804005\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_bandgap_refractive, llm_name: gpt-4o, record_id: 17645319\n","mpve, mat_paper_to_property_1_shot_bandgap_refractive, gpt-4o, 17645319\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_bandgap_refractive, llm_name: gpt-4o, record_id: 2837337\n","mpve, mat_paper_to_property_1_shot_bandgap_refractive, gpt-4o, 2837337\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_bandgap_refractive, llm_name: gpt-4o, record_id: 317542\n","mpve, mat_paper_to_property_1_shot_bandgap_refractive, gpt-4o, 317542\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_bandgap_refractive, llm_name: gpt-4o, record_id: 53384093\n","mpve, mat_paper_to_property_1_shot_bandgap_refractive, gpt-4o, 53384093\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_bandgap_refractive, llm_name: gpt-4o, record_id: 53519111\n","mpve, mat_paper_to_property_1_shot_bandgap_refractive, gpt-4o, 53519111\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_bandgap_refractive, llm_name: gpt-4o, record_id: 55005437\n","mpve, mat_paper_to_property_1_shot_bandgap_refractive, gpt-4o, 55005437\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_bandgap_refractive, llm_name: gpt-4o, record_id: 6183251\n","mpve, mat_paper_to_property_1_shot_bandgap_refractive, gpt-4o, 6183251\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_bandgap_refractive, llm_name: gpt-4o, record_id: 68518\n","mpve, mat_paper_to_property_1_shot_bandgap_refractive, gpt-4o, 68518\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_bandgap_refractive, llm_name: gpt-4o, record_id: 97574650\n","mpve, mat_paper_to_property_1_shot_bandgap_refractive, gpt-4o, 97574650\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_bandgap_refractive, llm_name: claude-3-opus-20240229, record_id: 10222315\n","mpve, mat_paper_to_property_1_shot_bandgap_refractive, claude-3-opus-20240229, 10222315\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_bandgap_refractive, llm_name: claude-3-opus-20240229, record_id: 11093908\n","mpve, mat_paper_to_property_1_shot_bandgap_refractive, claude-3-opus-20240229, 11093908\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_bandgap_refractive, llm_name: claude-3-opus-20240229, record_id: 11181068\n","mpve, mat_paper_to_property_1_shot_bandgap_refractive, claude-3-opus-20240229, 11181068\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_bandgap_refractive, llm_name: claude-3-opus-20240229, record_id: 12841719\n","mpve, mat_paper_to_property_1_shot_bandgap_refractive, claude-3-opus-20240229, 12841719\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_bandgap_refractive, llm_name: claude-3-opus-20240229, record_id: 135893324\n","mpve, mat_paper_to_property_1_shot_bandgap_refractive, claude-3-opus-20240229, 135893324\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_bandgap_refractive, llm_name: claude-3-opus-20240229, record_id: 137261967\n","mpve, mat_paper_to_property_1_shot_bandgap_refractive, claude-3-opus-20240229, 137261967\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_bandgap_refractive, llm_name: claude-3-opus-20240229, record_id: 137362119\n","mpve, mat_paper_to_property_1_shot_bandgap_refractive, claude-3-opus-20240229, 137362119\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_bandgap_refractive, llm_name: claude-3-opus-20240229, record_id: 15804005\n","mpve, mat_paper_to_property_1_shot_bandgap_refractive, claude-3-opus-20240229, 15804005\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_bandgap_refractive, llm_name: claude-3-opus-20240229, record_id: 17645319\n","mpve, mat_paper_to_property_1_shot_bandgap_refractive, claude-3-opus-20240229, 17645319\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_bandgap_refractive, llm_name: claude-3-opus-20240229, record_id: 2837337\n","mpve, mat_paper_to_property_1_shot_bandgap_refractive, claude-3-opus-20240229, 2837337\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_bandgap_refractive, llm_name: claude-3-opus-20240229, record_id: 317542\n","mpve, mat_paper_to_property_1_shot_bandgap_refractive, claude-3-opus-20240229, 317542\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_bandgap_refractive, llm_name: claude-3-opus-20240229, record_id: 53384093\n","mpve, mat_paper_to_property_1_shot_bandgap_refractive, claude-3-opus-20240229, 53384093\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_bandgap_refractive, llm_name: claude-3-opus-20240229, record_id: 53519111\n","mpve, mat_paper_to_property_1_shot_bandgap_refractive, claude-3-opus-20240229, 53519111\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_bandgap_refractive, llm_name: claude-3-opus-20240229, record_id: 55005437\n","mpve, mat_paper_to_property_1_shot_bandgap_refractive, claude-3-opus-20240229, 55005437\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_bandgap_refractive, llm_name: claude-3-opus-20240229, record_id: 6183251\n","mpve, mat_paper_to_property_1_shot_bandgap_refractive, claude-3-opus-20240229, 6183251\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_bandgap_refractive, llm_name: claude-3-opus-20240229, record_id: 68518\n","mpve, mat_paper_to_property_1_shot_bandgap_refractive, claude-3-opus-20240229, 68518\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_bandgap_refractive, llm_name: claude-3-opus-20240229, record_id: 97574650\n","mpve, mat_paper_to_property_1_shot_bandgap_refractive, claude-3-opus-20240229, 97574650\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_exclude_trivia, llm_name: command-r-plus, record_id: 10222315\n","mpve, mat_paper_to_property_1_shot_exclude_trivia, command-r-plus, 10222315\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_exclude_trivia, llm_name: command-r-plus, record_id: 11093908\n","mpve, mat_paper_to_property_1_shot_exclude_trivia, command-r-plus, 11093908\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_exclude_trivia, llm_name: command-r-plus, record_id: 11181068\n","mpve, mat_paper_to_property_1_shot_exclude_trivia, command-r-plus, 11181068\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_exclude_trivia, llm_name: command-r-plus, record_id: 12841719\n","mpve, mat_paper_to_property_1_shot_exclude_trivia, command-r-plus, 12841719\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_exclude_trivia, llm_name: command-r-plus, record_id: 135893324\n","mpve, mat_paper_to_property_1_shot_exclude_trivia, command-r-plus, 135893324\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_exclude_trivia, llm_name: command-r-plus, record_id: 137261967\n","mpve, mat_paper_to_property_1_shot_exclude_trivia, command-r-plus, 137261967\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_exclude_trivia, llm_name: command-r-plus, record_id: 137362119\n","mpve, mat_paper_to_property_1_shot_exclude_trivia, command-r-plus, 137362119\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_exclude_trivia, llm_name: command-r-plus, record_id: 15804005\n","mpve, mat_paper_to_property_1_shot_exclude_trivia, command-r-plus, 15804005\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_exclude_trivia, llm_name: command-r-plus, record_id: 17645319\n","mpve, mat_paper_to_property_1_shot_exclude_trivia, command-r-plus, 17645319\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_exclude_trivia, llm_name: command-r-plus, record_id: 2837337\n","mpve, mat_paper_to_property_1_shot_exclude_trivia, command-r-plus, 2837337\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_exclude_trivia, llm_name: command-r-plus, record_id: 317542\n","mpve, mat_paper_to_property_1_shot_exclude_trivia, command-r-plus, 317542\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_exclude_trivia, llm_name: command-r-plus, record_id: 53384093\n","mpve, mat_paper_to_property_1_shot_exclude_trivia, command-r-plus, 53384093\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_exclude_trivia, llm_name: command-r-plus, record_id: 53519111\n","mpve, mat_paper_to_property_1_shot_exclude_trivia, command-r-plus, 53519111\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_exclude_trivia, llm_name: command-r-plus, record_id: 55005437\n","mpve, mat_paper_to_property_1_shot_exclude_trivia, command-r-plus, 55005437\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_exclude_trivia, llm_name: command-r-plus, record_id: 6183251\n","mpve, mat_paper_to_property_1_shot_exclude_trivia, command-r-plus, 6183251\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_exclude_trivia, llm_name: command-r-plus, record_id: 68518\n","mpve, mat_paper_to_property_1_shot_exclude_trivia, command-r-plus, 68518\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_exclude_trivia, llm_name: command-r-plus, record_id: 97574650\n","mpve, mat_paper_to_property_1_shot_exclude_trivia, command-r-plus, 97574650\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_exclude_trivia, llm_name: longllama, record_id: 10222315\n","mpve, mat_paper_to_property_1_shot_exclude_trivia, longllama, 10222315\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_exclude_trivia, llm_name: longllama, record_id: 11093908\n","mpve, mat_paper_to_property_1_shot_exclude_trivia, longllama, 11093908\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_exclude_trivia, llm_name: longllama, record_id: 11181068\n","mpve, mat_paper_to_property_1_shot_exclude_trivia, longllama, 11181068\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_exclude_trivia, llm_name: longllama, record_id: 12841719\n","mpve, mat_paper_to_property_1_shot_exclude_trivia, longllama, 12841719\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_exclude_trivia, llm_name: longllama, record_id: 135893324\n","mpve, mat_paper_to_property_1_shot_exclude_trivia, longllama, 135893324\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_exclude_trivia, llm_name: longllama, record_id: 137261967\n","mpve, mat_paper_to_property_1_shot_exclude_trivia, longllama, 137261967\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_exclude_trivia, llm_name: longllama, record_id: 137362119\n","mpve, mat_paper_to_property_1_shot_exclude_trivia, longllama, 137362119\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_exclude_trivia, llm_name: longllama, record_id: 15804005\n","mpve, mat_paper_to_property_1_shot_exclude_trivia, longllama, 15804005\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_exclude_trivia, llm_name: longllama, record_id: 17645319\n","mpve, mat_paper_to_property_1_shot_exclude_trivia, longllama, 17645319\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_exclude_trivia, llm_name: longllama, record_id: 2837337\n","mpve, mat_paper_to_property_1_shot_exclude_trivia, longllama, 2837337\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_exclude_trivia, llm_name: longllama, record_id: 317542\n","mpve, mat_paper_to_property_1_shot_exclude_trivia, longllama, 317542\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_exclude_trivia, llm_name: longllama, record_id: 53384093\n","mpve, mat_paper_to_property_1_shot_exclude_trivia, longllama, 53384093\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_exclude_trivia, llm_name: longllama, record_id: 53519111\n","mpve, mat_paper_to_property_1_shot_exclude_trivia, longllama, 53519111\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_exclude_trivia, llm_name: longllama, record_id: 55005437\n","mpve, mat_paper_to_property_1_shot_exclude_trivia, longllama, 55005437\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_exclude_trivia, llm_name: longllama, record_id: 6183251\n","mpve, mat_paper_to_property_1_shot_exclude_trivia, longllama, 6183251\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_exclude_trivia, llm_name: longllama, record_id: 68518\n","mpve, mat_paper_to_property_1_shot_exclude_trivia, longllama, 68518\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_exclude_trivia, llm_name: longllama, record_id: 97574650\n","mpve, mat_paper_to_property_1_shot_exclude_trivia, longllama, 97574650\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_exclude_trivia, llm_name: mixtral-gcp, record_id: 10222315\n","mpve, mat_paper_to_property_1_shot_exclude_trivia, mixtral-gcp, 10222315\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_exclude_trivia, llm_name: mixtral-gcp, record_id: 11093908\n","mpve, mat_paper_to_property_1_shot_exclude_trivia, mixtral-gcp, 11093908\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_exclude_trivia, llm_name: mixtral-gcp, record_id: 11181068\n","mpve, mat_paper_to_property_1_shot_exclude_trivia, mixtral-gcp, 11181068\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_exclude_trivia, llm_name: mixtral-gcp, record_id: 12841719\n","mpve, mat_paper_to_property_1_shot_exclude_trivia, mixtral-gcp, 12841719\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_exclude_trivia, llm_name: mixtral-gcp, record_id: 135893324\n","mpve, mat_paper_to_property_1_shot_exclude_trivia, mixtral-gcp, 135893324\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_exclude_trivia, llm_name: mixtral-gcp, record_id: 137261967\n","mpve, mat_paper_to_property_1_shot_exclude_trivia, mixtral-gcp, 137261967\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_exclude_trivia, llm_name: mixtral-gcp, record_id: 137362119\n","mpve, mat_paper_to_property_1_shot_exclude_trivia, mixtral-gcp, 137362119\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_exclude_trivia, llm_name: mixtral-gcp, record_id: 15804005\n","mpve, mat_paper_to_property_1_shot_exclude_trivia, mixtral-gcp, 15804005\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_exclude_trivia, llm_name: mixtral-gcp, record_id: 17645319\n","mpve, mat_paper_to_property_1_shot_exclude_trivia, mixtral-gcp, 17645319\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_exclude_trivia, llm_name: mixtral-gcp, record_id: 2837337\n","mpve, mat_paper_to_property_1_shot_exclude_trivia, mixtral-gcp, 2837337\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_exclude_trivia, llm_name: mixtral-gcp, record_id: 317542\n","mpve, mat_paper_to_property_1_shot_exclude_trivia, mixtral-gcp, 317542\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_exclude_trivia, llm_name: mixtral-gcp, record_id: 53384093\n","mpve, mat_paper_to_property_1_shot_exclude_trivia, mixtral-gcp, 53384093\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_exclude_trivia, llm_name: mixtral-gcp, record_id: 53519111\n","mpve, mat_paper_to_property_1_shot_exclude_trivia, mixtral-gcp, 53519111\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_exclude_trivia, llm_name: mixtral-gcp, record_id: 55005437\n","mpve, mat_paper_to_property_1_shot_exclude_trivia, mixtral-gcp, 55005437\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_exclude_trivia, llm_name: mixtral-gcp, record_id: 6183251\n","mpve, mat_paper_to_property_1_shot_exclude_trivia, mixtral-gcp, 6183251\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_exclude_trivia, llm_name: mixtral-gcp, record_id: 68518\n","mpve, mat_paper_to_property_1_shot_exclude_trivia, mixtral-gcp, 68518\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_exclude_trivia, llm_name: mixtral-gcp, record_id: 97574650\n","mpve, mat_paper_to_property_1_shot_exclude_trivia, mixtral-gcp, 97574650\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_exclude_trivia, llm_name: gemini-1.5-flash-latest, record_id: 10222315\n","mpve, mat_paper_to_property_1_shot_exclude_trivia, gemini-1.5-flash-latest, 10222315\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_exclude_trivia, llm_name: gemini-1.5-flash-latest, record_id: 11093908\n","mpve, mat_paper_to_property_1_shot_exclude_trivia, gemini-1.5-flash-latest, 11093908\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_exclude_trivia, llm_name: gemini-1.5-flash-latest, record_id: 11181068\n","mpve, mat_paper_to_property_1_shot_exclude_trivia, gemini-1.5-flash-latest, 11181068\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_exclude_trivia, llm_name: gemini-1.5-flash-latest, record_id: 12841719\n","mpve, mat_paper_to_property_1_shot_exclude_trivia, gemini-1.5-flash-latest, 12841719\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_exclude_trivia, llm_name: gemini-1.5-flash-latest, record_id: 135893324\n","mpve, mat_paper_to_property_1_shot_exclude_trivia, gemini-1.5-flash-latest, 135893324\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_exclude_trivia, llm_name: gemini-1.5-flash-latest, record_id: 137261967\n","mpve, mat_paper_to_property_1_shot_exclude_trivia, gemini-1.5-flash-latest, 137261967\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_exclude_trivia, llm_name: gemini-1.5-flash-latest, record_id: 137362119\n","mpve, mat_paper_to_property_1_shot_exclude_trivia, gemini-1.5-flash-latest, 137362119\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_exclude_trivia, llm_name: gemini-1.5-flash-latest, record_id: 15804005\n","mpve, mat_paper_to_property_1_shot_exclude_trivia, gemini-1.5-flash-latest, 15804005\n","task: mpve, prompt: mat_paper_to_property_1_shot_exclude_trivia, llm_name: gemini-1.5-flash-latest, record_id: 17645319\n","mpve, mat_paper_to_property_1_shot_exclude_trivia, gemini-1.5-flash-latest, 17645319\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_exclude_trivia, llm_name: gemini-1.5-flash-latest, record_id: 2837337\n","mpve, mat_paper_to_property_1_shot_exclude_trivia, gemini-1.5-flash-latest, 2837337\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_exclude_trivia, llm_name: gemini-1.5-flash-latest, record_id: 317542\n","mpve, mat_paper_to_property_1_shot_exclude_trivia, gemini-1.5-flash-latest, 317542\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_exclude_trivia, llm_name: gemini-1.5-flash-latest, record_id: 53384093\n","mpve, mat_paper_to_property_1_shot_exclude_trivia, gemini-1.5-flash-latest, 53384093\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_exclude_trivia, llm_name: gemini-1.5-flash-latest, record_id: 53519111\n","mpve, mat_paper_to_property_1_shot_exclude_trivia, gemini-1.5-flash-latest, 53519111\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_exclude_trivia, llm_name: gemini-1.5-flash-latest, record_id: 55005437\n","mpve, mat_paper_to_property_1_shot_exclude_trivia, gemini-1.5-flash-latest, 55005437\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_exclude_trivia, llm_name: gemini-1.5-flash-latest, record_id: 6183251\n","mpve, mat_paper_to_property_1_shot_exclude_trivia, gemini-1.5-flash-latest, 6183251\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_exclude_trivia, llm_name: gemini-1.5-flash-latest, record_id: 68518\n","mpve, mat_paper_to_property_1_shot_exclude_trivia, gemini-1.5-flash-latest, 68518\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_exclude_trivia, llm_name: gemini-1.5-flash-latest, record_id: 97574650\n","mpve, mat_paper_to_property_1_shot_exclude_trivia, gemini-1.5-flash-latest, 97574650\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_exclude_trivia, llm_name: gemini-1.0-pro, record_id: 10222315\n","mpve, mat_paper_to_property_1_shot_exclude_trivia, gemini-1.0-pro, 10222315\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_exclude_trivia, llm_name: gemini-1.0-pro, record_id: 11093908\n","mpve, mat_paper_to_property_1_shot_exclude_trivia, gemini-1.0-pro, 11093908\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_exclude_trivia, llm_name: gemini-1.0-pro, record_id: 11181068\n","mpve, mat_paper_to_property_1_shot_exclude_trivia, gemini-1.0-pro, 11181068\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_exclude_trivia, llm_name: gemini-1.0-pro, record_id: 12841719\n","mpve, mat_paper_to_property_1_shot_exclude_trivia, gemini-1.0-pro, 12841719\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_exclude_trivia, llm_name: gemini-1.0-pro, record_id: 135893324\n","mpve, mat_paper_to_property_1_shot_exclude_trivia, gemini-1.0-pro, 135893324\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_exclude_trivia, llm_name: gemini-1.0-pro, record_id: 137261967\n","mpve, mat_paper_to_property_1_shot_exclude_trivia, gemini-1.0-pro, 137261967\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_exclude_trivia, llm_name: gemini-1.0-pro, record_id: 137362119\n","mpve, mat_paper_to_property_1_shot_exclude_trivia, gemini-1.0-pro, 137362119\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_exclude_trivia, llm_name: gemini-1.0-pro, record_id: 15804005\n","mpve, mat_paper_to_property_1_shot_exclude_trivia, gemini-1.0-pro, 15804005\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_exclude_trivia, llm_name: gemini-1.0-pro, record_id: 17645319\n","mpve, mat_paper_to_property_1_shot_exclude_trivia, gemini-1.0-pro, 17645319\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_exclude_trivia, llm_name: gemini-1.0-pro, record_id: 2837337\n","mpve, mat_paper_to_property_1_shot_exclude_trivia, gemini-1.0-pro, 2837337\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_exclude_trivia, llm_name: gemini-1.0-pro, record_id: 317542\n","mpve, mat_paper_to_property_1_shot_exclude_trivia, gemini-1.0-pro, 317542\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_exclude_trivia, llm_name: gemini-1.0-pro, record_id: 53384093\n","mpve, mat_paper_to_property_1_shot_exclude_trivia, gemini-1.0-pro, 53384093\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_exclude_trivia, llm_name: gemini-1.0-pro, record_id: 53519111\n","mpve, mat_paper_to_property_1_shot_exclude_trivia, gemini-1.0-pro, 53519111\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_exclude_trivia, llm_name: gemini-1.0-pro, record_id: 55005437\n","mpve, mat_paper_to_property_1_shot_exclude_trivia, gemini-1.0-pro, 55005437\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_exclude_trivia, llm_name: gemini-1.0-pro, record_id: 6183251\n","mpve, mat_paper_to_property_1_shot_exclude_trivia, gemini-1.0-pro, 6183251\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_exclude_trivia, llm_name: gemini-1.0-pro, record_id: 68518\n","mpve, mat_paper_to_property_1_shot_exclude_trivia, gemini-1.0-pro, 68518\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_exclude_trivia, llm_name: gemini-1.0-pro, record_id: 97574650\n","mpve, mat_paper_to_property_1_shot_exclude_trivia, gemini-1.0-pro, 97574650\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_exclude_trivia, llm_name: gemini-1.5-pro-latest, record_id: 10222315\n","mpve, mat_paper_to_property_1_shot_exclude_trivia, gemini-1.5-pro-latest, 10222315\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_exclude_trivia, llm_name: gemini-1.5-pro-latest, record_id: 11093908\n","mpve, mat_paper_to_property_1_shot_exclude_trivia, gemini-1.5-pro-latest, 11093908\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_exclude_trivia, llm_name: gemini-1.5-pro-latest, record_id: 11181068\n","mpve, mat_paper_to_property_1_shot_exclude_trivia, gemini-1.5-pro-latest, 11181068\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_exclude_trivia, llm_name: gemini-1.5-pro-latest, record_id: 12841719\n","mpve, mat_paper_to_property_1_shot_exclude_trivia, gemini-1.5-pro-latest, 12841719\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_exclude_trivia, llm_name: gemini-1.5-pro-latest, record_id: 135893324\n","mpve, mat_paper_to_property_1_shot_exclude_trivia, gemini-1.5-pro-latest, 135893324\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_exclude_trivia, llm_name: gemini-1.5-pro-latest, record_id: 137261967\n","mpve, mat_paper_to_property_1_shot_exclude_trivia, gemini-1.5-pro-latest, 137261967\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_exclude_trivia, llm_name: gemini-1.5-pro-latest, record_id: 137362119\n","mpve, mat_paper_to_property_1_shot_exclude_trivia, gemini-1.5-pro-latest, 137362119\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_exclude_trivia, llm_name: gemini-1.5-pro-latest, record_id: 15804005\n","mpve, mat_paper_to_property_1_shot_exclude_trivia, gemini-1.5-pro-latest, 15804005\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_exclude_trivia, llm_name: gemini-1.5-pro-latest, record_id: 17645319\n","mpve, mat_paper_to_property_1_shot_exclude_trivia, gemini-1.5-pro-latest, 17645319\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_exclude_trivia, llm_name: gemini-1.5-pro-latest, record_id: 2837337\n","mpve, mat_paper_to_property_1_shot_exclude_trivia, gemini-1.5-pro-latest, 2837337\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_exclude_trivia, llm_name: gemini-1.5-pro-latest, record_id: 317542\n","mpve, mat_paper_to_property_1_shot_exclude_trivia, gemini-1.5-pro-latest, 317542\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_exclude_trivia, llm_name: gemini-1.5-pro-latest, record_id: 53384093\n","mpve, mat_paper_to_property_1_shot_exclude_trivia, gemini-1.5-pro-latest, 53384093\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_exclude_trivia, llm_name: gemini-1.5-pro-latest, record_id: 53519111\n","mpve, mat_paper_to_property_1_shot_exclude_trivia, gemini-1.5-pro-latest, 53519111\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_exclude_trivia, llm_name: gemini-1.5-pro-latest, record_id: 55005437\n","mpve, mat_paper_to_property_1_shot_exclude_trivia, gemini-1.5-pro-latest, 55005437\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_exclude_trivia, llm_name: gemini-1.5-pro-latest, record_id: 6183251\n","mpve, mat_paper_to_property_1_shot_exclude_trivia, gemini-1.5-pro-latest, 6183251\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_exclude_trivia, llm_name: gemini-1.5-pro-latest, record_id: 68518\n","mpve, mat_paper_to_property_1_shot_exclude_trivia, gemini-1.5-pro-latest, 68518\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_exclude_trivia, llm_name: gemini-1.5-pro-latest, record_id: 97574650\n","mpve, mat_paper_to_property_1_shot_exclude_trivia, gemini-1.5-pro-latest, 97574650\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_exclude_trivia, llm_name: gpt-4o, record_id: 10222315\n","mpve, mat_paper_to_property_1_shot_exclude_trivia, gpt-4o, 10222315\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_exclude_trivia, llm_name: gpt-4o, record_id: 11093908\n","mpve, mat_paper_to_property_1_shot_exclude_trivia, gpt-4o, 11093908\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_exclude_trivia, llm_name: gpt-4o, record_id: 11181068\n","mpve, mat_paper_to_property_1_shot_exclude_trivia, gpt-4o, 11181068\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_exclude_trivia, llm_name: gpt-4o, record_id: 12841719\n","mpve, mat_paper_to_property_1_shot_exclude_trivia, gpt-4o, 12841719\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_exclude_trivia, llm_name: gpt-4o, record_id: 135893324\n","mpve, mat_paper_to_property_1_shot_exclude_trivia, gpt-4o, 135893324\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_exclude_trivia, llm_name: gpt-4o, record_id: 137261967\n","mpve, mat_paper_to_property_1_shot_exclude_trivia, gpt-4o, 137261967\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_exclude_trivia, llm_name: gpt-4o, record_id: 137362119\n","mpve, mat_paper_to_property_1_shot_exclude_trivia, gpt-4o, 137362119\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_exclude_trivia, llm_name: gpt-4o, record_id: 15804005\n","mpve, mat_paper_to_property_1_shot_exclude_trivia, gpt-4o, 15804005\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_exclude_trivia, llm_name: gpt-4o, record_id: 17645319\n","mpve, mat_paper_to_property_1_shot_exclude_trivia, gpt-4o, 17645319\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_exclude_trivia, llm_name: gpt-4o, record_id: 2837337\n","mpve, mat_paper_to_property_1_shot_exclude_trivia, gpt-4o, 2837337\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_exclude_trivia, llm_name: gpt-4o, record_id: 317542\n","mpve, mat_paper_to_property_1_shot_exclude_trivia, gpt-4o, 317542\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_exclude_trivia, llm_name: gpt-4o, record_id: 53384093\n","mpve, mat_paper_to_property_1_shot_exclude_trivia, gpt-4o, 53384093\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_exclude_trivia, llm_name: gpt-4o, record_id: 53519111\n","mpve, mat_paper_to_property_1_shot_exclude_trivia, gpt-4o, 53519111\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_exclude_trivia, llm_name: gpt-4o, record_id: 55005437\n","mpve, mat_paper_to_property_1_shot_exclude_trivia, gpt-4o, 55005437\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_exclude_trivia, llm_name: gpt-4o, record_id: 6183251\n","mpve, mat_paper_to_property_1_shot_exclude_trivia, gpt-4o, 6183251\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_exclude_trivia, llm_name: gpt-4o, record_id: 68518\n","mpve, mat_paper_to_property_1_shot_exclude_trivia, gpt-4o, 68518\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_exclude_trivia, llm_name: gpt-4o, record_id: 97574650\n","mpve, mat_paper_to_property_1_shot_exclude_trivia, gpt-4o, 97574650\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_exclude_trivia, llm_name: claude-3-opus-20240229, record_id: 10222315\n","mpve, mat_paper_to_property_1_shot_exclude_trivia, claude-3-opus-20240229, 10222315\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_exclude_trivia, llm_name: claude-3-opus-20240229, record_id: 11093908\n","mpve, mat_paper_to_property_1_shot_exclude_trivia, claude-3-opus-20240229, 11093908\n","task: mpve, prompt: mat_paper_to_property_1_shot_exclude_trivia, llm_name: claude-3-opus-20240229, record_id: 11181068\n","mpve, mat_paper_to_property_1_shot_exclude_trivia, claude-3-opus-20240229, 11181068\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_exclude_trivia, llm_name: claude-3-opus-20240229, record_id: 12841719\n","mpve, mat_paper_to_property_1_shot_exclude_trivia, claude-3-opus-20240229, 12841719\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_exclude_trivia, llm_name: claude-3-opus-20240229, record_id: 135893324\n","mpve, mat_paper_to_property_1_shot_exclude_trivia, claude-3-opus-20240229, 135893324\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_exclude_trivia, llm_name: claude-3-opus-20240229, record_id: 137261967\n","mpve, mat_paper_to_property_1_shot_exclude_trivia, claude-3-opus-20240229, 137261967\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_exclude_trivia, llm_name: claude-3-opus-20240229, record_id: 137362119\n","mpve, mat_paper_to_property_1_shot_exclude_trivia, claude-3-opus-20240229, 137362119\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_exclude_trivia, llm_name: claude-3-opus-20240229, record_id: 15804005\n","mpve, mat_paper_to_property_1_shot_exclude_trivia, claude-3-opus-20240229, 15804005\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_exclude_trivia, llm_name: claude-3-opus-20240229, record_id: 17645319\n","mpve, mat_paper_to_property_1_shot_exclude_trivia, claude-3-opus-20240229, 17645319\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_exclude_trivia, llm_name: claude-3-opus-20240229, record_id: 2837337\n","mpve, mat_paper_to_property_1_shot_exclude_trivia, claude-3-opus-20240229, 2837337\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_exclude_trivia, llm_name: claude-3-opus-20240229, record_id: 317542\n","mpve, mat_paper_to_property_1_shot_exclude_trivia, claude-3-opus-20240229, 317542\n","task: mpve, prompt: mat_paper_to_property_1_shot_exclude_trivia, llm_name: claude-3-opus-20240229, record_id: 53384093\n","mpve, mat_paper_to_property_1_shot_exclude_trivia, claude-3-opus-20240229, 53384093\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_exclude_trivia, llm_name: claude-3-opus-20240229, record_id: 53519111\n","mpve, mat_paper_to_property_1_shot_exclude_trivia, claude-3-opus-20240229, 53519111\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_exclude_trivia, llm_name: claude-3-opus-20240229, record_id: 55005437\n","mpve, mat_paper_to_property_1_shot_exclude_trivia, claude-3-opus-20240229, 55005437\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_exclude_trivia, llm_name: claude-3-opus-20240229, record_id: 6183251\n","mpve, mat_paper_to_property_1_shot_exclude_trivia, claude-3-opus-20240229, 6183251\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_exclude_trivia, llm_name: claude-3-opus-20240229, record_id: 68518\n","mpve, mat_paper_to_property_1_shot_exclude_trivia, claude-3-opus-20240229, 68518\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["task: mpve, prompt: mat_paper_to_property_1_shot_exclude_trivia, llm_name: claude-3-opus-20240229, record_id: 97574650\n","mpve, mat_paper_to_property_1_shot_exclude_trivia, claude-3-opus-20240229, 97574650\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["JSON file successfully written to: /content/drive/My Drive/mpve.json\n"]}]}]}